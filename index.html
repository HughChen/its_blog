<!DOCTYPE html>
<html lang="en">
<title>A fast and exact game-theoretic algorithm to explain trees</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="stylesheet" type="text/css" href="index.css">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script language="JavaScript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/3.2.1/math.js"></script>
<script src="https://d3js.org/d3.v4.min.js"></script>
<script>d3v4 = d3;</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js"></script>


<style id="distill-prerendered-styles" type="text/css">/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

html {
  font-size: 14px;
  line-height: 1.6em;
  /* font-family: "Libre Franklin", "Helvetica Neue", sans-serif; */
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  /*, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";*/
  text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}

@media(min-width: 768px) {
  html {
    font-size: 16px;
  }
}

body {
  margin: 0;
}

a {
  color: #004276;
}

figure {
  margin: 0;
}

table {
  border-collapse: collapse;
  border-spacing: 0;
}

table th {
  text-align: left;
}

table thead {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

table thead th {
  padding-bottom: 0.5em;
}

table tbody :first-child td {
  padding-top: 0.5em;
}

pre {
  overflow: auto;
  max-width: 100%;
}

p {
  margin-top: 0;
  margin-bottom: 1em;
}

sup, sub {
  vertical-align: baseline;
  position: relative;
  top: -0.4em;
  line-height: 1em;
}

sub {
  top: 0.4em;
}

.kicker,
.marker {
  font-size: 15px;
  font-weight: 600;
  color: rgba(0, 0, 0, 0.5);
}


/* Headline */

@media(min-width: 1024px) {
  d-title h1 span {
    display: block;
  }
}

/* Figure */

figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

figcaption+figure {

}

figure img {
  width: 100%;
}

figure svg text,
figure svg tspan {
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@supports not (display: grid) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    display: block;
    padding: 8px;
  }
}

.base-grid,
distill-header,
d-title,
d-abstract,
d-article,
d-appendix,
distill-appendix,
d-byline,
d-footnote-list,
d-citation-list,
distill-footer {
  display: grid;
  justify-items: stretch;
  grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
  grid-column-gap: 8px;
}

.grid {
  display: grid;
  grid-column-gap: 8px;
}

@media(min-width: 768px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}




.base-grid {
  grid-column: screen;
}

/* .l-body,
d-article > *  {
  grid-column: text;
}

.l-page,
d-title > *,
d-figure {
  grid-column: page;
} */

.l-gutter {
  grid-column: gutter;
}

.l-text,
.l-body {
  grid-column: text;
}

.l-page {
  grid-column: page;
}

.l-body-outset {
  grid-column: middle;
}

.l-page-outset {
  grid-column: page;
}

.l-screen {
  grid-column: screen;
}

.l-screen-inset {
  grid-column: screen;
  padding-left: 16px;
  padding-left: 16px;
}


/* Aside */

d-article aside {
  grid-column: gutter;
  font-size: 12px;
  line-height: 1.6em;
  color: rgba(0, 0, 0, 0.6)
}

@media(min-width: 768px) {
  aside {
    grid-column: gutter;
  }

  .side {
    grid-column: gutter;
  }
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-title {
  padding: 2rem 0 1.5rem;
  contain: layout style;
  overflow-x: hidden;
}

@media(min-width: 768px) {
  d-title {
    padding: 4rem 0 1.5rem;
  }
}

d-title h1 {
  grid-column: text;
  font-size: 40px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

@media(min-width: 768px) {
  d-title h1 {
    font-size: 50px;
  }
}

d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  grid-column: text;
}

d-title .status {
  margin-top: 0px;
  font-size: 12px;
  color: #009688;
  opacity: 0.8;
  grid-column: kicker;
}

d-title .status span {
  line-height: 1;
  display: inline-block;
  padding: 6px 0;
  border-bottom: 1px solid #80cbc4;
  font-size: 11px;
  text-transform: uppercase;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-byline {
  contain: style;
  overflow: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  font-size: 0.8rem;
  line-height: 1.8em;
  padding: 1.5rem 0;
  min-height: 1.8em;
}


d-byline .byline {
  grid-template-columns: 1fr 1fr;
  grid-column: text;
}

@media(min-width: 768px) {
  d-byline .byline {
    grid-template-columns: 1fr 1fr 1fr 1fr;
  }
}

d-byline .authors-affiliations {
  grid-column-end: span 2;
  grid-template-columns: 1fr 1fr;
  margin-bottom: 1em;
}

@media(min-width: 768px) {
  d-byline .authors-affiliations {
    margin-bottom: 0;
  }
}

d-byline h3 {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  margin: 0;
  text-transform: uppercase;
}

d-byline p {
  margin: 0;
}

d-byline a,
d-article d-byline a {
  color: rgba(0, 0, 0, 0.8);
  text-decoration: none;
  border-bottom: none;
}

d-article d-byline a:hover {
  text-decoration: underline;
  border-bottom: none;
}

d-byline p.author {
  font-weight: 500;
}

d-byline .affiliations {

}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-article {
  contain: layout style;
  overflow-x: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  padding-top: 2rem;
  color: rgba(0, 0, 0, 0.8);
}

d-article > * {
  grid-column: text;
}

@media(min-width: 768px) {
  d-article {
    font-size: 16px;
  }
}

@media(min-width: 1024px) {
  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
}


/* H2 */


d-article .marker {
  text-decoration: none;
  border: none;
  counter-reset: section;
  grid-column: kicker;
  line-height: 1.7em;
}

d-article .marker:hover {
  border: none;
}

d-article .marker span {
  padding: 0 3px 4px;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  position: relative;
  top: 4px;
}

d-article .marker:hover span {
  color: rgba(0, 0, 0, 0.7);
  border-bottom: 1px solid rgba(0, 0, 0, 0.7);
}

d-article h2 {
  font-weight: 600;
  font-size: 24px;
  line-height: 1.25em;
  margin: 2rem 0 1.5rem 0;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding-bottom: 1rem;
}

@media(min-width: 1024px) {
  d-article h2 {
    font-size: 36px;
  }
}

/* H3 */

d-article h3 {
  font-weight: 700;
  font-size: 18px;
  line-height: 1.4em;
  margin-bottom: 1em;
  margin-top: 2em;
}

@media(min-width: 1024px) {
  d-article h3 {
    font-size: 20px;
  }
}

/* H4 */

d-article h4 {
  font-weight: 600;
  text-transform: uppercase;
  font-size: 14px;
  line-height: 1.4em;
}

d-article a {
  color: inherit;
}

d-article p,
d-article ul,
d-article ol,
d-article blockquote {
  margin-top: 0;
  margin-bottom: 1em;
  margin-left: 0;
  margin-right: 0;
}

d-article blockquote {
  border-left: 2px solid rgba(0, 0, 0, 0.2);
  padding-left: 2em;
  font-style: italic;
  color: rgba(0, 0, 0, 0.6);
}

d-article a {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  text-decoration: none;
}

d-article a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.8);
}

d-article .link {
  text-decoration: underline;
  cursor: pointer;
}

d-article ul,
d-article ol {
  padding-left: 24px;
}

d-article li {
  margin-bottom: 1em;
  margin-left: 0;
  padding-left: 0;
}

d-article li:last-child {
  margin-bottom: 0;
}

d-article pre {
  font-size: 14px;
  margin-bottom: 20px;
}

d-article hr {
  grid-column: screen;
  width: 100%;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article section {
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article span.equation-mimic {
  font-family: georgia;
  font-size: 115%;
  font-style: italic;
}

d-article > d-code,
d-article section > d-code  {
  display: block;
}

d-article > d-math[block],
d-article section > d-math[block]  {
  display: block;
}

@media (max-width: 768px) {
  d-article > d-code,
  d-article section > d-code,
  d-article > d-math[block],
  d-article section > d-math[block] {
      overflow-x: scroll;
      -ms-overflow-style: none;  // IE 10+
      overflow: -moz-scrollbars-none;  // Firefox
  }

  d-article > d-code::-webkit-scrollbar,
  d-article section > d-code::-webkit-scrollbar,
  d-article > d-math[block]::-webkit-scrollbar,
  d-article section > d-math[block]::-webkit-scrollbar {
    display: none;  // Safari and Chrome
  }
}

d-article .citation {
  color: #668;
  cursor: pointer;
}

d-include {
  width: auto;
  display: block;
}

d-figure {
  contain: layout style;
}

/* KaTeX */

.katex, .katex-prerendered {
  contain: style;
  display: inline-block;
}

/* Tables */

d-article table {
  border-collapse: collapse;
  margin-bottom: 1.5rem;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table th {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table td {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

d-article table tr:last-of-type td {
  border-bottom: none;
}

d-article table th,
d-article table td {
  font-size: 15px;
  padding: 2px 8px;
}

d-article table tbody :first-child td {
  padding-top: 2px;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

span.katex-display {
  text-align: left;
  padding: 8px 0 8px 0;
  margin: 0.5em 0 0.5em 1em;
}

span.katex {
  -webkit-font-smoothing: antialiased;
  color: rgba(0, 0, 0, 0.8);
  font-size: 1.18em;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@media print {

  @page {
    size: 8in 11in;
    @bottom-right {
      content: counter(page) " of " counter(pages);
    }
  }

  html {
    /* no general margins -- CSS Grid takes care of those */
  }

  p, code {
    page-break-inside: avoid;
  }

  h2, h3 {
    page-break-after: avoid;
  }

  d-header {
    visibility: hidden;
  }

  d-footer {
    display: none!important;
  }

}
</style>

<style>
hover a {
    color: "Olive";
}

.no-margin {
	margin:0px;
	font-family:courier;
	font-size:16px;
}

.responsive {
	width: 100%;
	height: auto;
}

.bar {
    fill: #4DAF51;
}

.bar:hover {
	fill: #019788;
}

.axis {
    font-size: 14px;
}

.axis path,
.axis line {
    fill: none;
    display: none;
    shape-rendering: crispEdges;
}

.label {
	color: #4DAF51;
    font-size: 14px;
}

.d3-tip:after {
  box-sizing: border-box;
  display: inline;
  font-size: 10px;
  width: 100%;
  line-height: 1;
  color: rgba(0, 0, 0, 0.8);
  content: "\25BC";
  position: absolute;
  text-align: center;
}

.d3-tip.n:after {
  margin: -1px 0 0 0;
  top: 100%;
  left: 0;
}

#table_container {
	/*margin: 0 auto;*/
	background-color : #F4F6F6;
}

.slidecontainer {
  width: 100%;
}

.slider {
  -webkit-appearance: none;
  width: 100%;
  height: 15px;
  border-radius: 5px;
  background: #d3d3d3;
  outline: none;
  opacity: 0.7;
  -webkit-transition: .2s;
  transition: opacity .2s;
}

.slider:hover {
  opacity: 1;
}

.slider::-webkit-slider-thumb {
  -webkit-appearance: none;
  appearance: none;
  width: 25px;
  height: 25px;
  border-radius: 50%;
  background: #4CAF50;
  cursor: pointer;
}

.slider::-moz-range-thumb {
  width: 25px;
  height: 25px;
  border-radius: 50%;
  background: #4CAF50;
  cursor: pointer;
}

.node circle {
	fill: #fff;
	stroke: #ccc;
	stroke-width: 4px;
}

.node text { font: 12px sans-serif; }

.link {
	fill: none;
	stroke-width: 3px;
}

div.tooltip {
	position: absolute;
}

.container {
	width: 760px;
}

.first {
	width: 380px;
	float: left;
	height: 630px;
}

.second {
	width: 380px;
	float: left;
	height: 630px;
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

a.figure-number,
a.section-number {
    border-bottom-color: hsla(206, 90%, 20%, 0.3);
    text-transform: uppercase;
    font-size: .85em;
    color: hsla(206, 90%, 20%, 0.7);
}
a.figure-number::before {
    content: "Figure ";
}
a.figure-number:hover,
a.section-number:hover {
    border-bottom-color: hsla(206, 90%, 20%, 0.6);
}

.svg-container {
  display: inline-block;
  position: relative;
  width: 100%;
  padding-bottom: 100%; /* aspect ratio */
  vertical-align: top;
  overflow: hidden;
}
.svg-content-responsive {
  display: inline-block;
  position: absolute;
  top: 10px;
  left: 0;
}

svg .rect {
  fill: gold;
  stroke: steelblue;
  stroke-width: 5px;
}
</style>

<body>

  <d-front-matter>
    <code style="display: none;" type="text/json"
      >{ "title": "A fast and exact game-theoretic algorithm to explain trees", "description": "Shapley values have recently been adapted to explain machine learning algorithms; however, calculating them is NP-hard.  By restricting our machine learning model class to trees, we can calculate them exactly in linear time.",
      "authors": [
        { "author": "Hugh Chen", "authorURL": "http://hughchen.github.io/", "affiliation": "Paul G. Allen School of CSE", "affiliationURL": "https://www.cs.washington.edu/"  },
        { "author": "Scott Lundberg", "authorURL": "https://scottlundberg.com/", "affiliation": "Microsoft Research", "affiliationURL": "https://www.microsoft.com/en-us/research/"  },
        { "author": "Su-In Lee", "authorURL": "https://suinlee.cs.washington.edu/", "affiliation": "Paul G. Allen School of CSE", "affiliationURL": "https://www.cs.washington.edu/"  }
      ] }</code>
  </d-front-matter>

  <d-title>
    <h1>A fast and exact game-theoretic algorithm to explain trees</h1>
      <p style="font-size: 150%;">Shapley values have recently been adapted to explain machine learning algorithms; however, calculating them is NP-hard.  By restricting our machine learning model class to trees, we can calculate them exactly in linear time.</p>
      <img
        src="./images/trees.jpg"
        style='grid-column: text; width: 100%; padding-top: 20px; padding-bottom:20px;' />
  </d-title>
  <d-byline></d-byline>
  <d-article>

    <d-contents>
      <nav class="l-text toc figcaption">
        <h3>Top</h3>
        <!--<div><a href="#introduction">Introduction</a></div>-->
        <div><a href="#introduction">Introduction</a></div>
        <div><a href="#background">What's in a SHAP Value?</a></div>
        <ul>
          <li><a href="#shapley_values">1: Back to basics with Shapley values</a></li>
          <li><a href="#shap_values">2: Adapting Shapley values to machine learning</a></li>
          <li><a href="#">3: Masking missing features</a></li>
          <li><a href="#">4: Imputing missing features by conditioning</a></li>
          <li><a href="#background_distribution">5: Interventional conditional expectation SHAP values with a background distribution</a></li>
        </ul>
        <div><a href="#claim-2">Explaining trees quickly and exactly</a></div>
        <ul>
          <li><a href="#brute_force">1: The brute force algorithm</a></li>
          <li><a href="#naive_implementation">2: The naive algorithm</a></li>
          <li><a href="#dynamic_programming_implementation">3: The dynamic algorithm</a></li>
        </ul>
        <div><a href="#comparison_of_methods">A comparison of Shapley value attribution methods</a></div>
        <div><a href="#references">References</a></div>
      </nav>
    </d-contents>

  <!-- Introduction -->
  <div style="max-width:800px" id="abstract">
    <h2 id="introduction">Introduction</h2>
    <p>
      Nowadays, machine learning (ML) is widespread.  In this field, one of the most popular machine learning model type is tree-based models.  As evidence, a recent survey of data scientists and researchers found that tree models were both the second and third most popular class of method, beaten only by Logistic Regression (Figure 1).  Although small tree models can be interpretable <d-cite bibtex-key="rudin2019stop"></d-cite>, most tree models are generally large and hard for humans to interpret.  
    </p>

  <!-- Figure 1 -->
  <figure class="l-body-outset">
    <div id="fig1"></div>
    <figcaption>
      <a href="#fig1" class="figure-number">1</a>: The most popular data science methods according to a <a href="https://www.kaggle.com/surveys/2017">2017 Kaggle survey</a> (based on a total of 7,301 responses).
    </figcaption>
  </figure>

    <p>
    In order to explain these models, we use Shapley values - a unique game-theoretic solution for spreading credit between features.  First, we discuss SHAP values, an extension of Shapley values to machine learning models (<a href="#background">Section 1</a>).  However, exactly computing SHAP values for an arbitrary model is NP-hard <d-cite bibtex-key="matsui2001np"></d-cite>, but by focusing on explaining tree models, it is possible to compute them exactly in linear time (<a href="#algorithm">Section 2</a>).
    </p>

    <!-- <h3 id="motivation">Motivation</h3> -->
    <p>
    <i>What is the goal of this article?</i> 

    <p>
    Given that there is a long history of model explanations going awry when users do not understand what an explanation means (e.g., p-values for linear models <d-cite bibtex-key="schervish1996p"></d-cite>), it is critical to have a broadly accessible explanation of SHAP values and how they are obtained for tree models to ensure that they are not misused.  To this end, we aim to provide an easily accessible answer to two questions: 1.) What are SHAP values?  2.) How can we obtain SHAP values for trees?  In particular, we focus on explaining an algorithm that was empirically evaluated in <d-cite bibtex-key="lundberg2020local"></d-cite>.
  </p>
  </div>

  <hr>

  <!-- The Background Section -->
  <div style="max-width:800px">
    <h2 id="background">1. What's in a SHAP value?</h2>
    
    <p>
 	   In this section, we describe Shapley values and a few versions that have been used to explain machine learning models.  Then, we use a linear model example to justify a specific extension of the Shapley values.  With this formulation, we show how obtaining the SHAP values reduces to a average over so-called single reference SHAP values that can be thought of as explanations with respect to a single foreground sample (explicand) and a single background sample (reference).
	</p>


    <!-- What are Shapley Values? -->
    <h3 id="shapley_values">1.1 Back to basics: Shapley values</h3>
	<p>
    	Shapley values are a method to spread credit among players in a "coalitional game".  We can define the players to be a set \(N=\{1,\cdots,d\}\).  Then, the coalitional game is a function that maps subsets of the players to a scalar value:

    	$$
    	v(S):2^N\to\mathbb{R}^1
    	$$
    </p>

    <p>
    	To make these concepts more concrete, we can imagine a company that makes a profit \(v(S)\) that is determined by what combination of individuals they employ \(S\).  Furthermore, let's assume we know \(v(S)\) for all possible combinations of employees.  Then, the Shapley values assign credit to an individual \(i\) by taking a weighted average of how much the profit increases when \(i\) works with a group \(S\) versus when he does not work with \(S\).  Repeating this for all possible subsets \(S\) gives us the Shapley Values:
    	<!-- (include a simple graphic here?) -->
    	$$
    	\overbrace{\phi_i(v)}^{\text{Shapley value of }i}=\sum_{S\subseteq N\setminus\{i\}}\underbrace{\frac{|S|!(|N|-|S|-1)!}{|N|!}}_{\text{Weight }W(|S|,|N|)}(\overbrace{v(S\cup\{i\})-v(S)}^{\text{Profit individual }i\text{ adds}})
    	$$
      <a href="#shapley_value_ex">Figure 2</a> computes this summation for an arbitrary coalitional game with three players.
    </p>

  <!-- Figure 2 -->
	<figure id="shapley_value_ex">
  
    <div>
  	  <table align="center" style="width:500px;border:none;">
  	  	<col width="200px"/>
      	<col width="250px"/>
      	<col width="50px"/>
        <tr align="center">
          <td style="border:none;" colspan="3">Coalitional game</td>
        </tr>
    		<tr>
    			<td>Subset \(S\)</td>
    			<td>Profit \(v(S)\)</td>
    			<td></td>
    		</tr>
    		<tr>
    			<td>\(\{\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_n" onchange="calcSV()"></td>
    			<td><span id="s_n_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_a" onchange="calcSV()"></td>
    			<td><span id="s_a_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ben\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_b" onchange="calcSV()"></td>
    			<td><span id="s_b_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_c" onchange="calcSV()"></td>
    			<td><span id="s_c_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava,Ben\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_ab" onchange="calcSV()"></td>
    			<td><span id="s_ab_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava,Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_ac" onchange="calcSV()"></td>
    			<td><span id="s_ac_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ben,Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_bc" onchange="calcSV()"></td>
    			<td><span id="s_bc_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava,Ben,Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_abc" onchange="calcSV()"></td>
    			<td><span id="s_abc_out"></span></td>
    		</tr>
  	  </table>
    </div>

    <div style="margin-bottom:0px">
  	  <table align="center" style="width:200px;border:none;">
    		<col width="100px"/>
      	<col width="100px"/>
        <tr align="center">
          <td style="border:none;" colspan="2">Shapley values</td>
        </tr>
    		<tr>
    			<td align=center>\(\phi_{Ava}(v)\)</td>
    			<td align=center id="phi_a">0</td>
    		</tr>
    		<tr>
    			<td align=center>\(\phi_{Ben}(v)\)</td>
    			<td align=center id="phi_b">0</td>
    		</tr>
    		<tr>
    			<td align=center>\(\phi_{Cat}(v)\)</td>
    			<td align=center id="phi_c">0</td>
    		</tr>
  	  </table>
    </div>

    <div align="center" style="margin-bottom: 10px">
  	  <input type="button" value="Preset A" class="w3-button w3-teal" id="ex1_presetA" onclick="ex1_presetA()"> 
  	  <input type="button" value="Preset B" class="w3-button w3-green" id="ex1_presetB" onclick="ex1_presetB()"> 
  	  <input type="button" value="Preset C" class="w3-button w3-green" id="ex1_presetC" onclick="ex1_presetC()"> 
  	  <input type="button" value="Preset D" class="w3-button w3-green" id="ex1_presetD" onclick="ex1_presetD()"> 
    </div>

	  <p align="center" style="font-size:13px" id="ex1_preset_text">No credit.</p>

    <figcaption>
      <a href="#shapley_value_ex" class="figure-number">2</a>: Shapley values for a company that makes a profit \(v(S)\) based on it's three prospective employees \(Ava\), \(Ben\), and \(Cat\).
    </figcaption>
	</figure>

	<p>
    	The Shapley values consider how much an individual increases profit when they work together with all other possible teams.  Furthermore, they are a unique solution to spreading credit as defined by several desirable properties <d-cite bibtex-key="young1985monotonic"></d-cite> (all of which hold for any coalitional game, as can be seen in <a href="#shapley_value_ex">Figure 2</a>):
    	<ul>
    		<li>Local Accuracy/Efficiency: The sum of Shapley values for all employees adds up to the profit with all employees minus the profit with no employees:</li>
	    		$$
	    			\sum_{i\in N} \phi_i(v)=v(N)-v(\{\})
	    		$$
    		<li>Consistency/Monotonicity: If an employee \(i\) always increases company \(v_1\)'s profit more than they would company \(v_2\) for all teams of other employees, then \(i\)'s attribution for \(v_1\) should be greater than or equal to their attribution in \(v_2\):</li>
    			$$
    			v_1(S\cup {i})-v_1(S)\geq v_2(S\cup {i})-v_2(S) \forall S \implies \phi_i(v_1)\geq \phi_i(v_2)
    			$$
    		<li>Missingness: Employees \(i\) that don't help or hurt the company's profit must have no attribution.</li>
    			$$
    			v(S\cup {i})=v(S)\forall S\implies \phi_i(v)=0
    			$$
    	</ul>
    </p>

	<p>
    	In <d-cite bibtex-key="lundberg2017unified"></d-cite>, Lundberg and Lee extend Shapley values to explain ML models (<a href="#shap_values">Section 1.2</a>).
    </p>


    <!-- What are SHAP Values? -->
    <h3 id="shap_values">1.2 SHAP values</h3>
	<p>
    	SHAP values are a variant of Shapley values to explain ML models.  For SHAP values, the game \(v(S)\) is now related to a machine learning model \(f(x)\) and the set of players is now a feature vector \(x:=\{x_1,\cdots,x_d\}\in\mathbb{R}^d\).  
    </p>

    <p>
    	In contrast, Shapley values define a game's output \(v(S)\) to be the value of the game with some players "present" and the remaining players "missing".  Here, "missing" is naturally defined: whether or not a player \(i\) is present in the set \(S\) (or, as in our example, whether an employee was working for the company).
    </p>

    <p>
    	In comparison, ML models generally require a fixed length input with continuous values which makes setting features to be "missing" or "present" less straightforward.  One simple approach is to impute the "missing" features by masking them by a fixed background sample \(x^b \in \mathbb{R}^d\).
    	$$
		v(S)=f(h^S)\text{, where } h^S_i = x_i\text{ if }i\in S\text{, }h^S_i = x^b_i\text{ otherwise}
    	$$
    	For instance, if we want to set the feature <i>Height</i> to "missing", we could replace it with a specific <i>background value</i>.  One natural option of <i>background value</i> is zero.  However, this is unsatisfying because a <i>Height</i> of zero is impossible.  Another option of <i>background value</i> could be the average human height.  This is arguably a better choice, however it means that explanations for people who are exactly average height will be biased to give no weight to height.  In fact, masking with any single background sample will introduce bias to SHAP values.  Alternatively, instead of using a single background sample, we can use an entire background distribution to define missingness.
    </p>

	<p>
    	Then, a very natural approach to impute features is with conditional expectation.  Instead of simply replacing "missing" features with a fixed value, we condition on the set of features that are "present" as if we know them and use those to guess at the "missing" features.  If we define \(D\) to be the background (underlying) distribution our samples are drawn from, the value of the game is:
    	$$
		v(S)=\mathbb{E}_D[f(x)|x_{S}]
    	$$
    </p>

	<p>
    	One caveat is that getting this conditional expectation for actual data is very difficult.  Furthermore, even if you do manage to do so, the resulting explanations can end up having undesirable characteristics (more on this later).  Because our goal is to focus on explaining the model itself, an arguably more natural approach is to use causal inference's <i>interventional conditional expectation</i>:
    	$$
    	v(S)=\mathbb{E}_D[f(x)|\text{do}(x_{S})]
    	$$
    	The <i>do</i> notation is causal inference's <i>do</i>-operator <d-cite bibtex-key="pearl2009causality"></d-cite>.  In words, we break the dependence between the features in \(S\) and the remaining features, which is analogous to <i>intervening</i> on the remaining features (more on this in <a href="#background_distribution">Section 1.3</a>).  The motivation behind this decision comes from <d-cite bibtex-key="janzing2019feature"></d-cite> which is also very close to Random Baseline Shapley in <d-cite bibtex-key="sundararajan2019many"></d-cite>.  Additionally, this is exactly the assumption made by <a href="https://shap.readthedocs.io/en/latest/#shap.KernelExplainer">Kernel Explainer</a> <d-cite bibtex-key="lundberg2017unified"></d-cite> and <a href="https://shap.readthedocs.io/en/latest/#shap.SamplingExplainer">Sampling Explainer</a> from the SHAP package.
    </p>

    <!-- Figure 3 -->
    <figure id="linear_shap_ex" class="l-page">
      <div align=center style="margin-bottom: 20px">

    		<table style="width:110px;display:inline;margin-right:25px;border:none;">
  	      <col width="50px">
  	      <col width="65px">
  	      <tr align="center">
  	      	<td style="border:none;" colspan="2">Linear</td>
  	  	  </tr>
  	      <tr align="center">
  	      	<td colspan="2">Model</td>
  	  	  </tr>
    		  <tr align="center">
    		    <td>\(\beta_1\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b1" value="1"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(\beta_2\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b2" value="2"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(\beta_3\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b3" value="3"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(\beta_4\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b4" value="4"></td>
    		  </tr>
    		</table>

    		<table style="width:300px;display:inline;margin-right:25px;border:none;">
  	      <col width="50px">
  	      <col width="65px">
  	      <col width="65px">
  	      <col width="65px">
  	      <col width="65px">
  	      <tr align="center">
  	      	<td colspan="5">Covariance \(C\)</td>
  	      </tr>
  	      <tr align="center">
    		    <td></td>
    		    <td>\(x_1\)</td>
    		    <td>\(x_2\)</td>
    		    <td>\(x_3\)</td>
    		    <td>\(x_4\)</td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_1\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor11" value="1"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor12" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor13" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor14" value="0"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_2\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor21" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor22" value="1"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor23" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor24" value="0"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_3\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor31" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor32" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor33" value="1"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor34" value="0"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_4\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor41" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor42" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor43" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor44" value="1"></td>
    		  </tr>
    		</table>

    		<table style="width:110px;display:inline;margin-right:25px;border:none;">
  	      <col width="50px">
  	      <col width="65px">
  	      <tr align="center">
  	      	<td colspan="2" style="border:none;">Foreground</td>
  	  	  </tr>
  	      <tr align="center">
  	      	<td colspan="2">Sample</td>
  	  	  </tr>
    		  <tr align="center">
    		    <td>\(x_1\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x1" value="1"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_2\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x2" value="1"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_3\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x3" value="1"></td>
    		  </tr>
    		  <tr align="center">
    		    <td>\(x_4\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x4" value="1"></td>
    		  </tr>
    		</table>
      </div>

      <div align=center style="margin-bottom:20px">
  	  	<table style="width:300px;display:inline;margin-right:25px;border:none;">
  	      <col width="180px">
  	      <col width="80px">
  	      <col width="80px">
  	      <col width="80px">
  	      <col width="80px">
  	      <tr align="center">
  	      	<td></td>
  	      	<td>\(\phi_1\)</td>
  	      	<td>\(\phi_2\)</td>
  	      	<td>\(\phi_3\)</td>
  	      	<td>\(\phi_4\)</td>
  	  	  </tr>
    		  <tr align="center">
    		    <td>SHAP Values (CE)</td>
    		    <td id="ex2_CE_phi1">1</td>
    		    <td id="ex2_CE_phi2">2</td>
    		    <td id="ex2_CE_phi3">3</td>
    		    <td id="ex2_CE_phi4">4</td>
    		  </tr>
    		  <tr align="center">
    		  	<td>SHAP Values (ICE)</td>
    		    <td id="ex2_ICE_phi1">1</td>
    		    <td id="ex2_ICE_phi2">2</td>
    		    <td id="ex2_ICE_phi3">3</td>
    		    <td id="ex2_ICE_phi4">4</td>
    		  </tr>
  		  </table>
      </div>

      <div align=center style="margin-bottom: 10px">
    		<input type="button" value="Preset A" class="w3-button w3-teal" id="ex2_presetA" onclick="ex2_presetA()">
      	<input type="button" value="Preset B" class="w3-button w3-green" id="ex2_presetB" onclick="ex2_presetB()">
      	<input type="button" value="Preset C" class="w3-button w3-green" id="ex2_presetC" onclick="ex2_presetC()">
      	<input type="button" value="Preset D" class="w3-button w3-green" id="ex2_presetD" onclick="ex2_presetD()">
      </div>

	    <p align="center" id="ex2_preset_text" style="font-size:13px">Independent variables.</p>

      <figcaption>
        <a href="#linear_shap_ex" class="figure-number">3</a>: Comparing two versions of SHAP values: conditional expectation (CE) and interventional conditional expectation (ICE).  We make two simplifying assumptions:

        <ul align="left" style="margin-top:0px;margin-bottom:0px;line-height:0.2em;padding-top:0.2em;padding-bottom:0.2em;">
          <li style="margin-top:0px;margin-bottom:0px;line-height:0.2em;padding-top:0.2em;padding-bottom:0.2em;">The function is linear (\(f=\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4\))</li>
          <li style="margin-top:0px;margin-bottom:0px;line-height:0.2em;padding-top:0.2em;padding-bottom:0.2em;">The data-generating distribution is multivariate normal (\(D\sim \mathcal{N}_4(0,C)\))</li>
        </ul>
      </figcaption>
    </figure>


  <p>
    In <a href="#example2">Example 2</a> we highlight tradeoffs between the conditional expectation and the interventional conditional expectation by devising a simple example with a linear function and a multivariate normally distributed background distribution.  In general, computing the conditional expectation SHAP value is difficult; however, because we choose a multivariate normal distribution the conditional expectation is well defined.  In addition, we choose a linear function because the conditional expectation of the function equals the function applied to the conditional expectation.
  </p>


	<!-- Proof -->
	<div">
		<p><a onclick="hideshow('proof_linearmodel')"><strong>+ Technical details</strong></a></p>

		<div id="proof_linearmodel", style="display:none">
	    <p>
	    	Computing SHAP values for a linear model is much easier than for other model classes.  This is how we compute them for <a href="#example2">Example 2</a>.
	    </p>

	    <p>
	    	First, to compute Interventional Conditional Expectation (ICE) SHAP values for a linear model, we can start with:
  			$$
  			\begin{aligned}
  			\phi_i(f,x)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(x)|do(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[f(x)|do(x_{S})])\\
  			&=\sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[\beta x|do(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[\beta x|do(x_{S})])\\
  			&=\sum_{S\in C } W(|S|,|N|) \beta (\mathbb{E}_{D}[x|do(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[x|do(x_{S})])\\
  			&=\sum_{S\in C } W(|S|,|N|) \beta (h^{S\cup \{i\}} {-} h^S)\\ 
  			&=\sum_{S\in C } W(|S|,|N|) \beta_i x^f_i\\ 
  			&= \beta_i x^f_i\\ 
  			\end{aligned}
        $$
		</p>

	    <p>
	    	Second, to compute Conditional Expectation (CE) SHAP values for a linear model, we assume the background distribution \(D\) is multivariate normal with zero mean and covariance \(C\), we can start with:
  			$$
  			\begin{aligned}
  			\phi_i(f,x)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(x)|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[f(x)|x_{S}])\\
  			&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[\beta x|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[\beta x|x_{S}])\\
  			&= \sum_{S\in C } W(|S|,|N|)\beta (\mathbb{E}_{D}[x|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[x|x_{S}])\\
  			\end{aligned}
  			$$
  			Here, we know that \(\mathbb{E}_{D}[x|x_{S}])=C_{N\setminus S,S} C_{S,S}^{-1} x_{S}\).
		  </p>
    </div>

	</div>

    <!-- Background distribution -->
    <h3 id="background_distribution">1.3 Single reference SHAP values</h3>

	<p>
		As we saw earlier, to compute \(\phi_i(f,x^f)\) we evaluate the interventional conditional expectation.  However, this depends on a <i>background distribution</i> \(D\) that the sample we are explaining, otherwise known as the foreground sample \(x^f\), will be compared to.  
	</p>

	<p>
		One natural definition of the background distribution is a uniform distribution over a population sample.  For instance, in machine learning, you could assign equal probability to every sample in your training set.  With this background distribution, we can re-write the SHAP value as an average of <i>single reference SHAP values</i> <d-cite bibtex-key="chen2019explaining"></d-cite>:
		$$
		\phi_i(f,x^f)=\frac{1}{|D|}\sum_{x^b\in D}\phi_i(f,x^f,x^b)
		$$
		This is in part because the interventional conditional expectation has a very natural definition when the background distribution is a single sample \(x^b\) (\(D_{x^b}\)):
		$$
		\mathbb{E}_{D_{x^b}}[f(x^f)|\text{do}(x_{S})]=h^S
		$$
		Where \(h^S\in\mathbb{R}^d\) with \(h^S_i=x^f_i\) if \(i\in S\) otherwise \(h^S_i=x^b_i\).  In words, the interventional conditional expectation of \(x^f\) given a set of features \(S\) and \(x^b\) is a hybrid sample where the features in \(S\) are from \(x^f\) and the remaining features are from \(x^b\).  This is as if <i>we intervene on features in the foreground sample with features from the background sample</i>. 
	</p>  

	<!-- Background Distribution Proof -->
	<div">
		<p><a onclick="hideshow('proof_backgrounddist')"><strong>+ Technical details</strong></a></p>

		<div id="proof_backgrounddist", style="display:none">

		    <p>
			    Define \(C\) to be all combinations of the set \(N \setminus \{i\}\) and \(P\) to be all permutations of \(N \setminus \{i\}\).  Starting with the definition of SHAP values: 
				$$
				\begin{aligned}
				\phi_i(f,x^f)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(x^f)|\text{do}(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[f(x^f)|\text{do}(x_{S})])\\
				&=\frac{1}{|P|}\sum_{S\subseteq P} \mathbb{E}_D[f(x^f)|\text{do}(x_{S \cup \{i\}})] {-} \mathbb{E}_D[f(x^f)|\text{do}(x_{S})]\\
				&= \frac{1}{|P|}\sum_{S\subseteq P}\frac{1}{|D|}\sum_{x^b\in D} f(h^{S\cup \{i\}}) {-} f(h^{S})\\
				&= \frac{1}{|D|}\sum_{x^b\in D} \frac{1}{|P|}\sum_{S\subseteq P} f(h^{S\cup \{i\}}) {-} f(h^{S})\\
				&= \frac{1}{|D|}\sum_{x^b\in D} \underbrace{\sum_{S\subseteq C} W(|S|,|N|)f(h^{S\cup \{i\}}) {-} f(h^{S})}_{\text{Single reference SHAP value}}\\
				&=\frac{1}{|D|}\sum_{x^b\in D}\phi_i(f,x^f,x^b)
				\end{aligned}
				$$
			</p>

		</div>
	</div>

	<p>
		In summary, we reduce the problem of obtaining \(\phi_i(f,x^f)\) to an average of simpler problems \(\phi_i(f,x^f,x^b)\) where our foreground sample \(x^f\) is compared to a distribution with only one background sample \(x^b\).  This new problem formulation will prove to be an easy problem to tackle for tree models.
	</p>

  </div>

  <hr>


  <!-- The Algorithm Section -->
  <div style="max-width:800px">
    <h2 id="algorithm">2. Algorithm</h2>
    
    <p>
    Now our goal is to tackle the simpler problem of obtaining single reference SHAP values \(\phi_i(f,x^f,x^b)\) that are attributions for a single foreground (sample being explained) and background sample (sample being compared to).  In this section, we consider a specific foreground sample, background sample, and tree as specified in <a href="#example3">Example 3</a>.
	</p>

	<figure>
		<p align=center style="font-size:15px;">
			Tree Parameters <d-footnote>Green links indicate the foreground sample goes down a particular split, red indicates the background sample does, and blue indicates both samples do.</d-footnote> (Click nodes)</strong> <br>
		</p>

    <!-- The SVG tree itself -->
    <div align=center style="margin-bottom: -45px">
  	  <div id="graphic"></div> 
  	  <div class="tooltip" id="tooltip"></div>
    </div>

    <!-- Select variable/threshold -->
    <div align=center style="margin-bottom: 20px">
      <span id="ex3_var_label" style="font-size: 15px">Node Variable:</span>
      <input type="button" value="x1" class="w3-button w3-teal" id="ex3_x1_select" onclick="ex3_select_feat1()" style="font-size: 15px">
      <input type="button" value="x2" class="w3-button w3-green" id="ex3_x2_select" onclick="ex3_select_feat2()" style="font-size: 15px">
      <input type="button" value="x3" class="w3-button w3-green" id="ex3_x3_select" onclick="ex3_select_feat3()" style="font-size: 15px">
    </div>

    <div id="ex3_thres_div" align=center style="margin-bottom: 20px">
      <span style="font-size: 15px">Node Threshold:</span>
      <input type="range" min="-15" max="15" value="5" class="slider" id="ex3_thres" style="width: 130px;">
      <span style="font-size: 15px;width: 20px;display: inline-block;" id="ex3_thres_out">5</span>
    </div>

    <div id="ex3_val_div" align=center style="margin-bottom: 20px;display: none;">
      <span style="font-size: 15px">Leaf Value:</span>
      <input type="range" min="-15" max="15" value="5" class="slider" id="ex3_val" style="width: 130px;">
      <span style="font-size: 15px;width: 20px;display: inline-block;" id="ex3_val_out">5</span>
    </div>

    <!-- Foreground and background samples -->
    <div align=center style="margin-bottom: 10px;">
      <table style="width:500px;display:inline;border:none;">
        <col width="100px"/>
        <col width="150px"/>
        <col width="50px"/>
        <col width="150px"/>
        <col width="50px"/>
        <tr>
          <td>Variable</td>
          <td colspan="2">Foreground Sample \(x^f\)</td>
          <td colspan="2">Background Sample \(x^b\)</td>
        </tr>
        <tr>
          <td>\(x_1\)</td>
          <td><input type="range" min="-15" max="15" value="0" class="slider" id="fx1"></td>
          <td align="left" id="fx1_out"></td>
          <td><input type="range" min="-15" max="15" value="10" class="slider" id="bx1"></td>
          <td align="left" id="bx1_out"></td>
        </tr>
        <tr>
          <td>\(x_2\)</td>
          <td><input type="range" min="-15" max="15" value="0" class="slider" id="fx2"></td>
          <td align="left" id="fx2_out"></td>
          <td><input type="range" min="-15" max="15" value="10" class="slider" id="bx2"></td>
          <td align="left" id="bx2_out"></td>
        </tr>
        <tr>
          <td>\(x_3\)</td>
          <td><input type="range" min="-15" max="15" value="10" class="slider" id="fx3"></td>
          <td align="left" id="fx3_out"></td>
          <td><input type="range" min="-15" max="15" value="0" class="slider" id="bx3"></td>
          <td align="left" id="bx3_out"></td>
        </tr>
      </table>
    </div>


    <div align=center style="margin-bottom: 10px">
      <input type="button" value="Reset" class="w3-button w3-green" onclick="ex3_reset()">
    </div>

    <figcaption>
      <a href="#shapley_value_ex" class="figure-number">4</a>: Choose foreground sample \(x^f\), background sample \(x^b\), and tree parameters for the remainder of <a href="#algorithm">Section 2</a>.
    </figcaption>

	</figure>

    <!-- Brute force -->
    <h3 id="brute_force">2.1 Brute force</h3>

    <p>
    	Based on the proof in <a href="#background_distribution">Section 1.3</a>, the brute force approach would be to compute the following:

    	$$
    	\phi_i(f,x^f,x^b)=\sum_{S\subseteq N\setminus\{i\}} \underbrace{W(|S|,|N|)}_{W}\underbrace{f(h^{S\cup \{i\}})}_{\text{\textcolor{green}{Pos} term}} {-} \underbrace{f(h^S)}_{\text{\textcolor{red}{Neg} term}})
    	$$
    </p>

    <p>
    	If we assume the computational cost of computing the weight \(W\) is constant, then the complexity of the brute force method is the number of terms in the summation multiplied by the cost of making a prediction (on the order of the depth of the tree \((D)\)).  Then, the computational complexity of the brute force approach is \(O(D\times2^{d})\).
    </p>

    <p>
    	In order to compute \(\phi_i(f,x^f,x^b)\) for all features, we have to re-run the entire algorithm \(d\) times, giving us a complexity of \(O(d\times D\times 2^{d})\).
	</p>


  <div id="table_container" style="overflow-x:auto;align:center;">
  	<p align="left" style="margin:20px">
		<strong>Example 4</strong>: Brute force algorithm for the tree and samples specified in Example 3.
    </p>
	</div>

  <!-- <div id="table_container" style="overflow-x:auto;align:center"> -->
  <figure class="l-page">
  <div class="container">

    <div class="first" style="width:460px;height:300px">
    	<p style="margin: 0px 0px 0px 20px;"><strong>Tree Parameters</strong></p>
    	<div id="ex4_divtree" style="margin-top:10px;"></div>
    </div>


    <div class="second" style="width:300px;height:300px">
    	<p style="margin: 0px 0px 0px -100px;"><strong>Foreground & background sample</strong></p>
		<table cellpadding="10" style="margin: 10px 0px 0px -10px">
			<col width="40px"/>
			<col width="50px"/>
			<col width="50px"/>
			<tr>
				<th></th>
				<th>\(x_1\)</th>
				<th>\(x_2\)</th>
				<th>\(x_3\)</th>
			</tr>
			<tr>
				<td>\(x^f\)</td>
				<td id="ex4_fx1">0</td>
				<td id="ex4_fx2">0</td>
				<td id="ex4_fx3">10</td>
			</tr>
			<tr>
				<td>\(x^b\)</td>
				<td id="ex4_bx1">10</td>
				<td id="ex4_bx2">10</td>
				<td id="ex4_bx3">0</td>
			</tr>
			<tr id="ex4_hS">
				<td>\(h^S\)</td>
				<td id="ex4_hs1"></td>
				<td id="ex4_hs2"></td>
				<td id="ex4_hs3"></td>
			</tr>
			<tr id="ex4_hSi">
				<td>\(h^{S\cup i}\)</td>
				<td id="ex4_hsi1"></td>
				<td id="ex4_hsi2"></td>
				<td id="ex4_hsi3"></td>
			</tr>
		</table>
    </div>

    <div class="clear"></div>
    <div class="container">
    	<div class="first" style="width:460px;height:280px">
		<p style="margin: 0px 0px 0px 20px;"><strong>Brute Force Values</strong></p>
    		<table cellpadding="10" style="margin: 10px 0px 0px 90px">
	      <col width="40px"/>
	      <col width="50px"/>
	      <col width="50px"/>
	      <col width="60px"/>
	      <col width="60px"/>
		<thead>
			<tr>
				<th>\(W\)</th>
				<th>\(S\)</th>
				<th id="ex4_fxS">\(f(x_S)\)</th>
				<th>\(S\cup{i}\)</th>
				<th id="ex4_fxSi">\(f(x_{S\cup{i}})\)</th>
			</tr>
		</thead>
		<tbody>
			<tr id="ex4_s1_row">
				<td>1/3</td>
				<td id="s1"></td>
				<td id="s1_val"></td>
				<td id="s1i"></td>
				<td id="s1i_val"></td>
			</tr>
			<tr id="ex4_s2_row">
				<td>1/6</td>
				<td id="s2"></td>
				<td id="s2_val"></td>
				<td id="s2i"></td>
				<td id="s2i_val"></td>
			</tr>
			<tr id="ex4_s3_row">
				<td>1/6</td>
				<td id="s3"></td>
				<td id="s3_val"></td>
				<td id="s3i"></td>
				<td id="s3i_val"></td>
			</tr>
			<tr id="ex4_s4_row">
				<td>1/3</td>
				<td id="s4"></td>
				<td id="s4_val"></td>
				<td id="s4i"></td>
				<td id="s4i_val"></td>
			</tr>
		</tbody>
		</table>
    	</div>

    	<div class="second" style="width:300px;height:280px">
    	<p style="margin: 0px 0px 0px -110px;"><strong>Attribution Values</strong></p>

		<table cellpadding="10" style="margin: 10px 0px 0px -10px">
	      <col width="60px"/>
	      <col width="80px"/>
			<thead>
			<!-- <tr style="background-color:#8BC34A;"> -->
			<tr id="ex4_phi1">
				<td>\(\phi_1(f,x^f,x^b)\)</td>
				<td id="ex4_phi1_val">0</td>
			</tr>
			<tr id="ex4_phi2">
				<td>\(\phi_2(f,x^f,x^b)\)</td>
				<td id="ex4_phi2_val">0</td>
			</tr>
			<tr id="ex4_phi3">
				<td>\(\phi_3(f,x^f,x^b)\)</td>
				<td id="ex4_phi3_val">0</td>
			</tr>
		</thead>
		</table>
    	</div>
    </div>
    <input type="button" class="w3-button w3-green" value="<<" onclick="ex4_reset()">
    <input type="button" class="w3-button w3-green" value=">" onclick="bruteForceStep()">
    <input type="button" class="w3-button w3-green" value=">>" onclick="bruteForceRunAll()">
    <br><br>
    <div class="clear"></div>
  </div>
  </figure>


	<p>
	    However, if we <i>constrain \(f(x)\) to be a tree-based model</i> (e.g., XGBoost, decision trees, random forests, etc.), then we can come up with a polynomial time algorithm to compute \(\phi_i(f,x^f,x^b)\) exactly.  Why is this the case?  Well, looking at Example 4, we can see that even for explaining a single feature, the brute force algorithm may consider a particular path multiple times.  However, to compute the SHAP value for a single feature, it turns out that we only need to consider each path once.  This insight leads us to the naive algorithm in <a href="#naive_implementation">Section 2.2</a>.
	</p>


    <!--                      -->
    <!-- Naive Implementation -->
    <!--                      -->

    <h3 id="naive_implementation">2.2 Naive Implementation</h3>

	<p>
		Before we get into the algorithm, we first describe a theorem that is the basis for this naive implementation.
	</p>    

	<p>
    	<strong>Theorem 1: To calculate \(\phi_i(f,x,x^b)\), we can calculate attributions for each path from the root to each leaf.</strong>  For a given path \(P\), we define \(N_P\) to be the "unique" features encountered and \(S_P\) to be the "unique" features that came from \(x\).  Finally, define \(v\) to be the value of the path's leaf.  Then, the attribution of the path is:

    	$$
		\phi_i^P(f,x,x^b)=
	    \begin{cases}
	    	0 & \text{if}\ i\notin N_P \\
	    	\textcolor{green}{W(|S_P|-1,|N_P|)\times v} & \text{if}\ i\in S_P \\
	    	\textcolor{red}{-W(|S_P|,|N_P|)\times v} & \text{o.w.}
	    \end{cases}
    	$$

	</p>

	<!-- Proof -->
	<div style="background-color:aliceblue;">

		<div style="padding-left:10px;padding-right:10px">

			<p><a onclick="hideshow('proof')"><strong>Theorem 1 Sketch of Proof (Click)</strong></a></p>

			<div id="proof", style="display:none">

				<p>
					If we treat each path in the tree from the root to the leaf as a separate model \(f'(x)\) that returns the value of the leaf if that path is traversed by \(x\) or zero otherwise, then we have \(L\) models that operate on disjoint parts of the input space.  Then, \(f(x)=\sum f'(x)\) and by the additivity of SHAP values, \(\phi_i(f,x,x^b)=\sum_f\phi_i(f',x,x^b)\).  Then, we can simply calculate \(\phi_i\) for each path model.  Since the path model is zero everywhere except for the associated path, it is easy to arrive to the solution in Theorem 1.
				</p>

			</div>
		</div>

	</div>

	<p>
		Then the goal of the algorithm is to obtain \(N_P\) and \(S_P\) for each path by recursively traversing the tree.  We will start by explaining the algorithm via an example:
	</p>

	<figure>
		<figcaption>Figure 3: Green paths are associated with \(\textcolor{green}{x^f}\), red paths are \(\textcolor{red}{x^b}\), and blue paths are associated with both.</figcaption>
    <br>
		<img src="images/tree_example3.png" alt="Tree Example 3" style="width: 360px;">
	</figure>

	<p>
		In the naive algorithm, we maintain lists \(N_P\) and \(S_P\) as we traverse the tree.  At each internal node (Cases 2-4) we update the lists and then pass them to the node's children.  At the leaf nodes (Case 1), we calculate the attribution for each path.  In Figure 3, we see four possible cases:
		<ul>
			<li>Case 1: \(n\) is a leaf</li>
			<ul>
				<li>Return the attribution in Theorem 1 based on \(N_P\) and \(S_P\)</li>
			</ul>

			<li>Case 2: The feature has been encountered already (\(n_{feature}\in N_P\))</li>
			<ul>
				<li>Depending on if we split on \(x^f\) or \(x^b\), we compare either \(x^f_{n_{feature}}\) or \(x^b_{n_{feature}}\) to \(n_{threshold}\) and go down the appropriate child</li>
				<li>Pass down \(N_P\) and \(S_P\) without modifications because we did not add a new feature</li>
			</ul>

			<li>Case 3: Both \(x\) and \(x^b\) are on the same side of \(n\)'s split</li>
			<ul>
				<li>Pass down \(N_P\) and \(S_P\) without modifications because relative to \(x\) and \(x^b\) it's as if this node doesn't exist</li>
			</ul>

			<li>Case 4: \(x\) and \(x^b\) go to different children</li>
			<ul>
				<li>Add \(n_{feature}\) to both \(N_P\) and \(S_P\) and pass both lists to the \(x\) child</li>
				<li>Only add \(n_{feature}\) to \(N_P\) and pass both lists to the \(x^b\) child</li>
			</ul>
		</ul>
	</p>


    <div id="table_container" style="overflow-x:auto;align:center;">
    	<p align="left" style="margin:20px">
			<strong>Example 5</strong>: Naive algorithm for the tree and samples from Example 3.
		</p>
	</div>

    <div id="table_container" style="overflow-x:auto;align:center">
    	<p style="margin: 0px 0px 0px 20px;"><strong>Tree Parameters</strong></p>
    	<div id="ex5_divtree" style="margin-top:10px;"></div>
    </div>

    <div id="table_container" style="overflow-x:auto;align:center">
    	<div class="container">

    	<div class="first" style="width:300px;height:220px">
			<p style="margin: 0px 0px 0px 30px;"><strong>Foreground & background sample</strong></p>
			<table cellpadding="10" style="margin: 10px 0px 0px 60px">
			<col width="40px"/>
			<col width="50px"/>
			<col width="50px"/>
			<tr>
				<th></th>
				<th>\(x_1\)</th>
				<th>\(x_2\)</th>
				<th>\(x_3\)</th>
			</tr>
			<tr>
				<td>\(x^f\)</td>
				<td id="ex5_fx1">0</td>
				<td id="ex5_fx2">0</td>
				<td id="ex5_fx3">10</td>
			</tr>
			<tr>
				<td>\(x^b\)</td>
				<td id="ex5_bx1">10</td>
				<td id="ex5_bx2">10</td>
				<td id="ex5_bx3">0</td>
			</tr>
			<tr id="ex5_h">
				<td>\(h\)</td>
				<td id="ex5_h1"></td>
				<td id="ex5_h2"></td>
				<td id="ex5_h3"></td>
			</tr>
			</table>
		</div>

    	<div class="first" style="width:250px;height:220px">
	    	<p style="margin: 0px 0px 0px 30px;"><strong>Algorithm state</strong></p>
			<table cellpadding="10" style="margin: 10px 0px 0px 80px">
				<col width="40px"/>
				<col width="80px"/>
				<tr>
					<td>\(S_P\)</td>
					<td id="ex5_sp"></td>
				</tr>
				<tr>
					<td>\(N_P\)</td>
					<td id="ex5_np"></td>
				</tr>
			</table>
    	</div>


    	<div class="first" style="width:210px;height:220px">
	    	<p style="margin: 0px 0px 0px 10px;"><strong>Attribution Values</strong></p>

			<table cellpadding="10" style="margin: 10px 0px 0px 10px">
		      <col width="60px"/>
		      <col width="80px"/>
				<thead>
				<!-- <tr style="background-color:#8BC34A;"> -->
				<tr id="ex5_phi1">
					<td>\(\phi_1(f,x^f,x^b)\)</td>
					<td id="ex5_phi1_val"></td>
				</tr>
				<tr id="ex5_phi2">
					<td>\(\phi_2(f,x^f,x^b)\)</td>
					<td id="ex5_phi2_val"></td>
				</tr>
				<tr id="ex5_phi3">
					<td>\(\phi_3(f,x^f,x^b)\)</td>
					<td id="ex5_phi3_val"></td>
				</tr>
			</thead>
			</table>
    	</div>

	    <div class="clear"></div>
		</div>


    	<input type="button" class="w3-button w3-green" value="<<" onclick="ex5_reset()">
    	<input type="button" class="w3-button w3-green" value=">" onclick="naiveStep()">
    	<input type="button" class="w3-button w3-green" value=">>" onclick="naiveRunAll()">

    	<br><br>

		<p style="margin: 0px 0px 20px 0px;" id="ex5_naive_step">Naive algorithm</p>

	</div>


	<!-- Pseudocode -->
	<div style="background-color:#e6ffee;">

		<div style="padding-left:10px;padding-right:10px">

			<p><a onclick="hideshow('pseudocode_naive')"><strong>Naive Pseudocode (Click)</strong></a></a></p>

			<div id="pseudocode_naive" style="display:none">
			<p class="no-margin" style="font-family:courier;font-size:16px">
				ITE_N(array \(x^f\), array \(x^b\), tree \(T\)):
			</p>

			<ul class="no-margin" style="font-family:courier;font-size:16px">
				RECURSE(node \(n\), list \(S_P\), list \(N_P\), array \(x^f\), array \(x^b\)):
				<ul style="font-size:16px">
					<font color="#8E44AD">// Case 1: At a leaf</font><br>
					if n is a leaf:
					<ul style="font-size:16px">
						return \(\phi_i^P(f,x^f,x^b)\) based on \(S_P\) and \(N_P\) (Theorem 1)
					</ul>
					<font color="#8E44AD">// Find children associated with \(x\) and \(x^b\)</font><br>
					\(x^f_{child} =\) \(n_{leftchild}\) if \(x^f[n_{feature}] < n_{threshold}\) else \(x^f_{child}\) = \(n_{rightchild}\) <br>
					\(x^b_{child} =\) \(n_{leftchild}\) if \(x^b[n_{feature}] < n_{threshold}\) else \(x^b_{child}\) = \(n_{rightchild}\) <br>
					<font color="#8E44AD">// Case 2: Feature was encountered previously</font><br>
					if \(n_{feature}\in N_P\):
					<ul style="font-size:16px">
						if \(n_{feature}\in S_P\):
						<ul style="font-size:16px">
							return ITE_N(\(x^f_{child}\),\(S_P\),\(N_P\),\(x^f\),\(x^b\))
						</ul>
						else: 
						<ul style="font-size:16px">
							return ITE_N(\(x^b_{child}\),\(S_P\),\(N_P\),\(x^f\),\(x^b\))
						</ul>
					</ul>

					<font color="#8E44AD">// Case 3: \(x^f\) and \(x^b\) go to same children</font><br>
					if \(x^f_{child}==x^b_{child}\):
					<ul style="font-size:16px">
						return ITE_N(\(x^f_{child}\),\(S_P\),\(N_P\),\(x\),\(x^b\))
					</ul>
					<font color="#8E44AD">// Case 4: \(x^f\) and \(x^b\) go to different children</font><br>
					if not \(x^f_{child}==x^b_{child}\):
					<ul style="font-size:16px">
						return ITE_N(\(x^b_{child}\),\(S_P\),\(N_P+[n_{feature}]\),\(x^f\),\(x^b\)) + <br> ITE_N(\(x^f_{child}\),\(S_P+[n_{feature}]\),\(N_P+[n_{feature}]\),\(x^f\),\(x^b\))
					</ul>
				</ul>
				return RECURSE(\(T_{rootnode}\), \(S_P=[\ ]\), \(N_P=[\ ]\), \(x^f\), \(x^b\))
			</ul>
			</div>

		</div>

	</div>

    <p>
		The computational complexity to compute the single reference SHAP value using the naive algorithm is \(O(T_{numnodes}\times T_{depth})\) where \(T_{numnodes}\) is the number of nodes in the tree and \(T_{depth}\) is the depth of the tree.  This is because in the worst case, each internal node needs to check the lists \(S_P\) and \(N_P\) which are of length \(O(T_{depth})\).  Furthermore, each leaf node needs to check if \(i\) is in \(S_P\) which is also \(O(T_{depth})\) cost.  Note that we can actually get rid of the multiplicative \(T_{depth}\) factor by representing \(S_P\) and \(N_P\) as arrays and keeping track of the sizes of \(|S|\) and \(|N|\).
	</p>

	<p>
		Finally, getting the attributions for all features means that we will have to repeat the above algorithm \(|N|\) times.  In the next section we present a dynamic programming approach that allows us to compute the attributions for all features simultaneously.
	</p>

    <!-- Dynamic Programming -->
    <h3 id="dynamic_programming_implementation">2.3 Dynamic Programming Implementation</h3>

    <p>
	    For the dynamic programming version of the algorithm, we can compute the attributions for all features simultaneously as we traverse the tree by passing \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) attributions to parent nodes.  Before describing the algorithm in more detail, we first present an figure that illustrates why passing up the attributions is sufficient.
	</p>

	<div id="table_container" style="overflow-x:auto;">

		<figure style="float:left">
			<figcaption>Figure 4: Example to illustrate collapsibility for features.  Green paths are associated with \(\textcolor{green}{x}\) and red paths are \(\textcolor{red}{x^b}\)</figcaption>
      <br>
			<img src="images/tree_example4.png" alt="Tree Example 3" style="width: 220px;">
		</figure>

		<table cellpadding="10" align="center">
			<tr bgcolor="#F8F8F8">
				<td align="left">\(\phi_1(f,x^f,x^b)\)</td>
				<td align="left">\(\textcolor{green}{\text{Pos}_1}+\textcolor{green}{\text{Pos}_2}+\textcolor{red}{\text{Neg}_3}+\textcolor{red}{\text{Neg}_4}\)</td>
			</tr>
			<tr bgcolor="#F8F8F8">
				<td align="left">\(\phi_2(f,x^f,x^b)\)</td>
				<td align="left">\(\textcolor{red}{\text{Neg}_1}+\textcolor{green}{\text{Pos}_2}+\textcolor{green}{\text{Pos}_3}+\textcolor{red}{\text{Neg}_4}\)</td>
			</tr>
		</table>
	</div>



	<p>
		In Figure 4, we can first observe that for each leaf, according to Theorem 1, there are only two possible values needed to compute the SHAP values (\(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\)).  Based on the attributions for \(x_1\) we see that these \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms can be grouped by the left and right subtrees below \(x_1\).  To generalize this example, we make the following observation:
	</p>

	<p>
		<strong>Observation:  In order to compute the attribution for any feature \(i\) it is sufficient to consider the paths that correspond to each Case 4 node's children.</strong>  First, focusing on a specific Case 4 node \(n\), we know that one child is associated with \(x^f\) child and one child is associated with \(x^b\).  Then, the attribution to \(n\)'s feature is:
		$$
		\sum_{\text{paths }P\text{ under }x\text{ child}}\textcolor{green}{\text{Pos}_P} + \sum_{\text{paths }P\text{ under }x^b\text{ child}}\textcolor{red}{\text{Neg}_P}
		$$

		Then, doing this for all nodes is equivalent to explaining all features (because SHAP values are additive).
	</p>

	<p>
		Furthermore, this observation suggests that we can always add the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms at a given node and pass them up to the parent.  This information is sufficient to calculate the attributions for each upstream feature.  This aggregation of the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms is the dynamic programming observation that allows each upstream node to only need a constant number of operations to compute its feature's attribution.
	</p>

	<p>
		Using this observation, we devise an algorithm that computes the attributions for all features simultaneously:
	</p>

    <div id="table_container" style="overflow-x:auto;align:center;">
    	<p id="example6" align="left" style="margin:20px">
			<strong>Example 6</strong>: DP algorithm for the tree and samples from Example 3.
		</p>
	</div>

    <div id="table_container" style="overflow-x:auto;align:center">
    	<p style="margin: 0px 0px 0px 20px;"><strong>Tree Parameters</strong></p>
    	<div id="ex6_divtree" style="margin-top:10px;"></div>
    </div>

    <div id="table_container" style="overflow-x:auto;align:center">
    	<div class="container">

    	<div class="first" style="width:300px;height:220px">
			<p style="margin: 0px 0px 0px 30px;"><strong>Foreground & background sample</strong></p>
			<table cellpadding="10" style="margin: 10px 0px 0px 60px">
			<col width="40px"/>
			<col width="50px"/>
			<col width="50px"/>
			<tr>
				<th></th>
				<th>\(x_1\)</th>
				<th>\(x_2\)</th>
				<th>\(x_3\)</th>
			</tr>
			<tr>
				<td>\(x^f\)</td>
				<td id="ex6_fx1">0</td>
				<td id="ex6_fx2">0</td>
				<td id="ex6_fx3">10</td>
			</tr>
			<tr>
				<td>\(x^b\)</td>
				<td id="ex6_bx1">10</td>
				<td id="ex6_bx2">10</td>
				<td id="ex6_bx3">0</td>
			</tr>
			<tr id="ex6_h">
				<td>\(h\)</td>
				<td id="ex6_h1"></td>
				<td id="ex6_h2"></td>
				<td id="ex6_h3"></td>
			</tr>
			</table>
		</div>

    	<div class="first" style="width:250px;height:220px">
	    	<p style="margin: 0px 0px 0px 30px;"><strong>Algorithm state</strong></p>
			<table cellpadding="10" style="margin: 10px 0px 0px 80px">
				<col width="40px"/>
				<col width="80px"/>
				<tr>
					<td>\(S_C\)</td>
					<td id="ex6_sc"></td>
				</tr>
				<tr>
					<td>\(N_C\)</td>
					<td id="ex6_nc"></td>
				</tr>
			</table>
    	</div>


    	<div class="first" style="width:210px;height:220px">
	    	<p style="margin: 0px 0px 0px 10px;"><strong>Attribution Values</strong></p>

			<table cellpadding="10" style="margin: 10px 0px 0px 10px">
		      <col width="60px"/>
		      <col width="80px"/>
				<thead>
				<!-- <tr style="background-color:#8BC34A;"> -->
				<tr id="ex6_phi1">
					<td>\(\phi_1(f,x^f,x^b)\)</td>
					<td id="ex6_phi1_val"></td>
				</tr>
				<tr id="ex6_phi2">
					<td>\(\phi_2(f,x^f,x^b)\)</td>
					<td id="ex6_phi2_val"></td>
				</tr>
				<tr id="ex6_phi3">
					<td>\(\phi_3(f,x^f,x^b)\)</td>
					<td id="ex6_phi3_val"></td>
				</tr>
			</thead>
			</table>
    	</div>

	    <div class="clear"></div>
		</div>


    	<input type="button" class="w3-button w3-green" value="<<" onclick="ex6_reset()">
    	<input type="button" class="w3-button w3-green" value=">" onclick="dynamicStep()">
    	<input type="button" class="w3-button w3-green" value=">>" onclick="dynamicRunAll()">

    	<br><br>

		<p style="margin: 0px 0px 20px 0px;" id="ex6_dynamic_step">Dynamic algorithm</p>

	</div>


	<!-- Pseudocode -->
	<div style="background-color:#e6ffee;">

		<div style="padding-left:10px;padding-right:10px">

			<p><a onclick="hideshow('pseudocode_dynamic')"><strong>DP Pseudocode (Click)</strong></a></a></p>

			<!-- <div id="pseudocode_dynamic", style="display:none"> -->
			<div id="pseudocode_dynamic" style="display:none">
			<p class="no-margin">
				ITE_D(tree \(t\), array \(x^f\), array \(x^b\)):
			</p>
			<ul class="no-margin">
				\(\phi=\) [0]*\(len(x)\) <br>

				RECURSE(node \(n\), int \(S^c\), int \(N^c\), array \(x^f_a\), array \(x^b_a\)):
				<ul style="font-family:courier;font-size:16px">
					<font color="#8E44AD">// Case 1: At a leaf</font><br>
					if \(n\) is a leaf:
					<ul style="font-family:courier;font-size:16px">
						if \(U==0\): return (0,0)<br>
						else: return (\(W(S^c,N-1)\times n_{value}\),\(-W(S^c,N^c)\times n_{value}\))
					</ul>
					<font color="#8E44AD">// Find children associated with \(x^f\) and \(x^b\)</font><br>
					\(x^f_{child} =\) \(n_{leftchild}\) if \(x[n_{feature}] < n_{threshold}\) else \(x^f_{child}\) = \(n_{rightchild}\) <br>
					\(x^b_{child} =\) \(n_{leftchild}\) if \(x^b[n_{feature}] < n_{threshold}\) else \(x^b_{child}\) = \(n_{rightchild}\) <br>
					<font color="#8E44AD">// Case 2: Feature was encountered previously</font><br>
					if \(x_a[n_{feature}]>0\):
					<ul style="font-size:16px">
						return RECURSE(\(x^f_{child}\),\(S^c\),\(N^c\),\(x^f_a\),\(x^b_a\))
					</ul>
					if \(x^b_a[n_{feature}]>0\):
					<ul style="font-size:16px">
						return RECURSE(\(x^b_{child}\),\(S^c\),\(N^c\),\(x^f_a\),\(x^b_a\))
					</ul>

					<font color="#8E44AD">// Case 3: \(x^f\) and \(x^b\) go to same children</font><br>
					if \(x^f_{child}==x^b_{child}\):
					<ul style="font-size:16px">
						return RECURSE(\(x^f_{child}\),\(S^c\),\(N^c\),\(x^f\),\(x^b\))
					</ul>
					<font color="#8E44AD">// Case 4: \(x^f\) and \(x^b\) go to different children</font><br>
					\(X_a =\) copy(\(x^f_a\)); \(X_a[n_{feature}]=X_a[n_{feature}]+1\)<br>
					\(x^b_a =\) copy(\(x^b_a\)); \(x^b_a[n_{feature}]=x^b_a[n_{feature}]+1\)<br>
					if not \(x^f_{child}==x^b_{child}\):
					<ul style="font-size:16px">
						\(pos_x,neg_x=\) RECURSE(\(x^f_{child}\),\(S^c+1\),\(N^c+1\),\(x^f_a\),\(x^b_a\))<br>
						\(pos_{x^b},neg_{x^b}=\) RECURSE(\(x^b_{child}\),\(S^c\),\(N^c+1\),\(x^f_a\),\(x^b_a\))<br>
						\(\phi[n_{feature}]=\phi[n_{feature}]+pos_{x}+neg_{x^b}\)<br>
						return (\(pox_{x}+pox_{x^b}\),\(neg_{x}+neg_{x^b}\))
					</ul>
				</ul>
				return RECURSE(tree.root, 0, 0, [0]*\(len(x)\), [0]*\(len(x)\))
			</ul> 
			</div>
		</div>
	</div>

    <p>
		The computational complexity to compute \(\phi_i(f,x,x^b)\) using the dynamic programming algorithm for all features is now just \(O(T_{numnodes})\) where \(T_{numnodes}\) is the number of nodes in the tree.  In <a href="#example6">Example 6</a> it is easy to see that each node now only requires a constant amount of work.  
	</p>

    <p>
		Finally, our original goal was to compute \(\phi_i(f,x)\).  We simply need to compute \(\phi_i(f,x,x^b)\) for many references, resulting in a run time of \(O(|D|T_{numnodes})\) where \(|D|\) is the number of samples in the background distribution.  In practice, using a fixed number of about 100 to 1000 references works well.
	</p>


  <hr>

    <h2 id="comparison_of_methods">Comparison of SHAP Methods</h3>

    <p>
    	It should be noted that there are a number of alternative methods that aim to approximate SHAP values: Path Dependent Tree Explainer, Kernel Explainer, and Sampling Explainer.  If you are explaining tree-based models, it may not be clear which one you should use.  In this article we briefly overview the methods and compare them to ITE:
	</p>

    <p>
    	<ul>
    		<li>Path Dependent Tree Explainer (PDTE): </li>
    		<ul>
    			<li>Like ITE, PDTE is also meant to obtain SHAP values for tree models.</li> 
				<li>PDTE approximates the interventional conditional expectation based on how many training samples went down paths in the tree, whereas ITE computes it exactly.</li>
				<li>The computational complexity is \(O(T_{numleaves}T_{depth}^2)\).  In practice, PDTE can be faster than ITE, although it may depend on the number of references or the tree depth.</li>
    		</ul>
    		<li>Sampling Explainer:</li>
    		<ul>
    			<li>A model agnostic approach to obtain SHAP values.</li>
    			<li>An extension of Interactions-based Method for Explanation (IME) <d-cite bibtex-key="kononenko2010efficient"></d-cite>.</li> 
    			<li>This approach is sampling based and converges to the SHAP values ITE obtains, but in practice is much slower than ITE.</li>
    		</ul>    		
    		<li>Kernel Explainer <d-cite bibtex-key="lundberg2017unified"></d-cite>:</li>
    		<ul>
    			<li>A model agnostic approach to obtain SHAP values.</li>
    			<li>An extension of Local Interpretable Model-agnostic Explanations (LIME) <d-cite bibtex-key="ribeiro2016should"></d-cite>.</li> 
    			<li>This approach is sampling based and converges to the SHAP values ITE obtains, but in practice is much slower than ITE.</li>
    		</ul>
    	</ul>
	</p>

    <p>
		For an in-depth empirical comparison of some of these methods, please refer to <d-cite bibtex-key="lundberg2020local"></d-cite>.
	</p>	

    <h2 id="references">Acknowledgements</h2>

    <p>This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1762114.  Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation.</p>

	</div>

  </div>

</div>


<!-- Figure 1 - Kaggle methods d3 bar plot -->
<script src="kaggleMethods.js"></script>

<!-- Example 1 - Computing Shapley values -->
<script src="shapleyValues.js"></script>

<!-- Example 2 - Computing Shapley values CES vs RBS -->
<script src="linearModelCESvsRBS.js"></script>

<!-- Example 3 - Initial tree parameters -->
<script src="treeData0.js"></script>

<!-- Example 3 - Creating tree and samples -->
<script src="createTreeSamples.js"></script>

<!-- Example 4 - Brute force algorithm -->
<script src="brute_force_ex.js"></script>

<!-- Example 5 - Naive tree algorithm -->
<script src="naive_ex.js"></script>

<!-- Example 6 - DP tree algorithm -->
<script src="dp_ex.js"></script>

<script>
function hideshow(type) {
    var x = document.getElementById(type);
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<d-appendix>
  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<d-bibliography src="bibliography.bib"></d-bibliography>


<script src="https://distill.pub/template.v2.js"></script>

</body>
</html>
