<!DOCTYPE html>
<html lang="en">
<title>Interventional Tree Explainer</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">

<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>
<script language="JavaScript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/3.2.1/math.js"></script>

<script src="https://d3js.org/d3.v4.min.js"></script>
<script>d3v4 = d3;</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js"></script>

<style>
hover a {
    color: "Olive";
}

.sidenav {
  height: 100%;
  width: 300px;
  position: fixed;
  z-index: 1;
  top: 0;
  left: 0;
  background-color: #111;
  overflow-x: hidden;
  padding-top: 20px;
}

.sidenav a {
  padding: 6px 8px 6px 16px;
  text-decoration: none;
  font-size: 25px;
  color: #818181;
  display: block;
}

.sidenav a:hover {
  color: #f1f1f1;
}

body {font-family: "Lato", sans-serif}
p {font-size: 20px}
ul {font-size: 20px}
caption {font-size: 18px}
figcaption {font-size: 18px}

.no-margin {
	margin:0px;
	font-family:courier;
	font-size:16px;
}

.responsive {
	width: 100%;
	height: auto;
}

/*Figure 1*/
.bar {
    fill: #4DAF51;
}

.bar:hover {
	fill: #019788;
}

.axis {
    font-size: 16px;
}

.axis path,
.axis line {
    fill: none;
    display: none;
    shape-rendering: crispEdges;
}

.label {
	color: #4DAF51;
    font-size: 16px;
}

/* Creates a small triangle extender for the tooltip */
.d3-tip:after {
  box-sizing: border-box;
  display: inline;
  font-size: 10px;
  width: 100%;
  line-height: 1;
  color: rgba(0, 0, 0, 0.8);
  content: "\25BC";
  position: absolute;
  text-align: center;
}

/* Style northward tooltips differently */
.d3-tip.n:after {
  margin: -1px 0 0 0;
  top: 100%;
  left: 0;
}

#table_container {
	margin: 0 auto;
	background-color : #F4F6F6;
}

/* Slider code */
.slidecontainer {
  width: 100%;
}

.slider {
  -webkit-appearance: none;
  width: 100%;
  height: 15px;
  border-radius: 5px;
  background: #d3d3d3;
  outline: none;
  opacity: 0.7;
  -webkit-transition: .2s;
  transition: opacity .2s;
}

.slider:hover {
  opacity: 1;
}

.slider::-webkit-slider-thumb {
  -webkit-appearance: none;
  appearance: none;
  width: 25px;
  height: 25px;
  border-radius: 50%;
  background: #4CAF50;
  cursor: pointer;
}

.slider::-moz-range-thumb {
  width: 25px;
  height: 25px;
  border-radius: 50%;
  background: #4CAF50;
  cursor: pointer;
}
/* End slider code */

/* D3 Trees*/
.node circle {
	fill: #fff;
	stroke: #ccc;
	stroke-width: 4px;
}

.node text { font: 12px sans-serif; }

.link {
	fill: none;
	/*stroke: #ccc;*/
	stroke-width: 3px;
}

div.tooltip {
	position: absolute;
}

.container {
	width: 760px;
	/*margin: auto;*/
}

.first {
	width: 380px;
	float: left;
	height: 630px;
	/*background-color: blue;*/
}

.second {
	width: 380px;
	float: left;
	height: 630px;
	/*background-color: green;*/
}

</style>
<body>


<div class="sidenav">
	<a href="#" class="w3-justify w3-button"><h3>Top</h3></a>
	<a href="#introduction" class="w3-justify w3-button"><h3>Introduction</h3></a>
		<a href="#motivation" class="w3-justify w3-button" style="margin-left:20px"><h5>Motivation</h5></a>
	<a href="#background" class="w3-justify w3-button"><h3>1. Background</h3></a>
		<a href="#shapley_values" class="w3-justify w3-button" style="margin-left:20px"><h5>1.1 Shapley values</h5></a>
		<a href="#shap_values" class="w3-justify w3-button" style="margin-left:20px"><h5>1.2 SHAP values</h5></a>
		<a href="#background_distribution" class="w3-justify w3-button" style="margin-left:20px"><h5>1.3 SHAP values with a <br>Background Distribution</h5></a>
	<a href="#algorithm" class="w3-justify w3-button"><h3>2. Algorithm</h3></a>
	  	<a href="#brute_force" class="w3-justify w3-button" style="margin-left:20px"><h5>2.1 Brute force <br>implementation</h5></a>
		<a href="#an_example" class="w3-justify w3-button" style="margin-left:20px"><h5>2.2 An example</h5></a>
		<a href="#naive_implementation" class="w3-justify w3-button" style="margin-left:20px"><h5>2.3 Naive implementation</h5></a>
		<a href="#dynamic_programming_implementation" class="w3-justify w3-button" style="margin-left:20px"><h5>2.4 Dynamic programming <br> implementation</h5></a>
		<a href="#comparison_of_methods" class="w3-justify w3-button" style="margin-left:20px"><h5>2.5 Comparison of SHAP <br> Methods</h5></a>
	<a href="#references" class="w3-justify w3-button"><h3>References</h3></a>
</div>

<!-- Page content -->
<div class="w3-content" style="max-width:2000px;margin-left:300px">
  <div class="w3-display-container w3-center">
    <img src="images/trees.jpg" style="width:100%">
    <div class="w3-display-bottommiddle w3-container w3-text-white w3-hide-small">
      <h2><strong>An Exact Linear Time Algorithm to <br>Compute Shapley values for Trees</strong></h2>
      <!-- <h2>Exact game-theoretic explanations of trees in linear time</h2> -->
      <h2>Hugh Chen</h2>
    </div>
  </div>

  <!-- Introduction -->
  <div class="w3-container w3-content w3-center w3-padding-16" style="max-width:800px" id="abstract">
    <h2 class="w3-justify" id="introduction">Introduction</h2>
    <p class="w3-opacity w3-justify">
      Nowadays, machine learning (ML) is widespread.  In particular, trees are one of the most popular ML model classes.  In a recent survey of data scientists and researchers, tree models were both the second and third most popular class of method, beaten only by Logistic Regression (Figure 1).  Although small tree models can be interpretable (<a href="#rudin2019">Rudin 2019</a>), most tree models are generally large and hard for humans to interpret.  
    </p>

	<div id="table_container" style="overflow-x:auto;align:center;">
    <p class="w3-opacity" style="font-size:20px;margin:20px 20px 0px 20px"><strong>Figure 1</strong>: The most popular data science methods according to a <a href="https://www.kaggle.com/surveys/2017">2017 Kaggle survey</a> (based on a total of 7,301 responses).</p>
    <div id="fig1"></div>
	</div>

    <p class="w3-opacity w3-justify">
    In order to rigorously explain these models, we turn to Shapley values (a unique game-theoretic solution for spreading credit between features).  Then, we discuss an extension of Shapley values to machine learning models (SHAP values) and trade-offs of different versions of SHAP values (Section 1).  Finally, computing SHAP values exactly is NP-hard (<a href="#matsui2001NP">Matsui et. al. 2001</a>), but by focusing on explaining trees, we can devise an exact linear time algorithm for obtaining SHAP values (Section 2).
    </p>

    <h3 class="w3-justify" id="motivation">Motivation</h3>
    <p class="w3-opacity w3-justify">
    The goal of this article is to explain an algorithm we developed called Interventional Tree Explainer (ITE) that is currently the default algorithm for explaining trees in the popular SHAP package. ITE is introduced in <a href="#lundberg2020fromlocal">Lundberg et. al. 2020</a>; however, it is a complicated algorithm we did not have room to fully explain in the paper.  
  </p>

    <p class="w3-opacity w3-justify">
    Given that there is a long history of model explanations going awry when users do not understand what an explanation means (e.g., p-values for linear models (<a href="#schervish1996">Schervish 1996</a>)), it is extremely important to have a broadly accessible explanation of SHAP values and how they are obtained for tree models to ensure that people do not misuse them.
  </p>
  </div>


  <!-- The Background Section -->
  <div class="w3-container w3-content w3-center w3-padding-16" style="max-width:800px">
    <h2 class="w3-justify" id="background">1. Background</h2>
    
    <!-- <h3 class="w3-justify" id="trees_popular">1.1 Tree models are popular</h3>
	<p class="w3-opacity w3-justify">
    	Why do we even care about explaining trees?
    </p> -->


    <!-- What are Shapley Values? -->
    <h3 class="w3-justify" id="shapley_values">1.1 Shapley values</h3>
	<p class="w3-opacity w3-justify">
    	Shapley values are a concept from cooperative game theory that spreads credit among players in a coalitional game.  We can define the players to be a set \(N=\{1,\cdots,d\}\).  Then, the game is a function that maps the players (\(N\)) to a scalar value:

    	$$
    	v(S):2^N\to\mathbb{R}^1
    	$$
    </p>

    <p class="w3-opacity w3-justify">
    	To make these concepts more concrete, we can imagine a company that makes a profit \(v(S)\) that is determined by what combination of individuals they employ \(S\).  Furthermore, let's assume we know \(v(S)\) for all possible combinations of employees.  Then, the Shapley values assign credit to an individual \(i\) by taking a weighted average of how much the profit increases when \(i\) works with a group \(S\) versus when he does not work with \(S\).  Repeating this for all possible subsets \(S\) gives us the Shapley Values:
    	<!-- (include a simple graphic here?) -->
    	$$
    	\overbrace{\phi_i(v)}^{\text{Shapley value of }i}=\sum_{S\subseteq N\setminus\{i\}}\underbrace{\frac{|S|!(|N|-|S|-1)!}{|N|!}}_{\text{Weight }W(|S|,|N|)}(\overbrace{v(S\cup\{i\})-v(S)}^{\text{Profit individual }i\text{ adds}})
    	$$

    </p>

	<div id="table_container" style="overflow-x:auto;align:center;">
		<p class="w3-opacity w3-left" align="left" style="margin:20px"><strong>Example 1</strong>: Shapley values for a company that makes a profit \(v(S)\) based on it's three prospective employees \(Ava\), \(Ben\), and \(Cat\).</p>
	  <table class="w3-opacity w3-center" style="width:300px;display:inline;margin-right:25px;font-size:18px;">
	  	<caption align="top" style="font-size:20px;"><strong>Coalitional game</strong></caption>
	  	<col width="200px"/>
    	<col width="150px"/>
    	<col width="50px"/>
		<tr>
			<th>Subset \(S\)</th>
			<th>Profit \(v(S)\)</th>
			<th></th>
		</tr>
		<tr>
			<td>\(\{\}\)</td>
			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_n" onchange="calcSV()"></td>
			<td><span id="s_n_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Ava\}\)</td>
			<td><input type="range" min="-15" max="15" value="1" class="slider" id="s_a" onchange="calcSV()"></td>
			<td><span id="s_a_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Ben\}\)</td>
			<td><input type="range" min="-15" max="15" value="1" class="slider" id="s_b" onchange="calcSV()"></td>
			<td><span id="s_b_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Cat\}\)</td>
			<td><input type="range" min="-15" max="15" value="1" class="slider" id="s_c" onchange="calcSV()"></td>
			<td><span id="s_c_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Ava,Ben\}\)</td>
			<td><input type="range" min="-15" max="15" value="2" class="slider" id="s_ab" onchange="calcSV()"></td>
			<td><span id="s_ab_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Ava,Cat\}\)</td>
			<td><input type="range" min="-15" max="15" value="2" class="slider" id="s_ac" onchange="calcSV()"></td>
			<td><span id="s_ac_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Ben,Cat\}\)</td>
			<td><input type="range" min="-15" max="15" value="2" class="slider" id="s_bc" onchange="calcSV()"></td>
			<td><span id="s_bc_out"></span></td>
		</tr>
		<tr>
			<td>\(\{Ava,Ben,Cat\}\)</td>
			<td><input type="range" min="-15" max="15" value="3" class="slider" id="s_abc" onchange="calcSV()"></td>
			<td><span id="s_abc_out"></span></td>
		</tr>
	  </table>

	  <table class="w3-opacity w3-center fixed" style="width:200px;display:inline;margin-left:25px;font-size:20px;">
	  	<caption align="top" style="font-size:20px;"><strong>Shapley values</strong></caption>
		<col width="100px"/>
    	<col width="100px"/>
		<tr>
			<td>\(\phi_{Ava}(v)\)</td>
			<td id="phi_a">1</td>
		</tr>
		<tr>
			<td>\(\phi_{Ben}(v)\)</td>
			<td id="phi_b">1</td>
		</tr>
		<tr>
			<td>\(\phi_{Cat}(v)\)</td>
			<td id="phi_c">1</td>
		</tr>
	  </table>

	  <br><br>
	  <input type="button" value="Preset A" class="w3-button w3-green" id="ex1_presetA" style="font-size:20px;" onclick="ex1_presetA()"> 
	  <input type="button" value="Preset B" class="w3-button w3-teal" id="ex1_presetB" style="font-size:20px;" onclick="ex1_presetB()"> 
	  <input type="button" value="Preset C" class="w3-button w3-green" id="ex1_presetC" style="font-size:20px;" onclick="ex1_presetC()"> 
	  <br>

	  <p class="w3-opacity w3-center" align="center" id="ex1_preset_text" style="margin:20px">All equals.</p>

	</div>

	<p class="w3-opacity w3-justify">
    	The Shapley values consider how much an individual increases profit when they work together with all other possible teams.  Furthermore, they are a unique solution to spreading credit as defined by several desirable properties (<a href="#young_uniquesol">Young 1985</a>):
    	<ul class="w3-opacity w3-justify">
    		<li>Local Accuracy/Efficiency: The sum of Shapley values for all employees adds up to the profit with all employees minus the profit with no employees:</li>
	    		$$
	    			\sum_{i\in N} \phi_i(v)=v(N)-v(\{\})
	    		$$
    		<li>Consistency/Monotonicity: If an employee \(i\) always increases company \(v_1\)'s profit more than they would company \(v_2\) for all teams of other employees, then \(i\)'s attribution for \(v_1\) should be greater than or equal to their attribution in \(v_2\):</li>
    			$$
    			v_1(S\cup {i})-v_1(S)\geq v_2(S\cup {i})-v_2(S) \forall S \implies \phi_i(v_1)\geq \phi_i(v_2)
    			$$
    		<li>Missingness: Employees \(i\) that don't help or hurt the company's profit must have no attribution.</li>
    			$$
    			v(S\cup {i})=v(S)\forall S\implies \phi_i(v)=0
    			$$
    	</ul>
    </p>

	<p class="w3-opacity w3-justify">
    	<a href="#lundberg_unified">Lundberg and Lee (2017)</a> extend Shapley values to explain ML models (<a href="#shap_values">Section 1.2</a>).
    </p>


    <!-- What are SHAP Values? -->
    <h3 class="w3-justify" id="shap_values">1.2 SHAP values</h3>
	<p class="w3-opacity w3-justify">
    	SHAP values are a variant of Shapley values to explain ML models.  For SHAP values, the game \(v(S)\) is now related to a machine learning model \(f(x)\) and the set of players is now a feature vector \(x\in\mathbb{R}^d\).
    </p>

    <p class="w3-opacity w3-justify">
    	Previously, for Shapley values the game's output \(v(S)\) was the value of the game with the players in \(S\) "present" and the remaining players "missing".  For \(v(S)\), "missing" is naturally defined: whether or not a player \(i\) is present in the set \(S\) (or, as in our example, whether an employee was working for the company).  
    </p>

    <p class="w3-opacity w3-justify">
    	In comparison, ML models generally require a fixed length input which makes setting features to be "missing" or "present" less straightforward.  One natural way to do this is with a conditional expectation.  In words, the value of the game is the expected value of the model if we condition on a set of features that are "present".  If we define \(D\) to the background (underlying) distribution \(x\) should be compared to, then:
    	$$
		v(S)=\mathbb{E}_\mathcal{D}[f(x)|x_{S}]
    	$$
    </p>

	<p class="w3-opacity w3-justify">
    	One caveat is that modelling the conditional expectation is very difficult.  Further, even if you do perfectly obtain the conditional expectation, the correlations you capture may cause you to give weight to features your model does not use as an input.  Although explaining relationships by modelling the conditional expectation may be desirable for some use cases, our goal is to explain the model itself; therefore, an arguably more natural approach is to use causal inference's <i>interventional conditional expectation</i>:
    	$$
    	v(S)=\mathbb{E}_\mathcal{D}[f(x)|\text{do}(x_{S})]
    	$$
    	The <i>do</i> notation is Judea Pearl's <i>do</i>-operator (<a href="pearl_2000_causality">Pearl 2000</a>). The motivation behind this decision comes from <a href="#janzing2019feature">Janzing et. al. (2019)</a> which is also very close to Random Baseline Shapley in <a href="#sundararajan2019many">Sundararajan et. al. (2019)</a>).  Additionally, this is exactly the assumption made by <a href="https://shap.readthedocs.io/en/latest/#shap.KernelExplainer">Kernel Explainer</a> and <a href="https://shap.readthedocs.io/en/latest/#shap.SamplingExplainer">Sampling Explainer</a> from the SHAP package.
    </p>

    <div id="table_container" style="overflow-x:auto;align:center;">
		<p class="w3-opacity w3-left" align="left" style="margin:20px">
			<strong>Example 2</strong>: Comparing choices of set function for Shapley values: conditional expectation (CE) and interventional conditional expectation (ICE).  We make two simplifying assumptions:
		</p>
		<ul class="w3-opacity" align="left" style="margin:20px">
			<li>The function is linear (\(f=\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4\))</li>
			<li>The data-generating distribution is multivariate normal (\(D\sim \mathcal{N}_4(0,\Sigma)\))</li>
		</ul>

		<table class="w3-opacity" style="width:300px;display:inline;margin-right:25px;font-size:20px;">
	      <col width="60px">
	      <col width="60px">
	      <tr align="center">
	      	<td colspan="2"><strong>Linear</strong></td>
	  	  </tr>
	      <tr align="center">
	      	<td colspan="2"><strong>Model</strong></td>
	  	  </tr>
		  <tr align="center">
		    <td>\(\beta_1\)</td>
		    <td><input class="w3-input" type="text" id="ex2_b1" value="1"></td>
		  </tr>
		  <tr align="center">
		    <td>\(\beta_2\)</td>
		    <td><input class="w3-input" type="text" id="ex2_b2" value="2"></td>
		  </tr>
		  <tr align="center">
		    <td>\(\beta_3\)</td>
		    <td><input class="w3-input" type="text" id="ex2_b3" value="3"></td>
		  </tr>
		  <tr align="center">
		    <td>\(\beta_4\)</td>
		    <td><input class="w3-input" type="text" id="ex2_b4" value="4"></td>
		  </tr>
		</table>


		<table class="w3-opacity" style="width:300px;display:inline;margin-right:25px;font-size:20px;">
	      <col width="50px">
	      <col width="60px">
	      <col width="60px">
	      <col width="60px">
	      <col width="60px">
	      <tr align="center">
	      	<td colspan="5"><strong>Covariance \(\Sigma\)</strong></td>
	      </tr>
	      <tr align="center">
		    <th></th>
		    <th>\(x_1\)</th>
		    <th>\(x_2\)</th>
		    <th>\(x_3\)</th>
		    <th>\(x_4\)</th>
		  </tr>
		  <tr align="center">
		    <td>\(x_1\)</td>
		    <td><input class="w3-input" type="text" id="ex2_cor11" value="1"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor12" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor13" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor14" value="0"></td>
		  </tr>
		  <tr align="center">
		    <td>\(x_2\)</td>
		    <td><input class="w3-input" type="text" id="ex2_cor21" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor22" value="1"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor23" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor24" value="0"></td>
		  </tr>
		  <tr align="center">
		    <td>\(x_3\)</td>
		    <td><input class="w3-input" type="text" id="ex2_cor31" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor32" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor33" value="1"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor34" value="0"></td>
		  </tr>
		  <tr align="center">
		    <td>\(x_4\)</td>
		    <td><input class="w3-input" type="text" id="ex2_cor41" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor42" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor43" value="0"></td>
		    <td><input class="w3-input" type="text" id="ex2_cor44" value="1"></td>
		  </tr>
		</table>


		<table class="w3-opacity" style="width:300px;display:inline;margin-right:25px;font-size:20px;">
	      <col width="60px">
	      <col width="60px">
	      <tr align="center">
	      	<td colspan="2"><strong>Explicand</strong></td>
	  	  </tr>
	      <tr align="center">
	      	<td colspan="2"><strong>Sample</strong></td>
	  	  </tr>
		  <tr align="center">
		    <td>\(x_1\)</td>
		    <td><input class="w3-input" type="text" id="ex2_x1" value="1"></td>
		  </tr>
		  <tr align="center">
		    <td>\(x_2\)</td>
		    <td><input class="w3-input" type="text" id="ex2_x2" value="1"></td>
		  </tr>
		  <tr align="center">
		    <td>\(x_3\)</td>
		    <td><input class="w3-input" type="text" id="ex2_x3" value="1"></td>
		  </tr>
		  <tr align="center">
		    <td>\(x_4\)</td>
		    <td><input class="w3-input" type="text" id="ex2_x4" value="1"></td>
		  </tr>
		</table>

		<br><br>

	  	<table class="w3-opacity" style="width:300px;display:inline;margin-right:25px;font-size:20px;">
	      <col width="180px">
	      <col width="80px">
	      <col width="80px">
	      <col width="80px">
	      <col width="80px">
	      <tr align="center">
	      	<td></td>
	      	<td>\(\phi_1\)</td>
	      	<td>\(\phi_2\)</td>
	      	<td>\(\phi_3\)</td>
	      	<td>\(\phi_4\)</td>
	  	  </tr>
		  <tr align="center">
		    <td><strong>CE Shapley Values</strong></td>
		    <td id="ex2_CE_phi1">1</td>
		    <td id="ex2_CE_phi2">2</td>
		    <td id="ex2_CE_phi3">3</td>
		    <td id="ex2_CE_phi4">4</td>
		  </tr>
		  <tr align="center">
		  	<td><strong>ICE Shapley Values</strong></td>
		    <td id="ex2_ICE_phi1">1</td>
		    <td id="ex2_ICE_phi2">2</td>
		    <td id="ex2_ICE_phi3">3</td>
		    <td id="ex2_ICE_phi4">4</td>
		  </tr>
		</table>

		<br><br>

		<input type="button" value="Preset A" class="w3-button w3-teal" style="font-size:20px;" id="ex2_presetA" onclick="ex2_presetA()">
	  	<input type="button" value="Preset B" class="w3-button w3-green" style="font-size:20px;" id="ex2_presetB" onclick="ex2_presetB()">
	  	<input type="button" value="Preset C" class="w3-button w3-green" style="font-size:20px;" id="ex2_presetC" onclick="ex2_presetC()">
	  	<input type="button" value="Preset D" class="w3-button w3-green" style="font-size:20px;" id="ex2_presetD" onclick="ex2_presetD()">

		<p class="w3-opacity w3-center" align="center" id="ex2_preset_text" style="margin:20px">Independent variables.</p>
	</div>

    <!-- Background distribution -->
    <h3 class="w3-justify" id="background_distribution">1.3 SHAP values with a background distribution</h3>

	<p class="w3-opacity w3-justify">
		As we saw earlier, to compute \(\phi_i(f,x)\) we need to evaluate the interventional conditional expectation.  This conditional expectation depends on a <i>background distribution</i> \(D\) that the foreground sample \(x\) is compared against.  
	</p>

	<p class="w3-opacity w3-justify">
		One natural definition of the background distribution is a uniform distribution over a population sample.  For instance, in machine learning, you could assign equal probability to every sample in your training set.  With this background distribution, we can re-write the SHAP value as an average of <i>single reference SHAP values</i> (<a href="#chen2019explaining">Chen et. al. 2019</a>):
		$$
		\phi_i(f,x)=\frac{1}{|D|}\sum_{\hat{x}\in D}\phi_i(f,x,\hat{x})
		$$
		This is in part because the interventional conditional expectation has a very natural definition when the background distribution is a single sample \(\hat{x}\) (\(D_{\hat{x}}\)):
		$$
		\mathbb{E}_\mathcal{D_{\hat{x}}}[f(x)|\text{do}(x_{S})]=\mathcal{X}(x,\hat{x},S)
		$$
		Where \(\mathcal{X}(x,\hat{x},S)\) to return a hybrid sample \(h\) where the features in \(S\) are from \(x\) and the remaining features are from \(\hat{x}\).  In words, the interventional conditional expectation of \(x\) given a set of features \(S\), is a hybrid sample where the features in \(S\) are from \(x\) and the remaining features are from \(\hat{x}\).  This is as if <i>we intervene on features in the foreground sample with features from the background sample</i>. 
	</p>  

		<!-- Proof -->
	<div style="background-color:aliceblue;">

		<div style="padding-left:10px;padding-right:10px">

			<p class="w3-justify"><a onclick="hideshow('proof_backgrounddist')"><strong>Single reference SHAP values Proof (Click)</strong></a></p>

			<div id="proof_backgrounddist", style="display:none">

			    <p class="w3-opacity w3-justify">
				    Define \(C\) to be all combinations of the set \(N \setminus \{i\}\) and \(P\) to be all permutations of \(N \setminus \{i\}\).  Starting with the definition of SHAP values: 
					$$
					\begin{aligned}
					\phi_i(f,x)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(X)|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[f(X)|x_{S}])\\
					&=\frac{1}{|P|}\sum_{S\subseteq P} \mathbb{E}_\mathcal{D}[f(x)|\text{do}(x_{S \cup \{i\}})] {-} \mathbb{E}_\mathcal{D}[\text{do}(f(x)|x_{S})]\\
					&= \frac{1}{|P|}\sum_{S\subseteq P}\frac{1}{|D|}\sum_{\hat{x}\in D} f(\mathcal{X}(x,\hat{x},S\cup \{i\})) {-} f(\mathcal{X}(x,\hat{x},S))\\
					&= \frac{1}{|D|}\sum_{\hat{x}\in D} \frac{1}{|P|}\sum_{S\subseteq P} f(\mathcal{X}(x,\hat{x},S\cup \{i\})) {-} f(\mathcal{X}(x,\hat{x},S)) \\
					&= \frac{1}{|D|}\sum_{\hat{x}\in D} \underbrace{\sum_{S\subseteq C} W(|S|,|N|)f(\mathcal{X}(x,\hat{x},S\cup \{i\})) {-} f(\mathcal{X}(x,\hat{x},S))}_{\text{Single reference SHAP value}}\\
					&=\frac{1}{|D|}\sum_{\hat{x}\in D}\phi_i(f,x,\hat{x})
					\end{aligned}
					$$
				</p>

			</div>
		</div>

	</div>

	<p class="w3-opacity w3-justify">
		In summary, we reduce the problem of obtaining \(\phi_i(f,x)\) to an average of simpler problems \(\phi_i(f,x,\hat{x})\) where our foreground sample \(x\) is compared to a distribution with only one background sample \(\hat{x}\).
	</p>

  </div>


  <!-- The Algorithm Section -->
  <div class="w3-container w3-content w3-center w3-padding-16" style="max-width:800px">
    <h2 class="w3-justify" id="algorithm">2. Algorithm</h2>
    
    <p class="w3-opacity w3-justify">
    Now our goal is to tackle the simpler problem of obtaining single reference SHAP values \(\phi_i(f,x,\hat{x})\).  In this section, we consider a specific foreground sample (sample being explained), background sample (sample being compared to), and tree (specified in Example 3).
	</p>

	<div id="table_container" style="overflow-x:auto;align:center;">
		<p class="w3-opacity w3-left" align="left" style="margin:20px">
			<strong>Example 3</strong>: Choose \(x^f\), \(x^b\), and tree parameters for the remainder of this section.
		</p>

    	<table class="w3-center" style="width:300px;display:inline;margin-right:25px;font-size:18px;">
	      <col width="100px"/>
	      <col width="150px"/>
	      <col width="50px"/>
	      <col width="150px"/>
	      <col width="50px"/>
	      <col width="50px"/>
	    <tr class="w3-opacity">
	      <th>Variable</th>
	      <th colspan="2">Foreground Sample \(x^f\)</th>
	      <th colspan="2">Background Sample \(x^b\)</th>
	      <th></th>
	    </tr>
	    <tr>
	      <td class="w3-opacity">\(x_1\)</td>
	      <td><input type="range" min="-15" max="15" value="0" class="slider" id="fx1"></td>
	      <td class="w3-opacity" align="left" id="fx1_out"></td>
	      <td><input type="range" min="-15" max="15" value="10" class="slider" id="bx1"></td>
	      <td class="w3-opacity" align="left" id="bx1_out"></td>
	      <td></td>
	    </tr>
	    <tr>
	      <td class="w3-opacity">\(x_2\)</td>
	      <td><input type="range" min="-15" max="15" value="0" class="slider" id="fx2"></td>
	      <td class="w3-opacity" align="left" id="fx2_out"></td>
	      <td><input type="range" min="-15" max="15" value="10" class="slider" id="bx2"></td>
	      <td class="w3-opacity" align="left" id="bx2_out"></td>
	      <td><input type="button" value="Reset" class="w3-button w3-green" style="font-size:20px;" onclick="ex3_reset()"> </td>
	    </tr>
	    <tr>
	      <td class="w3-opacity">\(x_3\)</td>
	      <td><input type="range" min="-15" max="15" value="10" class="slider" id="fx3"></td>
	      <td class="w3-opacity" align="left" id="fx3_out"></td>
	      <td><input type="range" min="-15" max="15" value="0" class="slider" id="bx3"></td>
	      <td class="w3-opacity" align="left" id="bx3_out"></td>
	      <td></td>
	    </tr>
	  </table>

	  <br><br>

		<p class="w3-opacity w3-center" style="line-height:0;font-size:18px">
			<strong>Tree Parameters* (Click nodes)</strong> <br>
		</p>

	  <div id="graphic"></div> 
	  <div class="tooltip" id="tooltip"></div>
		<p class="w3-opacity w3-center" style="margin:-30px 0px 30px 0px;font-size:18px">
			*Green links indicate the foreground sample goes down a particular split, red indicates the background sample does, and blue indicates both samples do.
		</p>
	</div>

    <!-- Brute force -->
    <h3 class="w3-justify" id="brute_force">2.1 Brute force</h3>

    <p class="w3-opacity w3-justify">
    	Based on the proof in <a href="#background_distribution">Section 1.3</a>, the brute force approach would be to compute the following:

    	$$
    	\phi_i(f,x,\hat{x})=\sum_{S\subseteq N\setminus\{i\}} \underbrace{W(|S|,|N|)}_{W}\underbrace{f(\mathcal{X}(x,\hat{x},S\cup \{i\}))}_{\text{\textcolor{green}{Pos} term}} {-} \underbrace{f(\mathcal{X}(x,\hat{x},S)}_{\text{\textcolor{red}{Neg} term}})
    	$$

    	Note that \(\mathcal{X}(x,\hat{x},S)\) returns a hybrid sample \(h\) where the features in \(S\) are from \(x\) and the remaining features are from \(\hat{x}\).  If the cost of computing the weight \(W\) is constant, then the computational complexity of the brute force method is the number of terms in the summation times the cost of making a prediction \(f(x)\) (likely on the order of the depth of the tree \(O(D)\)).  Since we consider two terms (\(\text{\textcolor{green}{Pos}}\) and \(\text{\textcolor{red}{Neg}}\)) for all possible combinations of the full set of features (without \(i\)), the computational complexity is \(O(D\times2^{d})\).

    	Finally, the computational complexity to compute \(\phi_i(f,x,\hat{x})\) for all features is \(O(|N|\times D\times 2^{d})\).

	</p>


    <div id="table_container" style="overflow-x:auto;align:center;font-size:18px">
    	<p class="w3-opacity w3-left" align="left" style="margin:20px">
			<strong>Example 4</strong>: Brute force algorithm for the tree and samples specified in Example 3.
		</p>
	</div>

    <div id="table_container" style="overflow-x:auto;align:center">
	  <div class="container">

	    <div class="first" style="width:460px;height:300px">
	    	<p class="w3-opacity w3-center" style="margin: 0px 0px 0px 20px;font-size:18px;"><strong>Tree Parameters</strong></p>
	    	<div id="ex4_divtree" style="margin-top:10px;"></div>
	    </div>


	    <div class="second" style="width:300px;height:300px">
	    	<p class="w3-opacity w3-center" style="margin: 0px 0px 0px -100px;font-size:18px;"><strong>Foreground & background sample</strong></p>
			<table class="w3-opacity" cellpadding="10" style="margin: 10px 0px 0px -10px">
				<col width="40px"/>
				<col width="50px"/>
				<col width="50px"/>
				<tr>
					<th></th>
					<th>\(x_1\)</th>
					<th>\(x_2\)</th>
					<th>\(x_3\)</th>
				</tr>
				<tr>
					<td>\(x^f\)</td>
					<td id="ex4_fx1">0</td>
					<td id="ex4_fx2">0</td>
					<td id="ex4_fx3">10</td>
				</tr>
				<tr>
					<td>\(x^b\)</td>
					<td id="ex4_bx1">10</td>
					<td id="ex4_bx2">10</td>
					<td id="ex4_bx3">0</td>
				</tr>
				<tr id="ex4_hS">
					<td>\(h_S\)</td>
					<td id="ex4_hs1"></td>
					<td id="ex4_hs2"></td>
					<td id="ex4_hs3"></td>
				</tr>
				<tr id="ex4_hSi">
					<td>\(h_{S\cup i}\)</td>
					<td id="ex4_hsi1"></td>
					<td id="ex4_hsi2"></td>
					<td id="ex4_hsi3"></td>
				</tr>
			</table>
	    </div>

	    <div class="clear"></div>
	    <div class="container">
	    	<div class="first" style="width:460px;height:280px">
			<p class="w3-opacity w3-center" style="margin: 0px 0px 0px 20px;font-size:18px;"><strong>Brute Force Values</strong></p>
      		<table class="w3-opacity" cellpadding="10" style="margin: 10px 0px 0px 90px">
		      <col width="40px"/>
		      <col width="50px"/>
		      <col width="50px"/>
		      <col width="60px"/>
		      <col width="60px"/>
			<thead>
				<tr>
					<th>\(W\)</th>
					<th>\(S\)</th>
					<th id="ex4_fxS">\(f(x_S)\)</th>
					<th>\(S\cup{i}\)</th>
					<th id="ex4_fxSi">\(f(x_{S\cup{i}})\)</th>
				</tr>
			</thead>
			<tbody>
				<tr id="ex4_s1_row">
					<td>1/3</td>
					<td id="s1"></td>
					<td id="s1_val"></td>
					<td id="s1i"></td>
					<td id="s1i_val"></td>
				</tr>
				<tr id="ex4_s2_row">
					<td>1/6</td>
					<td id="s2"></td>
					<td id="s2_val"></td>
					<td id="s2i"></td>
					<td id="s2i_val"></td>
				</tr>
				<tr id="ex4_s3_row">
					<td>1/6</td>
					<td id="s3"></td>
					<td id="s3_val"></td>
					<td id="s3i"></td>
					<td id="s3i_val"></td>
				</tr>
				<tr id="ex4_s4_row">
					<td>1/3</td>
					<td id="s4"></td>
					<td id="s4_val"></td>
					<td id="s4i"></td>
					<td id="s4i_val"></td>
				</tr>
			</tbody>
			</table>
	    	</div>

	    	<div class="second" style="width:300px;height:280px">
	    	<p class="w3-opacity w3-center" style="margin: 0px 0px 0px -110px;font-size:18px;"><strong>Attribution Values</strong></p>

			<table class="w3-opacity" cellpadding="10" style="margin: 10px 0px 0px -10px">
		      <col width="60px"/>
		      <col width="80px"/>
				<thead>
				<!-- <tr style="background-color:#8BC34A;"> -->
				<tr id="ex4_phi1">
					<td>\(\phi_1(f,x^f,x^b)\)</td>
					<td id="ex4_phi1_val">0</td>
				</tr>
				<tr id="ex4_phi2">
					<td>\(\phi_2(f,x^f,x^b)\)</td>
					<td id="ex4_phi2_val">0</td>
				</tr>
				<tr id="ex4_phi3">
					<td>\(\phi_3(f,x^f,x^b)\)</td>
					<td id="ex4_phi3_val">0</td>
				</tr>
			</thead>
			</table>
	    	</div>
	    </div>
	    <input style="font-size:20px;" type="button" class="w3-button w3-green" value="<<" onclick="ex4_reset()">
	    <input style="font-size:20px;" type="button" class="w3-button w3-green" value=">" onclick="bruteForceStep()">
	    <input style="font-size:20px;" type="button" class="w3-button w3-green" value=">>" onclick="bruteForceRunAll()">
	    <br><br>
	    <div class="clear"></div>
	  </div>
    </div>


	<p class="w3-opacity w3-justify">
	    However, if we <i>constrain \(f(x)\) to be a tree-based model</i> (e.g., XGBoost, decision trees, random forests, etc.), then we can come up with a polynomial time algorithm to compute \(\phi_i(f,x,\hat{x})\) exactly.  In the following section we discuss an example to provide intuition as to why.
	</p>


    <!-- Example -->
    <h3 class="w3-justify" id="an_example">2.2 An Example</h3>

	<div style="overflow-x:auto;">

		<figure style="float:left">
			<figcaption class="w3-opacity">Figure 1: Binary tree example.</figcaption>
			<img src="images/tree_example.png" alt="Tree Example" width="250">
		</figure>

		<table cellpadding="10" align="center">
			<br>
			<caption class="w3-opacity">Foreground sample \(x\).</caption>
			<thead>
				<tr>
					<th>\(x_1\)</th>
					<th>\(x_2\)</th>
					<th>\(x_3\)</th>
					<th>\(x_4\)</th>
				</tr>
			</thead>
			<tbody>
				<tr bgcolor="#F8F8F8">
					<td align="right">\(-1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(-3\)</td>
					<td align="right">\(-4\)</td>
				</tr>
			</tbody>
		</table>

	<br>

		<table cellpadding="10" align="center">
			<caption class="w3-opacity">Background sample \(\hat{x}\).</caption>
			<thead>
				<tr>
					<th>\(\hat{x}_1\)</th>
					<th>\(\hat{x}_2\)</th>
					<th>\(\hat{x}_3\)</th>
					<th>\(\hat{x}_4\)</th>
				</tr>
			</thead>
			<tbody>
				<tr bgcolor="#F8F8F8">
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(3\)</td>
					<td align="right">\(4\)</td>
				</tr>
			</tbody>			
		</table>
	</div>

    <p class="w3-opacity w3-justify">
    	In this section, we will focus on the tree in Figure 1.  First of all, we can examine a brute force approach to explain feature \(1\) with \(x=[-1,2,-3,-4]\) and \(\hat{x}=[1,-2,3,4]\).  
	</p>

    <p class="w3-opacity w3-justify">
    	In Table 1, each row corresponds to a combination \(S\) in the brute force summation.  In addition, we report the hybrid features \(h_i\) that are taken from either \(x\) or \(\hat{x}\).  The weight \(W\) is based on the size of \(S\) and the \(\text{\textcolor{green}{Pos}}\) and \(\text{\textcolor{red}{Neg}}\) terms correspond to \(f(\mathcal{X}(x,\hat{x},S\cup \{i\}))\) and \(f(\mathcal{X}(x,\hat{x},S))\) respectively.
	</p>	

    <p class="w3-opacity w3-justify">
		We color \(h_1\) to be green if it came from \(x\) and red if it came from \(\hat{x}\), because if \(h_1\) is from \(x\) it corresponds to the \(\text{\textcolor{green}{Pos}}\) term and if \(h_1\) is from \(\hat{x}\) it corresponds to the \(\text{\textcolor{red}{Neg}}\) term.
	</p>

	<div style="overflow-x:auto;">
		<table cellpadding="10" align="center">
			<caption class="w3-opacity"><strong>Table 1: </strong>Brute force approach to compute \(\phi_1(f,x,\hat{x})\) has \(2^3\) rows and \(2^4\) \(\text{\textcolor{green}{Pos}}\)/\(\text{\textcolor{red}{Neg}}\) terms, where \(4\) is the total number of features.</caption>
			<thead>
				<tr>
					<th>\(S\)</th>
					<th>\(\textcolor{green}{h_1}\)</th>
					<th>\(\textcolor{red}{h_1}\)</th>
					<th>\(h_2\)</th>
					<th>\(h_3\)</th>
					<th>\(h_4\)</th>
					<th>\(W\)</th>
					<th>\(\text{\textcolor{green}{Pos}}\)</th>
					<th>\(\text{\textcolor{red}{Neg}}\)</th>
				</tr>
			</thead>
			<tbody>
				<tr bgcolor="#F8F8F8">
					<td>\(\{\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(3\)</td>
					<td align="right">\(4\)</td>
					<td>\(1/4\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(4\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{2\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(3\)</td>
					<td align="right">\(4\)</td>
					<td>\(1/12\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(4\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{3\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(-3\)</td>
					<td align="right">\(4\)</td>
					<td>\(1/12\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(3\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{2,3\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(-3\)</td>
					<td align="right">\(4\)</td>
					<td>\(1/12\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(3\)</td>
				</tr>
				<tr bgcolor="#E8E8E8">
					<td>\(\{4\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(3\)</td>
					<td align="right">\(-4\)</td>
					<td>\(1/12\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(4\)</td>
				</tr>
				<tr bgcolor="#E8E8E8">
					<td>\(\{2,4\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(3\)</td>
					<td align="right">\(-4\)</td>
					<td>\(1/12\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(4\)</td>
				</tr>
				<tr bgcolor="#E8E8E8">
					<td>\(\{3,4\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(-3\)</td>
					<td align="right">\(-4\)</td>
					<td>\(1/12\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(3\)</td>
				</tr>
				<tr bgcolor="#E8E8E8">
					<td>\(\{2,3,4\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(-3\)</td>
					<td align="right">\(-4\)</td>
					<td>\( 1/4\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(3\)</td>
				</tr>
			</tbody>
		</table>
	</div>

    <p class="w3-opacity w3-justify">
    	<strong>Observation 1: We can ignore variables that are not present in the tree.</strong>   This is particularly useful for tree ensemble methods where each tree in the ensemble may be small, but the overall number of features is large.
	</p>

	<p class="w3-opacity w3-justify">
		In particular, the value of \(h_4\) does not influence the tree or summation.  We can collapse the top and bottom half of Table 1 by summing \(W\) and keeping \(\text{\textcolor{green}{Pos}}\) and \(\text{\textcolor{red}{Neg}}\) values:
	</p>
	
	<!-- Table 2 -->
	<div style="overflow-x:auto;">
		<table cellpadding="10" align="center">
			<caption class="w3-opacity"><strong>Table 2: </strong> We can reduce to \(2^2\) rows and \(2^3\) terms.</caption>
			<thead>
				<tr>
					<th>\(S\)</th>
					<th>\(\textcolor{green}{h_1}\)</th>
					<th>\(\textcolor{red}{h_1}\)</th>
					<th>\(h_2\)</th>
					<th>\(h_3\)</th>
					<th>\(W\)</th>
					<th>\(\text{\textcolor{green}{Pos}}\)</th>
					<th>\(\text{\textcolor{red}{Neg}}\)</th>
				</tr>
			</thead>
			<tbody>
				<tr bgcolor="#F8F8F8">
					<td>\(\{\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(3\)</td>
					<td>\(1/3\)</td>
					<td align="right" bgcolor="#f4eff5">\(1\)</td>
					<td align="right" bgcolor="#fef5e6">\(4\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{2\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(3\)</td>
					<td>\(1/6\)</td>
					<td align="right" bgcolor="#edf2f8">\(2\)</td>
					<td align="right" bgcolor="#fef5e6">\(4\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{3\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(-3\)</td>
					<td>\(1/6\)</td>
					<td align="right" bgcolor="#f4eff5">\(1\)</td>
					<td align="right" bgcolor="#ffffe5">\(3\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{2,3\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right">\(1\)</td>
					<td align="right">\(2\)</td>
					<td align="right">\(-3\)</td>
					<td>\(1/3\)</td>
					<td align="right" bgcolor="#edf2f8">\(2\)</td>
					<td align="right" bgcolor="#ffffe5">\(3\)</td>
				</tr>
			</tbody>
		</table>
	</div>


    <p class="w3-opacity w3-justify">
    	<strong>Observation 2: The number of \(\text{\textcolor{green}{Pos}}\) and \(\text{\textcolor{red}{Neg}}\) terms we need to calculate is equal to the number of leaves in the tree.</strong>  We color each term in Table 2 to illustrate which path in Figure 2 corresponds to each term.  Then, we can collapse the terms in Table 2 based on these paths to obtain Table 3.
	</p>


	<!-- Table 3 -->
	<div style="overflow-x:auto;">
		<figure style="float:left">
			<figcaption class="w3-opacity"><strong>Figure 2:</strong> Paths corresponding <br>to terms in Table 3.</figcaption>
			<br>
			<img src="images/tree_example2.png" alt="Tree Example" height="220">
		</figure>

		<br>
		<table cellpadding="10"> <!-- align="center" -->
			<caption class="w3-opacity"><strong>Table 3:</strong> We can reduce to \(2^2\) rows and \(2^2\) terms.</caption>
			<thead>
				<tr>
					<th>\(S\)</th>
					<th>\(\textcolor{green}{h_1}\)</th>
					<th>\(\textcolor{red}{h_1}\)</th>
					<th>\(h_2\)</th>
					<th>\(h_3\)</th>
					<th>\(W\)</th>
					<th>\(\text{\textcolor{green}{Pos}}\)</th>
					<th>\(\text{\textcolor{red}{Neg}}\)</th>
				</tr>
			</thead>
			<tbody>
				<tr bgcolor="#F8F8F8">
					<td>\(\{\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right"></td>
					<td align="right">\(-2\)</td>
					<td align="right">\(3\)</td>
					<td>\(1/2\)</td>
					<td align="right" bgcolor="#f4eff5">\(1\)</td>
					<td align="right"></td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{2\}\)</td>
					<td align="right">\(-1\)</td>
					<td align="right"></td>
					<td align="right">\(2\)</td>
					<td align="right">\(3\)</td>
					<td>\(1/2\)</td>
					<td align="right" bgcolor="#edf2f8">\(2\)</td>
					<td align="right"></td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{\}\)</td>
					<td align="right"></td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(3\)</td>
					<td>\(1/2\)</td>
					<td align="right"></td>
					<td align="right" bgcolor="#fef5e6">\(4\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td>\(\{3\}\)</td>
					<td align="right"></td>
					<td align="right">\(1\)</td>
					<td align="right">\(-2\)</td>
					<td align="right">\(-3\)</td>
					<td>\(1/2\)</td>
					<td align="right"></td>
					<td align="right" bgcolor="#ffffe5">\(3\)</td>
				</tr>
			</tbody>
		</table>
	</div>	

	<p class="w3-opacity w3-justify">
		<strong>Intuition:</strong> Drawing on this observation, we can intuitively see that each path in the tree will correspond to one of the \(\text{\textcolor{green}{Pos}}\) or \(\text{\textcolor{red}{Neg}}\) terms we need to calculate.  In the next section, we will discuss a naive algorithm to obtain these terms.
	</p>
    
    <!-- Naive Implementation -->
    <h3 class="w3-justify" id="naive_implementation">2.3 Naive Implementation</h3>

	<p class="w3-opacity w3-justify">
		Before we get into the algorithm, we first describe a theorem that is the basis for this naive implementation.
	</p>    

	<p class="w3-opacity w3-justify">
    	<strong>Theorem 1: To calculate \(\phi_i(f,x,\hat{x})\), we can calculate attributions for each path from the root to each leaf.</strong>  For a given path \(P\), we define \(N_P\) to be the "unique" features encountered and \(S_P\) to be the "unique" features that came from \(x\).  Finally, define \(v\) to be the value of the path's leaf.  Then, the attribution of the path is:

    	$$
		\phi_i^P(f,x,\hat{x})=
	    \begin{cases}
	    	0 & \text{if}\ i\notin N_P \\
	    	\textcolor{green}{W(|S_P|-1,|N_P|)\times v} & \text{if}\ i\in S_P \\
	    	\textcolor{red}{-W(|S_P|,|N_P|)\times v} & \text{o.w.}
	    \end{cases}
    	$$

	</p>

	<!-- Proof -->
	<div style="background-color:aliceblue;">

		<div style="padding-left:10px;padding-right:10px">

			<p class="w3-justify"><a onclick="hideshow('proof')"><strong>Theorem 1 Sketch of Proof (Click)</strong></a></p>

			<div id="proof", style="display:none">

				<p class="w3-opacity w3-justify">
					If we treat each path in the tree from the root to the leaf as a separate model \(f'(x)\) that returns the value of the leaf if that path is traversed by \(x\) or zero otherwise, then we have \(L\) models that operate on disjoint parts of the input space.  Then, \(f(x)=\sum f'(x)\) and by the additivity of SHAP values, \(\phi_i(f,x,\hat{x})=\sum_f\phi_i(f',x,\hat{x})\).  Then, we can simply calculate \(\phi_i\) for each path model.  Since the path model is zero everywhere except for the associated path, it is easy to arrive to the solution in Theorem 1.
				</p>

			</div>
		</div>

	</div>

	<p class="w3-opacity w3-justify">
		Then the goal of the algorithm is to obtain \(N_P\) and \(S_P\) for each path by recursively traversing the tree.  We will start by explaining the algorithm via an example:
	</p>

	<div>
	<figure>
		<figcaption class="w3-opacity">Figure 3: Green paths are associated with \(\textcolor{green}{x}\) and red paths are \(\textcolor{red}{\hat{x}}\).</figcaption>
		<img src="images/tree_example3.png" alt="Tree Example 3" width="400">
	</figure>
	</div>

	<p class="w3-opacity w3-justify">
		In the naive algorithm, we maintain lists \(N_P\) and \(S_P\) as we traverse the tree.  At each internal node (Cases 2-4) we update the lists and then pass them to the node's children.  At the leaf nodes (Case 1), we calculate the attribution for each path.  In Figure 3, we see four possible cases:
		<ul class="w3-opacity w3-justify">
			<li>Case 1: \(n\) is a leaf</li>
			<ul>
				<li>Return the attribution in Theorem 1 based on \(N_P\) and \(S_P\)</li>
			</ul>

			<li>Case 2: The feature has been encountered already (\(n_{feature}\in N_P\))</li>
			<ul>
				<li>We already split on the current feature based on \(x\) or \(\hat{x}\)</li>
				<li>Depending on which we used, we compare either \(x_{n_{feature}}\) or \(\hat{x}_{n_{feature}}\) to \(n_{threshold}\) and go down the appropriate child</li>
				<li>Pass down \(N_P\) and \(S_P\) without modifications because we did not add a new feature</li>
			</ul>

			<li>Case 3: Both \(x\) and \(\hat{x}\) are on the same side of \(n\)'s split</li>
			<ul>
				<li>Pass down \(N_P\) and \(S_P\) without modifications because relative to \(x\) and \(\hat{x}\) it's as if this node doesn't exist</li>
			</ul>

			<li>Case 4: \(x\) and \(\hat{x}\) go to different children</li>
			<ul>
				<li>Add \(n_{feature}\) to both \(N_P\) and \(S_P\) and pass both lists to the \(x\) child</li>
				<li>Only add \(n_{feature}\) to \(N_P\) and pass both lists to the \(\hat{x}\) child</li>
			</ul>
		</ul>
	</p>


    <div id="table_container" style="overflow-x:auto;align:center;font-size:18px">
    	<p class="w3-opacity w3-left" align="left" style="margin:20px">
			<strong>Example 5</strong>: Naive algorithm algorithm for the tree and samples from Example 3.
		</p>
	</div>

    <div id="table_container" style="overflow-x:auto;align:center">
    	<p class="w3-opacity w3-center" style="margin: 0px 0px 0px 20px;font-size:18px;"><strong>Tree Parameters</strong></p>
    	<div id="ex5_divtree" style="margin-top:10px;"></div>
    </div>

    <div id="table_container" style="overflow-x:auto;align:center">
    	<div class="container">

    	<div class="first" style="width:300px;height:220px">
			<p class="w3-opacity w3-center" style="margin: 0px 0px 0px 30px;font-size:18px;"><strong>Foreground & background sample</strong></p>
			<table class="w3-opacity" cellpadding="10" style="margin: 10px 0px 0px 60px">
			<col width="40px"/>
			<col width="50px"/>
			<col width="50px"/>
			<tr>
				<th></th>
				<th>\(x_1\)</th>
				<th>\(x_2\)</th>
				<th>\(x_3\)</th>
			</tr>
			<tr>
				<td>\(x^f\)</td>
				<td id="ex5_fx1">0</td>
				<td id="ex5_fx2">0</td>
				<td id="ex5_fx3">10</td>
			</tr>
			<tr>
				<td>\(x^b\)</td>
				<td id="ex5_bx1">10</td>
				<td id="ex5_bx2">10</td>
				<td id="ex5_bx3">0</td>
			</tr>
			<tr id="ex5_h">
				<td>\(h\)</td>
				<td id="ex5_h1"></td>
				<td id="ex5_h2"></td>
				<td id="ex5_h3"></td>
			</tr>
			</table>
		</div>

    	<div class="first" style="width:250px;height:220px">
	    	<p class="w3-opacity w3-center" style="margin: 0px 0px 0px 30px;font-size:18px;"><strong>Algorithm state</strong></p>
			<table class="w3-opacity" cellpadding="10" style="margin: 10px 0px 0px 80px">
				<col width="40px"/>
				<col width="80px"/>
				<tr>
					<td>\(S_P\)</td>
					<td id="ex5_sp"></td>
				</tr>
				<tr>
					<td>\(N_P\)</td>
					<td id="ex5_np"></td>
				</tr>
			</table>
    	</div>


    	<div class="first" style="width:210px;height:220px">
	    	<p class="w3-opacity w3-center" style="margin: 0px 0px 0px 10px;font-size:18px;"><strong>Attribution Values</strong></p>

			<table class="w3-opacity" cellpadding="10" style="margin: 10px 0px 0px 10px">
		      <col width="60px"/>
		      <col width="80px"/>
				<thead>
				<!-- <tr style="background-color:#8BC34A;"> -->
				<tr id="ex5_phi1">
					<td>\(\phi_1(f,x^f,x^b)\)</td>
					<td id="ex5_phi1_val"></td>
				</tr>
				<tr id="ex5_phi2">
					<td>\(\phi_2(f,x^f,x^b)\)</td>
					<td id="ex5_phi2_val"></td>
				</tr>
				<tr id="ex5_phi3">
					<td>\(\phi_3(f,x^f,x^b)\)</td>
					<td id="ex5_phi3_val"></td>
				</tr>
			</thead>
			</table>
    	</div>

	    <div class="clear"></div>
		</div>


    	<input style="font-size:20px;" type="button" class="w3-button w3-green" value="<<" onclick="ex5_reset()">
    	<input style="font-size:20px;" type="button" class="w3-button w3-green" value=">" onclick="naiveStep()">
    	<input style="font-size:20px;" type="button" class="w3-button w3-green" value=">>" onclick="naiveRunAll()">

    	<br><br>

		<p class="w3-opacity w3-center" style="margin: 0px 0px 20px 0px;font-size:18px;" id="ex5_naive_step">Naive algorithm</p>

	</div>


	<!-- Pseudocode -->
	<div style="background-color:#e6ffee;">

		<div style="padding-left:10px;padding-right:10px">

			<p class="w3-justify"><a onclick="hideshow('pseudocode_naive')"><strong>Naive Pseudocode (Click)</strong></a></a></p>

			<div id="pseudocode_naive">
			<p class="no-margin w3-opacity w3-justify" style="font-family:courier;font-size:16px">
				ITE_N(array \(x\), array \(\hat{x}\), tree \(T\)):
			</p>

			<ul class="no-margin w3-opacity w3-justify" style="font-family:courier;font-size:16px">
				RECURSE(node \(n\), list \(S_P\), list \(N_P\), array \(x\), array \(\hat{x}\)):
				<ul style="font-size:16px">
					<font color="#8E44AD">// Case 1: At a leaf</font><br>
					if n is a leaf:
					<ul style="font-size:16px">
						return \(\phi_i^P(f,x,\hat{x})\) based on \(S_P\) and \(N_P\) (Theorem 1)
					</ul>
					<font color="#8E44AD">// Find children associated with \(x\) and \(\hat{x}\)</font><br>
					\(x_{child} =\) \(n_{leftchild}\) if \(x[n_{feature}] < n_{threshold}\) else \(x_{child}\) = \(n_{rightchild}\) <br>
					\(\hat{x}_{child} =\) \(n_{leftchild}\) if \(\hat{x}[n_{feature}] < n_{threshold}\) else \(\hat{x}_{child}\) = \(n_{rightchild}\) <br>
					<font color="#8E44AD">// Case 2: Feature was encountered previously</font><br>
					if \(n_{feature}\in N_P\):
					<ul style="font-size:16px">
						if \(n_{feature}\in S_P\):
						<ul style="font-size:16px">
							return ITE_N(\(x_{child}\),\(S_P\),\(N_P\),\(x\),\(\hat{x}\))
						</ul>
						else: 
						<ul style="font-size:16px">
							return ITE_N(\(\hat{x}_{child}\),\(S_P\),\(N_P\),\(x\),\(\hat{x}\))
						</ul>
					</ul>

					<font color="#8E44AD">// Case 3: \(x\) and \(\hat{x}\) go to same children</font><br>
					if \(x_{child}==\hat{x}_{child}\):
					<ul style="font-size:16px">
						return ITE_N(\(x_{child}\),\(S_P\),\(N_P\),\(x\),\(\hat{x}\))
					</ul>
					<font color="#8E44AD">// Case 4: \(x\) and \(\hat{x}\) go to different children</font><br>
					if not \(x_{child}==\hat{x}_{child}\):
					<ul style="font-size:16px">
						return ITE_N(\(\hat{x}_{child}\),\(S_P\),\(N_P+[n_{feature}]\),\(x\),\(\hat{x}\)) + <br> ITE_N(\(x_{child}\),\(S_P+[n_{feature}]\),\(N_P+[n_{feature}]\),\(x\),\(\hat{x}\))
					</ul>
				</ul>
				return RECURSE(\(T_{rootnode}\), \(S_P=[\ ]\), \(N_P=[\ ]\), \(x\), \(\hat{x}\))
			</ul>
			</div>

		</div>

	</div>

    <p class="w3-opacity w3-justify">
		The computational complexity to compute \(\phi_i(f,x,\hat{x})\) using <font style="font-family:courier">ITE_N()</font> is \(O(T_{numnodes}\times T_{depth})\) where \(T_{numnodes}\) is the number of nodes in the tree and \(T_{depth}\) is the depth of the tree.  This is because in the worst case, each internal node needs to check the lists \(S_P\) and \(N_P\) which are of length \(O(T_{depth})\).  Furthermore, each leaf node needs to check if \(i\) is in \(S_P\) which is also \(O(T_{depth})\) cost.   Note that we can actually get rid of the multiplicative \(T_{depth}\) factor by representing \(S_P\) and \(N_P\) as arrays and keeping track of the sizes of \(|S|\) and \(|N|\).
	</p>

	<p class="w3-opacity w3-justify">
		Finally, getting the attributions for all features means that we will have to repeat the above algorithm \(|N|\) times.  In the next section we present a dynamic programming approach that allows us to compute the attributions for all features simultaneously.
	</p>

    <!-- Dynamic Programming -->
    <h3 class="w3-justify" id="dynamic_programming_implementation">2.4 Dynamic Programming Implementation</h3>

    <p class="w3-opacity w3-justify">
	    We can compute the attributions for all features simultaneously as we traverse the tree.  In this algorithm algorithm we pass \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) attributions to the parent.  Before describing the algorithm in more detail, we first present an example that illustrates why passing up the attributions is sufficient.
	</p>

	<div style="overflow-x:auto;">

		<figure style="float:left">
			<figcaption class="w3-opacity">Figure 4: Example to illustrate collapsibility for features.  Green paths are associated with \(\textcolor{green}{x}\) and red paths are \(\textcolor{red}{\hat{x}}\)</figcaption>
			<img src="images/tree_example4.png" alt="Tree Example 3" width="300">
		</figure>

		<table cellpadding="10" align="center">
			<br>
			<!-- <caption class="w3-opacity">Attributions.</caption> -->
			<thead class="w3-opacity">
				<tr>
					<th>Feature</th>
					<th>\(\phi_i(f,x,\hat{x})\)</th>
				</tr>
			</thead>
			<tbody>
				<tr bgcolor="#F8F8F8">
					<td align="left">\(x_1\)</td>
					<td align="left">\(\textcolor{green}{\text{Pos}_1}+\textcolor{green}{\text{Pos}_2}+\textcolor{red}{\text{Neg}_3}+\textcolor{red}{\text{Neg}_4}\)</td>
				</tr>
				<tr bgcolor="#F8F8F8">
					<td align="left">\(x_2\)</td>
					<td align="left">\(\textcolor{red}{\text{Neg}_1}+\textcolor{green}{\text{Pos}_2}+\textcolor{green}{\text{Pos}_3}+\textcolor{red}{\text{Neg}_4}\)</td>
				</tr>
			</tbody>
		</table>
	</div>



	<p class="w3-opacity w3-justify">
		In Figure 4, we can first observe that for each leaf, according to Theorem 1, there are only two possible values to compute (what we have been calling \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\)).  Based on the attributions for \(x_1\) we see that these \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms can be grouped by the left and right subtrees below \(x_1\).  To generalize this example, we make the following observation:
	</p>

	<p class="w3-opacity w3-justify">
		<strong>Observation:  In order to compute the attribution for any feature \(i\) it is sufficient to consider the paths that correspond to each Case 4 node's children.</strong>  First, focusing on a specific Case 4 node \(n\), we know that one child is associated with \(x\) child and one child is associated with \(\hat{x}\).  Then, the attribution to \(n_{feature}\) is:
		$$
		\sum_{\text{paths }P\text{ under }x\text{ child}}\textcolor{green}{\text{Pos}_P} + \sum_{\text{paths }P\text{ under }\hat{x}\text{ child}}\textcolor{red}{\text{Neg}_P}
		$$

		Then, doing this for all nodes is equivalent to explaining all features (because SHAP values are additive).
	</p>

	<p class="w3-opacity w3-justify">
		Furthermore, this observation suggests that we can always add the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms at a given node and pass them up to the parent.  This information is sufficient to calculate the attributions for each upstream feature.  This aggregation of the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms is the dynamic programming observation that allows each upstream node to only need a constant number of operations to compute its feature's attribution.
	</p>

	<p class="w3-opacity w3-justify">
		Using this observation, we devise an algorithm that computes the attributions for all features simultaneously:
	</p>

	<!-- Pseudocode -->
	<div style="background-color:#e6ffee;">

		<div style="padding-left:10px;padding-right:10px">

			<p class="w3-justify"><a onclick="hideshow('pseudocode_dynamic')"><strong>DP Pseudocode (Click)</strong></a></a></p>

			<!-- <div id="pseudocode_dynamic", style="display:none"> -->
			<div id="pseudocode_dynamic">
			<p class="no-margin w3-opacity w3-justify">
				ITE_D(tree \(t\), array \(x\), array \(\hat{x}\)):
			</p>
			<ul class="no-margin w3-opacity w3-justify">
				\(\phi=\) [0]*\(len(x)\) <br>

				RECURSE(node \(n\), int \(S^c\), int \(N^c\), array \(x_a\), array \(\hat{x}_a\)):
				<ul style="font-family:courier;font-size:16px">
					<font color="#8E44AD">// Case 1: At a leaf</font><br>
					if \(n\) is a leaf:
					<ul style="font-family:courier;font-size:16px">
						if \(U==0\): return (0,0)<br>
						else: return (\(W(S^c,N-1)\times n_{value}\),\(-W(S^c,N^c)\times n_{value}\))
					</ul>
					<font color="#8E44AD">// Find children associated with \(x\) and \(\hat{x}\)</font><br>
					\(x_{child} =\) \(n_{leftchild}\) if \(x[n_{feature}] < n_{threshold}\) else \(x_{child}\) = \(n_{rightchild}\) <br>
					\(\hat{x}_{child} =\) \(n_{leftchild}\) if \(\hat{x}[n_{feature}] < n_{threshold}\) else \(\hat{x}_{child}\) = \(n_{rightchild}\) <br>
					<font color="#8E44AD">// Case 2: Feature was encountered previously</font><br>
					if \(x_a[n_{feature}]>0\):
					<ul style="font-size:16px">
						return RECURSE(\(x_{child}\),\(S^c\),\(N^c\),\(x_a\),\(\hat{x}_a\))
					</ul>
					if \(\hat{x}_a[n_{feature}]>0\):
					<ul style="font-size:16px">
						return RECURSE(\(\hat{x}_{child}\),\(S^c\),\(N^c\),\(x_a\),\(\hat{x}_a\))
					</ul>

					<font color="#8E44AD">// Case 3: \(x\) and \(\hat{x}\) go to same children</font><br>
					if \(x_{child}==\hat{x}_{child}\):
					<ul style="font-size:16px">
						return RECURSE(\(x_{child}\),\(S^c\),\(N^c\),\(x\),\(\hat{x}\))
					</ul>
					<font color="#8E44AD">// Case 4: \(x\) and \(\hat{x}\) go to different children</font><br>
					\(X_a =\) copy(\(x_a\)); \(X_a[n_{feature}]=X_a[n_{feature}]+1\)<br>
					\(\hat{X}_a =\) copy(\(\hat{x}_a\)); \(\hat{X}_a[n_{feature}]=\hat{X}_a[n_{feature}]+1\)<br>
					if not \(x_{child}==\hat{x}_{child}\):
					<ul style="font-size:16px">
						\(pos_x,neg_x=\) RECURSE(\(x_{child}\),\(S^c+1\),\(N^c+1\),\(X_a\),\(\hat{x}_a\))<br>
						\(pos_{\hat{x}},neg_{\hat{x}}=\) RECURSE(\(\hat{x}_{child}\),\(S^c\),\(N^c+1\),\(x_a\),\(\hat{X}_a\))<br>
						\(\phi[n_{feature}]=\phi[n_{feature}]+pos_{x}+neg_{\hat{x}}\)<br>
						return (\(pox_{x}+pox_{\hat{x}}\),\(neg_{x}+neg_{\hat{x}}\))
					</ul>
				</ul>
				return RECURSE(tree.root, 0, 0, [0]*\(len(x)\), [0]*\(len(x)\))
			</ul> 
			</div>

		</div>

	</div>

    <p class="w3-opacity w3-justify">
		The computational complexity to compute \(\phi_i(f,x,\hat{x})\) using <font style="font-family:courier">ITE_D()</font> for all features is now just \(O(T_{numnodes})\) where \(T_{numnodes}\) is the number of nodes in the tree.  This is because every case for each node now only requires a constant amount of work.  
	</p>

    <p class="w3-opacity w3-justify">
		Finally, our original goal was to compute \(\phi_i(f,x)\).  We simply need to compute \(\phi_i(f,x,\hat{x})\) for many references, resulting in a run time of \(O(|D|T_{numnodes})\) where \(|D|\) is the number of samples in the background distribution.  In practice, using a fixed number of about 100 to 1000 references works well.
	</p>

    <h3 class="w3-justify" id="comparison_of_methods">2.5 Comparison of SHAP Methods</h3>

    <p class="w3-opacity w3-justify">
    	It should be noted that there are a number of alternative methods (Path Dependent Tree Explainer, Kernel Explainer, and Sampling Explainer) in the SHAP package.  If you are explaining tree-based models, it may not be clear which one you should use.  In this article we briefly overview the methods and compare them to ITE:
	</p>

    <p class="w3-opacity w3-justify">
    	<ul class="w3-opacity w3-justify">
    		<li>Path Dependent Tree Explainer (PDTE): </li>
    		<ul>
    			<li>Like ITE, PDTE is also meant to obtain SHAP values for tree models.</li> 
				<li>PDTE approximates the interventional conditional expectation based on how many training samples went down paths in the tree, whereas ITE computes it exactly.</li>
				<li>The computational complexity is \(O(T_{numleaves}T_{depth}^2)\).  In practice, PDTE can be faster than ITE, although it may depend on the number of references or the tree depth.</li>
    		</ul>
    		<li>Sampling Explainer:</li>
    		<ul>
    			<li>A model agnostic approach to obtain SHAP values.</li>
    			<li>An extension of Interactions-based Method for Explanation (IME) (<a href="#Strumbelj2010efficientexplanations">Strumbelj and Kononenko 2010</a>).</li> 
    			<li>This approach is sampling based and converges to the SHAP values ITE obtains, but in practice is much slower than ITE.</li>
    		</ul>    		
    		<li>Kernel Explainer (<a href="#lundberg_unified">Lundberg 2019</a>):</li>
    		<ul>
    			<li>A model agnostic approach to obtain SHAP values.</li>
    			<li>An extension of Local Interpretable Model-agnostic Explanations (LIME) (<a href="#ribeiro2016lime">Ribeiro et. al. 2016</a>).</li> 
    			<li>This approach is sampling based and converges to the SHAP values ITE obtains, but in practice is much slower than ITE.</li>
    		</ul>
    	</ul>
	</p>

    <p class="w3-opacity w3-justify">
		For an in-depth empirical comparison of these methods, please refer to <a href="https://www.nature.com/articles/s42256-019-0138-9.epdf?shared_access_token=RCYPTVkiECUmc0CccSMgXtRgN0jAjWel9jnR3ZoTv0O81kV8DqPb2VXSseRmof0Pl8YSOZy4FHz5vMc3xsxcX6uT10EzEoWo7B-nZQAHJJvBYhQJTT1LnJmpsa48nlgUWrMkThFrEIvZstjQ7Xdc5g%3D%3D">our paper</a> (<a href="#lundberg2020fromlocal">Lundberg 2020</a>).
	</p>	


    <h2 class="w3-justify" id="references">References</h2>
    <ol class="w3-justify w3-opacity">
    	 <li id="rudin2019">Rudin, Cynthia. "Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead." Nature Machine Intelligence 1.5 (2019): 206-215.</li>

      <li id="matsui2001NP">Matsui, Yasuko, and Tomomi Matsui. "NP-completeness for calculating power indices of weighted majority games." Theoretical Computer Science 263.1-2 (2001): 305-310.</li>

      <li id="lundberg2020fromlocal">Lundberg, Scott M., et al. "From local explanations to global understanding with explainable AI for trees." Nature Machine Intelligence (2020)</li>

      <li id="schervish1996">Schervish, Mark J. "P values: what they are and what they are not." The American Statistician 50.3 (1996): 203-206.</li>

    	<li id="young_uniquesol">Young, H. Peyton. "Monotonic solutions of cooperative games." International Journal of Game Theory 14.2 (1985): 65-72.</li>

    	<li id="lundberg_unified">Lundberg, Scott M., and Su-In Lee. "A unified approach to interpreting model predictions." Advances in neural information processing systems. 2017.</li>

    	<li id="pearl_2000_causality">Pearl, Judea. Causality. Cambridge university press, 2009.</li>

    	<li id="janzing2019feature">Janzing, Dominik, Lenon Minorics, and Patrick Blbaum. "Feature relevance quantification in explainable AI: A causality problem." arXiv preprint arXiv:1910.13413 (2019).</li>

    	<li id="sundararajan2019many">Sundararajan, Mukund, and Amir Najmi. "The many Shapley values for model explanation." arXiv preprint arXiv:1908.08474 (2019).</li>

    	<li id="chen2019explaining">Chen, Hugh, Scott Lundberg, and Su-In Lee. "Explaining Models by Propagating Shapley Values of Local Components." arXiv preprint arXiv:1911.11888 (2019).</li>

    	<li id="Strumbelj2010efficientexplanations">Strumbelj, Erik and Kononenko, Igor. "An efficient explanation of individual classifications using game theory." Journal of Machine Learning Research 11.Jan (2010): 1-18.</li>

    	<li id="ribeiro2016lime">Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. "'Why should i trust you?' Explaining the predictions of any classifier." Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 2016.</li>
    </ol>

    <h2 class="w3-justify" id="references">Acknowledgements</h2>

    <p class="w3-opacity w3-justify">This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1762114.  Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation.</p>

	</div>

  </div>

</div>

<!-- Footer -->
<footer class="w3-container w3-padding-64 w3-center w3-opacity w3-light-grey w3-xlarge" style="margin-left:300px">
  <i class="fa fa-linkedin w3-hover-opacity"></i>
</footer>

<!-- Figure 1 - Kaggle methods d3 bar plot -->
<script src="kaggleMethods.js"></script>

<!-- Example 1 - Computing Shapley values -->
<script src="shapleyValues.js"></script>

<!-- Example 2 - Computing Shapley values CES vs RBS -->
<script src="linearModelCESvsRBS.js"></script>

<!-- Example 3 - Initial tree parameters -->
<script src="treeData0.js"></script>

<!-- Example 3 - Creating tree and samples -->
<script src="createTreeSamples.js"></script>

<!-- Example 4 - Brute force algorithm -->
<script src="brute_force_ex.js"></script>

<!-- Example 5 - Naive tree algorithm -->
<script>
/////////////////////////////////////
////// Example 5 Tree Diagram ///////
/////////////////////////////////////
var margin5 = {top: 0, right: 0, bottom: 0, left: 0},
  width5 = 500 - margin5.right - margin5.left,
  height5 = 350 - margin5.top - margin5.bottom;

var tree5 = d3.layout.tree()
  .size([height5, width5]);

var diagonal5 = d3.svg.diagonal()
  .projection(function(d) { return [d.x, d.y]; });

var svg5 = d3.select("#ex5_divtree").append("svg")
  .attr("width", width5 + margin5.right + margin5.left)
  .attr("height", height5 + margin5.top + margin5.bottom)
  .append("g")
  .attr("transform", "translate(" + margin5.left + "," + margin5.top + ")");

update5(treeData[0]);

function update5(source) {
	/* @desc Update tree SVG (doesn't seem to update text for some reason) */

	// Compute the new tree layout.
	var nodes = tree5.nodes(source).reverse(),
	links = tree5.links(nodes);

	// Normalize for fixed-depth.
	nodes.forEach(function(d) { d.y = d.depth * 90 + 20; });
	nodes.forEach(function(d) { d.x = d.x * 1.4; });

	// Declare the nodes
	var node = svg5.selectAll("g.node")
		.data(nodes, function(d) { return d.id || (d.id = ++i); });

	// Enter the nodes.
	var nodeEnter = node.enter().append("g")
		.attr("class", "node")
		.attr("transform", function(d) { 
		  return "translate(" + d.x + "," + d.y + ")"; })

	nodeEnter.append("circle")
		.attr("r", 10)
		.style("fill", "#fff")

	nodeEnter.append("text")
		.attr("y", function(d) { 
		  return d.children || d._children ? 0 : 20; })
		.attr("x", function(d) { 
		  return d.children || d._children ? 15 : 0; })
		.attr("dy", ".35em")
		.attr("text-anchor", function(d) {
			if (d.name.startsWith("Leaf")) {
				return "middle"
			}
		})
	.text(function(d) { 
		if (d.name.startsWith("Leaf")) {
			return d.value;
		} else {
			return d.variable + ">" + d.threshold;   
		}
	})
	.style("font-family", "courier")
	.style("font-size", "16px")
	.style("fill-opacity", 1);

	// Declare the links
	var link = svg5.selectAll("path.link")
	.data(links, function(d) { return d.target.id; });

	// Enter the links.
	link.enter().insert("path", "g")
	.attr("class", "link")
	.attr("d", diagonal);
}

///////////////////////////////////////
////// Example 5 Naive tree algo //////
///////////////////////////////////////
function ex5_reset_tree() {
	var nodes = tree5.nodes(treeData[0]).reverse(), links = tree5.links(nodes);
	var link = svg5.selectAll("path.link").data(links, 
		function(d) { return d.target.id; });

	// Update colors
	link[0].forEach(function(d) {
		var stroke = document.createAttribute("stroke");
		d.attributes.setNamedItem(stroke);
	});
}

function ex5_color_tree(s_t_pairs, colors) {
	var nodes = tree5.nodes(treeData[0]).reverse(), links = tree5.links(nodes);
	var link = svg5.selectAll("path.link").data(links, 
		function(d) { return d.target.id; });

	// Remove colors
	// ex5_reset_tree();

	// Color the appropriate pairs
	for (var j=0; j<s_t_pairs.length; j++) {
		s_t_pair = s_t_pairs[j];
		color    = colors[j]

		// Update colors
		link[0].forEach(function(d) {
			var d2 = d.__data__;
			is_source = (d2.source.name == s_t_pair[0].name)
			is_target = (d2.target.name == s_t_pair[1].name)
			if (is_source & is_target) {
				var stroke = document.createAttribute("stroke");
				stroke.value = color;
				d.attributes.setNamedItem(stroke);				
			}
		});
	}
}

var newColor = "rgb(210, 180, 222)";

function reset_all_node_colors() {
	var nodes = svg5.selectAll("g.node");
	nodes[0].forEach(function (d) {
		oldHTML = d.innerHTML;
		if (oldHTML.includes(newColor)) {
			splitHTML = oldHTML.split(newColor);
			prefix = splitHTML[0];
			suffix = splitHTML[1];
			newHTML = prefix + "rgb(255, 255, 255)" + suffix;
			d.innerHTML = newHTML;			
		}
	})
}

function reset_node_color(node_name) {
	var nodes = svg5.selectAll("g.node");
	nodes[0].forEach(function (d) {
		if (d.__data__["name"] == node_name) {
			oldHTML = d.innerHTML;
			if (oldHTML.includes(newColor)) {
				splitHTML = oldHTML.split(newColor);
				prefix = splitHTML[0];
				suffix = splitHTML[1];
				newHTML = prefix + "rgb(255, 255, 255)" + suffix;
				d.innerHTML = newHTML;
			}
		}
	})
}

function change_node_color(node_name) {
	var nodes = svg5.selectAll("g.node");
	nodes[0].forEach(function (d) {
		if (d.__data__["name"] == node_name) {
			oldHTML = d.innerHTML;
			if (oldHTML.includes("rgb(255, 255, 255)")) {
				splitHTML = oldHTML.split("rgb(255, 255, 255)");
				prefix = splitHTML[0];
				suffix = splitHTML[1];
				newHTML = prefix + newColor + suffix;
				d.innerHTML = newHTML;
			}
		}
	})
}

function ex5_update_str(str) {
	document.getElementById("ex5_naive_step").innerHTML = str;
}

function ex5_update_np_sp() {
	document.getElementById("ex5_sp").innerHTML = "["+sp_lst+"]";
	document.getElementById("ex5_np").innerHTML = "["+np_lst+"]";
}

function ex5_update_phi() {
	for (var i = 0; i < ex5_phi.length; i++) {
		document.getElementById("ex5_phi"+(i+1)+"_val").innerHTML = ex5_phi[i];
	}
}

function ex5_update_h() {
	for (var i = 0; i < h.length; i++) {
		if (h[i] == "none") {
			document.getElementById("ex5_h"+(i+1)).innerHTML = "";
		} else {
			document.getElementById("ex5_h"+(i+1)).innerHTML = h[i];
		}
	}
}

function fact(x) {
	if (x == 0) {
		return(1);
	} else if (x == 1) {
		return(1);
	} else if (x == 2) {
		return(2);
	} else if (x == 3) {
		return(6);
	} else if (x == 4) {
		return(24);
	}
}

function compute_W(s_len, n_len) {
	var num = fact(s_len) * fact(n_len-s_len-1);
	var den = fact(n_len);
	return(num/den);
}

function ex5_reset() {
	// Reset variables
	is_initialize = true;
	ex5_phi = [0,0,0];
	prevnode = treeData[0];
	nextnodes = [];
	nodesseen = [];
	np_lst = [];
	sp_lst = [];
	h = ["none", "none", "none"];
	h_dict = {};
	h_dict[treeData[0].name] = h;
	np_dict = {};
	sp_dict = {};
	np_dict[treeData[0].name] = [];
	sp_dict[treeData[0].name] = [];

	ex5_update_str("Naive Algorithm");
	ex5_update_np_sp();
	ex5_update_phi();
	ex5_update_h();

	// Reset tree
	reset_all_node_colors();
	ex5_reset_tree();

	// Update text
	svg5.selectAll("g.node").remove();
	update5(treeData[0]);
}

var is_initialize = true;
var ex5_phi = [0,0,0];
var currnode;
var prevnode = treeData[0];
var nextnodes = [];
var nodesseen = [];
var np_lst = [];
var sp_lst = [];
var h = ["none", "none", "none"];
var h_dict = {};
h_dict[treeData[0].name] = h;
var np_dict = {};
var sp_dict = {};
np_dict[treeData[0].name] = [];
sp_dict[treeData[0].name] = [];

function naiveRunAll() {
	for (var i = 0; i < 20; i++) {
		naiveStep();
	}
}

function naiveStep() {
	if (is_initialize) {
		ex5_update_str('<strong>Case 0</strong>: Initialize');
		ex5_update_np_sp();
		ex5_update_phi();

		is_initialize = false;
		nextnodes.push(treeData[0]);
		return(1);
	}

	if (nextnodes.length == 0) {
		return(1);
	}

	if (currnode) {
		reset_node_color(currnode["name"]);
	}
	currnode = nextnodes.pop();
	change_node_color(currnode["name"]);

	np_lst = np_dict[currnode.name];
	sp_lst = sp_dict[currnode.name];
	h = h_dict[currnode.name];

	ex5_update_np_sp();
	ex5_update_h();

	// Case 1: at a leaf
	if (currnode["name"].includes("Leaf")) {
		var value = currnode["value"];
		ex5_update_str('<strong>Case 1</strong>: At a leaf');
		for (var k = 0; k < ex5_phi.length; k++) {
			var currvar = "x"+(k+1);
			if (np_lst.includes(currvar)) {
				if (sp_lst.includes(currvar)) {
					currW  = compute_W(sp_lst.length-1, np_lst.length);
					ex5_phi[k] = ex5_phi[k] + currW*value;
				} else {
					currW  = compute_W(sp_lst.length, np_lst.length);
					ex5_phi[k] = ex5_phi[k] - currW*value;
				}
			}
		}
		ex5_update_phi();
		return(1);
	}

	// Case 2-4: Internal node
	// Color both children of node
	n_thres = Number(currnode["threshold"]);
	n_var   = Number(currnode["variable"][1])-1;
	fxval   = foregroundx[n_var];
	bxval   = backgroundx[n_var];

	// Determine where foreground/background goes
	var lchild = currnode["children"][0];
	var rchild = currnode["children"][1];
    var fleft = false;
    var bleft = false;

	if (fxval <= n_thres) {
		fleft  = true;
		fchild = lchild;
	} else {
		fchild = rchild;
	}

	if (bxval <= n_thres) {
		bleft  = true;
		bchild = lchild;
	} else {
		bchild = rchild;
	}

	// Color the children of the current node
	var s_t_pairs = [];
	var colors = [];

	if (np_lst.includes(currnode.variable)) {
		ex5_update_str('<strong>Case 2</strong>: Previously seen feature');
		if (sp_lst.includes(n_var)) {
			s_t_pairs.push([currnode,fchild]);
			colors.push("#b3de69");
			if (!nodesseen.includes(currnode)) {
				nextnodes.push(fchild);
				np_dict[bchild.name] = np_lst;
				sp_dict[bchild.name] = sp_lst;
				h_dict[bchild.name]  = h;
			}
		} else {
			s_t_pairs.push([currnode,bchild]);
			colors.push("#fb8072");
			if (!nodesseen.includes(currnode)) {
				nextnodes.push(bchild);
				np_dict[bchild.name] = np_lst;
				sp_dict[bchild.name] = sp_lst;
				h_dict[bchild.name]  = h;
			}
		}
	} else if (fchild == bchild) {
		ex5_update_str('<strong>Case 3</strong>: Foreground and background match');
		s_t_pairs.push([currnode,fchild]);
		colors.push("#80b1d3");
		
		if (!nodesseen.includes(currnode)) {
			np_dict[bchild.name] = np_lst;
			sp_dict[bchild.name] = sp_lst;
			h_dict[bchild.name]  = h;
			nextnodes.push(fchild);
		}
	} else {
		ex5_update_str('<strong>Case 4</strong>: Foreground and background differ');
		s_t_pairs.push([currnode,fchild]);
		colors.push("#b3de69");

		s_t_pairs.push([currnode,bchild]);
		colors.push("#fb8072");

		if (!nodesseen.includes(currnode)) {
			np_dict[fchild.name] = np_lst.concat([currnode.variable]);
			sp_dict[fchild.name] = sp_lst.concat([currnode.variable]);

			var h2 = h.slice();
			h2[n_var] = foregroundx[n_var];
			h_dict[fchild.name]  = h2;

			np_dict[bchild.name] = np_lst.concat([currnode.variable]);
			sp_dict[bchild.name] = sp_lst;

			var h3 = h.slice();
			h3[n_var] = backgroundx[n_var];
			h_dict[bchild.name]  = h3;

			nextnodes.push(rchild);
			nextnodes.push(currnode);
			nextnodes.push(lchild);
		}
	}
	ex5_color_tree(s_t_pairs, colors);
	prevnode = currnode;
	nodesseen.push(currnode);
}



</script>


</body>
</html>
