<!DOCTYPE html>
<html lang="en">
<title>Shapley values for trees</title>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<link rel="stylesheet" type="text/css" href="index.css">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css" integrity="sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js" integrity="sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjs/3.2.1/math.js"></script>
<script src="https://d3js.org/d3.v4.min.js"></script>
<script>d3v4 = d3;</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js"></script>
<script src="local_template.v1.js"></script>
<style id="distill-prerendered-styles">/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

html {
  font-size: 14px;
  line-height: 1.6em;
  /* font-family: "Libre Franklin", "Helvetica Neue", sans-serif; */
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  /*, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";*/
  text-size-adjust: 100%;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}

@media(min-width: 768px) {
  html {
    font-size: 16px;
  }
}

body {
  margin: 0;
}

a {
  color: #004276;
}

figure {
  margin: 0;
}

table {
  border-collapse: collapse;
  border-spacing: 0;
}

table th {
  text-align: left;
}

table thead {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

table thead th {
  padding-bottom: 0.5em;
}

table tbody :first-child td {
  padding-top: 0.5em;
}

pre {
  overflow: auto;
  max-width: 100%;
}

p {
  margin-top: 0;
  margin-bottom: 1em;
}

sup, sub {
  vertical-align: baseline;
  position: relative;
  top: -0.4em;
  line-height: 1em;
}

sub {
  top: 0.4em;
}

.kicker,
.marker {
  font-size: 15px;
  font-weight: 600;
  color: rgba(0, 0, 0, 0.5);
}


/* Headline */

@media(min-width: 1024px) {
  d-title h1 span {
    display: block;
  }
}

/* Figure */

figure {
  position: relative;
  margin-bottom: 2.5em;
  margin-top: 1.5em;
}

figcaption+figure {

}

figure img {
  width: 100%;
}

figure svg text,
figure svg tspan {
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@supports not (display: grid) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    display: block;
    padding: 8px;
  }
}

.base-grid,
distill-header,
d-title,
d-abstract,
d-article,
d-appendix,
distill-appendix,
d-byline,
d-footnote-list,
d-citation-list,
distill-footer {
  display: grid;
  justify-items: stretch;
  grid-template-columns: [screen-start] 8px [page-start kicker-start text-start gutter-start middle-start] 1fr 1fr 1fr 1fr 1fr 1fr 1fr 1fr [text-end page-end gutter-end kicker-end middle-end] 8px [screen-end];
  grid-column-gap: 8px;
}

.grid {
  display: grid;
  grid-column-gap: 8px;
}

@media(min-width: 768px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start middle-start text-start] 45px 45px 45px 45px 45px 45px 45px 45px [ kicker-end text-end gutter-start] 45px [middle-end] 45px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1000px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 50px [middle-start] 50px [text-start kicker-end] 50px 50px 50px 50px 50px 50px 50px 50px [text-end gutter-start] 50px [middle-end] 50px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 16px;
  }

  .grid {
    grid-column-gap: 16px;
  }
}

@media(min-width: 1180px) {
  .base-grid,
  distill-header,
  d-title,
  d-abstract,
  d-article,
  d-appendix,
  distill-appendix,
  d-byline,
  d-footnote-list,
  d-citation-list,
  distill-footer {
    grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
    grid-column-gap: 32px;
  }

  .grid {
    grid-column-gap: 32px;
  }
}




.base-grid {
  grid-column: screen;
}

/* .l-body,
d-article > *  {
  grid-column: text;
}

.l-page,
d-title > *,
d-figure {
  grid-column: page;
} */

.l-gutter {
  grid-column: gutter;
}

.l-text,
.l-body {
  grid-column: text;
}

.l-page {
  grid-column: page;
}

.l-body-outset {
  grid-column: middle;
}

.l-page-outset {
  grid-column: page;
}

.l-screen {
  grid-column: screen;
}

.l-screen-inset {
  grid-column: screen;
  padding-left: 16px;
  padding-left: 16px;
}


/* Aside */

d-article aside {
  grid-column: gutter;
  font-size: 12px;
  line-height: 1.6em;
  color: rgba(0, 0, 0, 0.6)
}

@media(min-width: 768px) {
  aside {
    grid-column: gutter;
  }

  .side {
    grid-column: gutter;
  }
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-title {
  padding: 2rem 0 1.5rem;
  contain: layout style;
  overflow-x: hidden;
}

@media(min-width: 768px) {
  d-title {
    padding: 4rem 0 1.5rem;
  }
}

d-title h1 {
  grid-column: text;
  font-size: 40px;
  font-weight: 700;
  line-height: 1.1em;
  margin: 0 0 0.5rem;
}

@media(min-width: 768px) {
  d-title h1 {
    font-size: 50px;
  }
}

d-title p {
  font-weight: 300;
  font-size: 1.2rem;
  line-height: 1.55em;
  grid-column: text;
}

d-title .status {
  margin-top: 0px;
  font-size: 12px;
  color: #009688;
  opacity: 0.8;
  grid-column: kicker;
}

d-title .status span {
  line-height: 1;
  display: inline-block;
  padding: 6px 0;
  border-bottom: 1px solid #80cbc4;
  font-size: 11px;
  text-transform: uppercase;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-byline {
  contain: style;
  overflow: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  font-size: 0.8rem;
  line-height: 1.8em;
  padding: 1.5rem 0;
  min-height: 1.8em;
}


d-byline .byline {
  grid-template-columns: 1fr 1fr;
  grid-column: text;
}

@media(min-width: 768px) {
  d-byline .byline {
    grid-template-columns: 1fr 1fr; 
    /*Modified to have two columns*/
  }
}

d-byline .authors-affiliations {
  grid-column-end: span 2;
  grid-template-columns: 1fr 1fr;
  margin-bottom: 1em;
}

@media(min-width: 768px) {
  d-byline .authors-affiliations {
    margin-bottom: 0;
  }
}

d-byline h3 {
  font-size: 0.6rem;
  font-weight: 400;
  color: rgba(0, 0, 0, 0.5);
  margin: 0;
  text-transform: uppercase;
}

d-byline p {
  margin: 0;
}

d-byline a,
d-article d-byline a {
  color: rgba(0, 0, 0, 0.8);
  text-decoration: none;
  border-bottom: none;
}

d-article d-byline a:hover {
  text-decoration: underline;
  border-bottom: none;
}

d-byline p.author {
  font-weight: 500;
}

d-byline .affiliations {

}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

d-article {
  contain: layout style;
  overflow-x: hidden;
  border-top: 1px solid rgba(0, 0, 0, 0.1);
  padding-top: 2rem;
  color: rgba(0, 0, 0, 0.8);
}

d-article > * {
  grid-column: text;
}

@media(min-width: 768px) {
  d-article {
    font-size: 16px;
  }
}

@media(min-width: 1024px) {
  d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
  }
}


/* H2 */


d-article .marker {
  text-decoration: none;
  border: none;
  counter-reset: section;
  grid-column: kicker;
  line-height: 1.7em;
}

d-article .marker:hover {
  border: none;
}

d-article .marker span {
  padding: 0 3px 4px;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
  position: relative;
  top: 4px;
}

d-article .marker:hover span {
  color: rgba(0, 0, 0, 0.7);
  border-bottom: 1px solid rgba(0, 0, 0, 0.7);
}

d-article h2 {
  font-weight: 600;
  font-size: 24px;
  line-height: 1.25em;
  margin: 2rem 0 1.5rem 0;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  padding-bottom: 1rem;
}

@media(min-width: 1024px) {
  d-article h2 {
    font-size: 36px;
  }
}

/* H3 */

d-article h3 {
  font-weight: 700;
  font-size: 18px;
  line-height: 1.4em;
  margin-bottom: 1em;
  margin-top: 2em;
}

@media(min-width: 1024px) {
  d-article h3 {
    font-size: 20px;
  }
}

/* H4 */

d-article h4 {
  font-weight: 600;
  text-transform: uppercase;
  font-size: 14px;
  line-height: 1.4em;
}

d-article a {
  color: inherit;
}

d-article p,
d-article ul,
d-article ol,
d-article blockquote {
  margin-top: 0;
  margin-bottom: 1em;
  margin-left: 0;
  margin-right: 0;
}

d-article blockquote {
  border-left: 2px solid rgba(0, 0, 0, 0.2);
  padding-left: 2em;
  font-style: italic;
  color: rgba(0, 0, 0, 0.6);
}

d-article a {
  border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  text-decoration: none;
}

d-article a:hover {
  border-bottom: 1px solid rgba(0, 0, 0, 0.8);
}

d-article .link {
  text-decoration: underline;
  cursor: pointer;
}

d-article ul,
d-article ol {
  padding-left: 24px;
}

d-article li {
  margin-bottom: 1em;
  margin-left: 0;
  padding-left: 0;
}

d-article li:last-child {
  margin-bottom: 0;
}

d-article pre {
  font-size: 14px;
  margin-bottom: 20px;
}

d-article hr {
  grid-column: screen;
  width: 100%;
  border: none;
  border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article section {
  margin-top: 60px;
  margin-bottom: 60px;
}

d-article span.equation-mimic {
  font-family: georgia;
  font-size: 115%;
  font-style: italic;
}

d-article > d-code,
d-article section > d-code  {
  display: block;
}

d-article > d-math[block],
d-article section > d-math[block]  {
  display: block;
}

@media (max-width: 768px) {
  d-article > d-code,
  d-article section > d-code,
  d-article > d-math[block],
  d-article section > d-math[block] {
      overflow-x: scroll;
      -ms-overflow-style: none;  // IE 10+
      overflow: -moz-scrollbars-none;  // Firefox
  }

  d-article > d-code::-webkit-scrollbar,
  d-article section > d-code::-webkit-scrollbar,
  d-article > d-math[block]::-webkit-scrollbar,
  d-article section > d-math[block]::-webkit-scrollbar {
    display: none;  // Safari and Chrome
  }
}

d-article .citation {
  color: #668;
  cursor: pointer;
}

d-include {
  width: auto;
  display: block;
}

d-figure {
  contain: layout style;
}

/* KaTeX */

.katex, .katex-prerendered {
  contain: style;
  display: inline-block;
}

/* Tables */

d-article table {
  border-collapse: collapse;
  margin-bottom: 1.5rem;
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table th {
  border-bottom: 1px solid rgba(0, 0, 0, 0.2);
}

d-article table td {
  border-bottom: 1px solid rgba(0, 0, 0, 0.05);
}

d-article table tr:last-of-type td {
  border-bottom: none;
}

d-article table th,
d-article table td {
  font-size: 15px;
  padding: 2px 8px;
}

d-article table tbody :first-child td {
  padding-top: 2px;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

span.katex-display {
  text-align: left;
  padding: 8px 0 8px 0;
  margin: 0.5em 0 0.5em 1em;
}

span.katex {
  -webkit-font-smoothing: antialiased;
  color: rgba(0, 0, 0, 0.8);
  font-size: 1.18em;
}
/*
 * Copyright 2018 The Distill Template Authors
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

@media print {

  @page {
    size: 8in 11in;
    @bottom-right {
      content: counter(page) " of " counter(pages);
    }
  }

  html {
    /* no general margins -- CSS Grid takes care of those */
  }

  p, code {
    page-break-inside: avoid;
  }

  h2, h3 {
    page-break-after: avoid;
  }

  d-header {
    visibility: hidden;
  }

  d-footer {
    display: none!important;
  }

}
</style>

<style>
hover a {
    color: "Olive";
}

.no-margin {
	margin:0px;
	font-family:courier;
	font-size:16px;
}

.responsive {
	width: 100%;
	height: auto;
}

.bar {
    fill: #4DAF51;
}

.bar:hover {
	fill: #019788;
}

.axis {
    font-size: 14px;
}

.axis path,
.axis line {
    fill: none;
    display: none;
    shape-rendering: crispEdges;
}

.label {
	color: #4DAF51;
    font-size: 14px;
}

.d3-tip:after {
  box-sizing: border-box;
  display: inline;
  font-size: 10px;
  width: 100%;
  line-height: 1;
  color: rgba(0, 0, 0, 0.8);
  content: "\25BC";
  position: absolute;
  text-align: center;
}

.d3-tip.n:after {
  margin: -1px 0 0 0;
  top: 100%;
  left: 0;
}

#table_container {
	/*margin: 0 auto;*/
	background-color : #F4F6F6;
}

.slidecontainer {
  width: 100%;
}

.slider {
  -webkit-appearance: none;
  width: 100%;
  height: 15px;
  border-radius: 5px;
  background: #d3d3d3;
  outline: none;
  opacity: 0.7;
  -webkit-transition: .2s;
  transition: opacity .2s;
}

.slider:hover {
  opacity: 1;
}

.slider::-webkit-slider-thumb {
  -webkit-appearance: none;
  appearance: none;
  width: 25px;
  height: 25px;
  border-radius: 50%;
  background: #4CAF50;
  cursor: pointer;
}

.slider::-moz-range-thumb {
  width: 25px;
  height: 25px;
  border-radius: 50%;
  background: #4CAF50;
  cursor: pointer;
}

.node circle {
	fill: #fff;
	stroke: #ccc;
	stroke-width: 4px;
}

.node text { font: 12px sans-serif; }

.link {
	fill: none;
	stroke-width: 3px;
}

div.tooltip {
	position: absolute;
}

.container {
	width: 760px;
}

.first {
	width: 380px;
	float: left;
	height: 630px;
}

.second {
	width: 380px;
	float: left;
	height: 630px;
}

figcaption,
.figcaption {
  color: rgba(0, 0, 0, 0.6);
  font-size: 12px;
  line-height: 1.5em;
}

@media(min-width: 1024px) {
figcaption,
.figcaption {
    font-size: 13px;
  }
}

figure.external img {
  background: white;
  border: 1px solid rgba(0, 0, 0, 0.1);
  box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
  padding: 18px;
  box-sizing: border-box;
}

figcaption a {
  color: rgba(0, 0, 0, 0.6);
}

figcaption b,
figcaption strong, {
  font-weight: 600;
  color: rgba(0, 0, 0, 1.0);
}

a.figure-number,
a.section-number {
    border-bottom-color: hsla(206, 90%, 20%, 0.3);
    text-transform: uppercase;
    font-size: .85em;
    color: hsla(206, 90%, 20%, 0.7);
}
a.figure-number::before {
    content: "Figure ";
}
a.figure-number:hover,
a.section-number:hover {
    border-bottom-color: hsla(206, 90%, 20%, 0.6);
}

.svg-container {
  display: inline-block;
  position: relative;
  width: 100%;
  padding-bottom: 100%; /* aspect ratio */
  vertical-align: top;
  overflow: hidden;
}
.svg-content-responsive {
  display: inline-block;
  position: absolute;
  top: 10px;
  left: 0;
}

svg .rect {
  fill: gold;
  stroke: steelblue;
  stroke-width: 5px;
}

.no-space {
  margin-top:0px;
  margin-bottom:0px;
  /*line-height:0.1em;*/
  /*padding-top:0.3em;*/
  padding-bottom:0.0em;
}

pre {
  background: #f5f2f0;
}
</style>

<head>
  <link href="prism.css" rel="stylesheet" />
</head>


<body>



  <d-front-matter>
    <code style="display: none;" type="text/json"
      >{ "title": "Understanding Shapley value explanation algorithms for trees", "description": "Game theoretic Shapley values have recently become a popular way to explain the predictions of tree-based machine learning models. This rise in popularity was made possible by new efficient algorithms. Here we examine how these algorithms work, and how they solve what is in general an NP-hard problem in linear time for trees.",
      "authors": [
        { "author": "Hugh Chen", "authorURL": "http://hughchen.github.io/", "affiliation": "Paul G. Allen School of CSE", "affiliationURL": "https://www.cs.washington.edu/"  },
        { "author": "Scott Lundberg", "authorURL": "https://scottlundberg.com/", "affiliation": "Microsoft Research", "affiliationURL": "https://www.microsoft.com/en-us/research/"  },
        { "author": "Su-In Lee", "authorURL": "https://suinlee.cs.washington.edu/", "affiliation": "Paul G. Allen School of CSE", "affiliationURL": "https://www.cs.washington.edu/"  }
      ] }</code>
  </d-front-matter>

  <d-title>
    <h1 id="top">Understanding Shapley value explanation algorithms for trees</h1>
      <p style="font-size: 150%;">Game theoretic Shapley values have recently become a popular way to explain the predictions of tree-based machine learning models. This rise in popularity was made possible by new efficient algorithms. Here we examine how these algorithms work, and how they solve what is in general an NP-hard problem in linear time for trees.</p>
      <img src="./images/trees.jpg" alt="trees" style='grid-column: text; width: 100%; padding-top: 20px; padding-bottom:20px;'/>
  </d-title>
  <d-byline></d-byline>

  <d-article>
    <d-contents>
      <nav class="l-text toc figcaption">
        <a href="#top"><h3>Top</h3></a>
        <!--<div><a href="#introduction">Introduction</a></div>-->
        <!-- <div><a href="#introduction">Introduction</a></div> -->
        <div><a href="#background">Defining the feature attribution problem</a></div>
        <ul>
          <li><a href="#goal_feat_attr">The high level goal of feature attribution</a></li>
          <li><a href="#shapley_values">Back to basics with Shapley values</a></li>
          <li><a href="#shap_values">Adapting Shapley values to explain machine learning models</a></li>
          <li><a href="#masking_missing">Absence of a feature (masking)</a></li>
          <li><a href="#shap_conditional_distribution">Absence of a feature (conditioning)</a></li>
          <li><a href="#background_distribution">Baseline Shapley values</a></li>
        </ul>
        <div><a href="#algorithm">Explaining trees quickly and exactly</a></div>
        <ul>
          <li><a href="#define_tree_samples">Choose your own adventure</a></li>
          <li><a href="#brute_force">The brute force algorithm</a></li>
          <li><a href="#naive_implementation">The naive algorithm</a></li>
          <li><a href="#dynamic_programming_implementation">The dynamic algorithm</a></li>
          <li><a href="#final_considerations">Final considerations</a></li>
        </ul>
        <div><a href="#related_work">Related Work</a></div>
        <div><a href="#references">References</a></div>
      </nav>
    </d-contents>

  <!-- Introduction -->
  <div style="max-width:800px" id="abstract">
    <!-- <h2 id="introduction">Introduction</h2> -->
    <p>
      One of the most popular machine learning model types are tree-based models.  A 2017 survey of data scientists and researchers found that tree models were both the second and third most popular class of method (<a href="#fig1" class="figure-number">1</a>).  Although small tree models can be interpretable <d-cite bibtex-key="rudin2019stop"></d-cite>, most tree models are generally large and hard for humans to interpret.  
    </p>

  <!-- Figure 1 -->
  <figure>
    <div id="fig1"></div>
    <figcaption>
      <a href="#fig1" class="figure-number">1</a>: The most popular data science methods according to a <a href="https://www.kaggle.com/surveys/2017">2017 Kaggle survey</a> (based on a total of 7,301 responses).
    </figcaption>
  </figure>

    <p>
    This article discusses how to explain tree-based models with Shapley values - a unique game-theoretic solution for spreading credit between features.  First, we discuss how Shapley values can be applied to machine learning models (<a href="#background">Section 1</a>).  Then, since exactly computing Shapley values for an arbitrary model is NP-hard <d-cite bibtex-key="matsui2001np"></d-cite>, we discuss a recent exact algorithm focused specifically on tree models that runs in linear time (<a href="#algorithm">Section 2</a>).
    </p>

    <!-- <h3 id="motivation">Motivation</h3> -->
    <p>
    <i>What is the goal of this article?</i> 

    <p>
    Given that there is a long history of model explanations going awry when users do not understand what an explanation means (e.g., p-values for linear models <d-cite bibtex-key="schervish1996p"></d-cite>), it is critical to have a broadly accessible explanation of Shapley values and how they are obtained for tree models to ensure that they are not misused.  To this end, we aim to provide an easy to understand answer to two questions: 1.) What are Shapley values as used by popular package such as SHAP?  2.) How can we obtain Shapley values for trees?  In particular, we focus on explaining a linear-time algorithm to explain trees in the SHAP package called Interventional Tree Explainer (this algorithm was first introduced and empirically evaluated in <d-cite bibtex-key="lundberg2020local"></d-cite>).
  </p>
  </div>

  <hr>

  <!-- The Background Section -->
  <div style="max-width:800px">
    <h2 id="background">1. Defining the feature attribution problem</h2>
    
    <p>
     In this section, we introduce the notion of feature attributions.  Then, we introduce Shapley values and describe the ways in which they have been used to explain machine learning models, using an example with a linear model to motivate a specific extension of the Shapley values.  With this formulation, we show how obtaining these Shapley values reduces to an average of Baseline Shapley values that can be thought of as explanations with respect to a single foreground sample (sample being explained that we will denote as \(x^f\)) and a single background sample (sample the foreground sample is compared to that we will denote as \(x^b\)).
	</p>


  <h3 id="goal_feat_attr">1.1 The high level goal of feature attribution</h3>

    <p>
      The goal of feature attribution methods is to explain a model by assigning an importance value for each feature the model uses. In order to discuss the goal of feature attribution, it is useful to think about a linear model:
      $$
      f(x)=\beta_0 + \beta_1 x_1 + \cdots + \beta_d x_d
      $$
      Linear models are considered inherently interpretable because they summarize the importance for each feature with a scalar value where the importance (\(\phi\)) of a given feature (\(i\)) for a linear model (\(f\)) is:
      $$
      \phi_i(f)=\beta_i
      $$
      The attribution \(\phi_i(f)\) is known as a <i>global feature attribution</i> that explains the model as a whole.  This is possible because features in a linear model are constrained to have a linear relationship with the model prediction, so a sufficient statistic to describe the relationship between any feature and the output of the model is the slope of that feature.
    </p>

    <p>
      However, in many cases, it may be preferable to give a more individualized explanation that is not for the model as a whole, but rather for a specific sample's prediction (\(f(x^f)\)).  For linear models, we could do so by returning an attribution of the following form:
      $$
      \phi_i(f,x^f)=\beta_i x^f_i
      $$
      The attribution \(\phi_i(f,x^f)\) is known as a <i>local feature attribution</i> that explains the model for a specific individual.  Here, the attributions are easy to obtain because the relationship between \(x^f\) and \(f(x^f)\) is constrained to both be linear and consist only of marginal effects.
    </p>

    <p>
      However, many easily interpretable models require making unrealistic assumptions (e.g., linear relationships in linear models, strictly marginal or pairwise effects in generalized additive models).  Instead, if we use non-linear models that allow for complex interaction effects between variables, we can much better capture relationships in our data.  For these models, summarizing non-linear effects with a single number (a global feature attribution \(\phi_i(f)\)) may not make sense, because we no longer have a slope.  Instead, we can aim for local feature attributions (\(\phi_i(f,x^f)\)) that will explain the model's prediction for a specific individual.  In order to do so in a principled manner, we can turn to the Shapley values.
    </p>


    <!-- What are Shapley Values? -->
    <h3 id="shapley_values">1.2 Back to basics with Shapley values</h3>
	<p>
      Shapley values are a method to spread credit among players in a "coalitional game".  We can define the players to be a set \(N=\{1,\cdots,d\}\).  Then, the coalitional game is a function that maps subsets of the players to a scalar value:

    	$$
    	v(S):\text{Power Set}(N)\to\mathbb{R}^1
    	$$
    </p>

    <p>
      To make these concepts more concrete, we can imagine a company that makes a profit \(v(S)\) that is determined by what combination of individuals they employ \(S\).  Furthermore, let's assume we know \(v(S)\) for all possible teams of employees.  Then, the Shapley values assign credit to an individual \(i\) by taking a weighted average of how much the profit increases when \(i\) works with a group \(S\) versus when he does not work with \(S\).  Repeating this for all possible teams \(S\) gives us Shapley values:
    	$$
      \overbrace{\phi_i(v)}^{\mathclap{\text{Shapley value of }i}}
      =
      \underbrace{\sum_{S\subseteq N\setminus\{i\}}}_{\mathclap{\text{All subsets w/o }i}}
      \overbrace{\frac{|S|!(|N|-|S|-1)!}{|N|!}}^{\mathclap{\text{Weight }W(|S|,|N|)}}
      (
      \underbrace{v(S\cup\{i\})-v(S)}_{\text{Profit individual }i\text{ adds}})
    	$$
    </p>

  <!-- Figure 2 -->
	<figure id="shapley_value_ex">
  
    <div style="margin-bottom:10px;">
  	  <table style="width:500px;border:none;margin-bottom:10px;margin-left:auto;margin-right:auto;">
  	  	<col style="width:200px;"/>
      	<col style="width:250px;"/>
      	<col style="width:50px;"/>
        <tr style="text-align:center;">
          <td style="border:none;" colspan="3">Coalitional game</td>
        </tr>
    		<tr>
    			<td>Subset \(S\)</td>
    			<td>Profit \(v(S)\)</td>
    			<td></td>
    		</tr>
    		<tr>
    			<td>\(\{\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_n" onchange="calcSV()"></td>
    			<td><span id="s_n_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_a" onchange="calcSV()"></td>
    			<td><span id="s_a_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ben\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_b" onchange="calcSV()"></td>
    			<td><span id="s_b_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_c" onchange="calcSV()"></td>
    			<td><span id="s_c_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava,Ben\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_ab" onchange="calcSV()"></td>
    			<td><span id="s_ab_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava,Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_ac" onchange="calcSV()"></td>
    			<td><span id="s_ac_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ben,Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_bc" onchange="calcSV()"></td>
    			<td><span id="s_bc_out"></span></td>
    		</tr>
    		<tr>
    			<td>\(\{Ava,Ben,Cat\}\)</td>
    			<td><input type="range" min="-15" max="15" value="0" class="slider" id="s_abc" onchange="calcSV()"></td>
    			<td><span id="s_abc_out"></span></td>
    		</tr>
  	  </table>
    </div>

    <div style="margin-bottom:0px">
  	  <table style="border:none;margin-left:auto;margin-right:auto;">
		  <col style="width:80px;"/>
    	<col style="width:80px;"/>
		  <col style="width:80px;"/>
    	<col style="width:80px;"/>
		  <col style="width:80px;"/>
    	<col style="width:80px;"/>
        <tr style="text-align:center;">
          <td style="border:none;" colspan="6">Shapley values</td>
        </tr>
    		<tr>
    			<td style="text-align:center;">\(\phi_{Ava}(v)\)</td>
    			<td style="text-align:center;" id="phi_a">0</td>
    			<td style="text-align:center;">\(\phi_{Ben}(v)\)</td>
    			<td style="text-align:center;" id="phi_b">0</td>
    			<td style="text-align:center;">\(\phi_{Cat}(v)\)</td>
    			<td style="text-align:center;" id="phi_c">0</td>
    		</tr>
  	  </table>
    </div>

    <div align="center" style="margin-bottom: 10px">
  	  <input type="button" value="Preset A" class="w3-button w3-teal" id="ex1_presetA" onclick="ex1_presetA()"> 
  	  <input type="button" value="Preset B" class="w3-button w3-green" id="ex1_presetB" onclick="ex1_presetB()"> 
  	  <input type="button" value="Preset C" class="w3-button w3-green" id="ex1_presetC" onclick="ex1_presetC()"> 
  	  <input type="button" value="Preset D" class="w3-button w3-green" id="ex1_presetD" onclick="ex1_presetD()"> 
    </div>

	  <p style="text-align:center;font-size:13px" id="ex1_preset_text">No credit.</p>

    <figcaption>
      <a href="#shapley_value_ex" class="figure-number">2</a>: Shapley values for a company that makes a profit \(v(S)\) based on it's three prospective employees \(Ava\), \(Ben\), and \(Cat\).
    </figcaption>

	</figure>


    <p>
      Shapley values are an excellent way to give credit to individuals in a coalitional game.  In fact, they are known to be a unique solution to spreading credit as defined by the following three desirable properties <d-cite bibtex-key="young1985monotonic"></d-cite> (all of which hold for any coalitional game, as can be seen in <a href="#shapley_value_ex" class="figure-number">2</a>):
      <ul>
        <li>Local Accuracy/Efficiency<d-footnote>This property suggests that the units associated with the Shapley values are in terms of the coalitional game.  For instance, when we adapt them to explain machine learning models, the explanation will be in units that correspond to the model's output (e.g., probability space, etc.) </d-footnote>: The sum of Shapley values for all employees adds up to the profit with all employees minus the profit with no employees (<a href="#shapley_value_ex" class="figure-number">2A-2D</a>):
          $$
            \sum_{i\in N} \phi_i(v)=v(N)-v(\{\})
          $$
        </li>
        <li>Consistency/Monotonicity<d-footnote>This property is particularly important and implies that the Shapley values for features are ordered appropriately.</d-footnote>: If an employee \(i\) always increases company \(v_1\)'s profit more than they would company \(v_2\) for all possible teams of employees, then \(i\)'s attribution for \(v_1\) should be greater than or equal to their attribution in \(v_2\) (<a href="#shapley_value_ex" class="figure-number">2C</a> vs. <a href="#shapley_value_ex" class="figure-number">2B</a>):
          $$
          v_1(S\cup {i})-v_1(S)\geq v_2(S\cup {i})-v_2(S) \forall S \implies \phi_i(v_1)\geq \phi_i(v_2)
          $$
        </li>
        <li>Missingness: Employees \(i\) that don't help or hurt the company's profit must have no attribution (<a href="#shapley_value_ex" class="figure-number">2D</a>):
          $$
          v(S\cup {i})=v(S)\forall S\implies \phi_i(v)=0
          $$
        </li>
      </ul>
    </p>

    <h3 id="shap_values">1.3 Adapting Shapley values to explain machine learning models</h3>


    <p>
      Shapley values are an optimal solution for allocating credit among players (\({1,\cdots,d}\)) in a coalitional game (\(v(S)\)).  However, our goal is actually to allocate credit among features (\(x:=\{x_1,\cdots,x_d\}\in\mathbb{R}^d\)) in a machine learning model (\(f(x)\)) which is generally not a coalitional game:
      $$
      v(S)\neq f(x)
      $$
      In order to use Shapley values to explain a model, our goal moving forward is to define a new coalitional game related to the model's prediction:
      $$
      v(S)=g(f,x)
      $$
    </p>

    <p>
      As a first step, we can explore how coalitional games differ to machine learning models by looking at a model that is a coalitional game: a model with binary features \(x_i\in(0,1)\)<d-footnote>Where 1 indicates presence of a feature and 0 indicates absence of a feature.</d-footnote>.  For such a model, the most natural coalitional game is the function applied to a vector that is one if the feature is in the set \(S\) and zero otherwise:
      $$
      v(S):=f(z^S)\text{, where } z^S_i = 1\text{ if }i\in S\text{, }0\text{ otherwise}
      $$
      However, most machine learning models actually have continuous features. In order to explain a typical machine learning model, we have to define both the presence and absence of features<d-footnote>More precisely, we have to define a new coalitional game \(v(S)\) related to the model's prediction \(f(x)\) where the features in \(S\) are present and the remaining features are absent.  This is analogous to the way players \(S\) in a game are considered present and the remaining players are considered absent.</d-footnote>.
    </p>

    <p>
      <strong>Presence of a feature:</strong> Our goal is to obtain <i>local feature attributions</i> (\(\phi_i(f,x^f)\)), a vector of importance values for each feature of a model prediction for a specific sample \(x^f\).  This means that if feature \(i\) is present, we can simply set that feature to its value in the foreground sample \(x_i^f\). The next step is to address the absence of a feature, which can be done in several ways.
    </p>


  <h3 id="masking_missing">1.4 Absence of a feature (masking)</h3>

    <p>
      One straightforward way to address the absence of a feature is to define a baseline \(x^b\) (i.e., the background sample).  In this case, if feature \(i\) is absent, we can simply set that feature to be \(x_i^b\).  Then the new coalitional game is:
      $$
      v(S)=f(h^S)\text{, where } h^S_i = x^f_i\text{ if }i\in S\text{, }x^b_i\text{ otherwise}
      $$
    </p>

    <p>
      This specific adaptation of Shapley values to machine learning models is called Baseline Shapley, and were shown to be a unique solution to attribution methods with a single baseline based on cost-sharing literature <d-cite bibtex-key="sundararajan2019many"></d-cite>.  However, the choice of the baseline is a complicated one, and many different baselines have been considered including an all-zeros baseline, an average across features, a uniformly distributed baseline, and more (<d-cite bibtex-key="sundararajan2017axiomatic"></d-cite>, <d-cite bibtex-key="shrikumar2017learning"></d-cite>, <d-cite bibtex-key="fong2017interpretable"></d-cite>, <d-cite bibtex-key="sturmfels2020visualizing"></d-cite>) <d-footnote>For an in-depth discussion of this concept and a comparison of several baselines for Aumann-Shapley values applied to explaining images see <d-cite bibtex-key="sturmfels2020visualizing"></d-cite>.</d-footnote>.
    </p>


    <figure id="single_baselines_bad">

      <p style="font-size: 15px;text-align:center;"></p>

      <div style="margin-bottom: -10px">
        <table style="border:none;margin-left:auto;margin-right:auto;">
          <col style="width:130px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <tr style="text-align:left;">
          	<td colspan="7" style="border:none;">a.) Model and sample being explained.</td>
          </tr>
          <tr style="text-align:center;">
          	<td style="text-align:right;">Linear Model:</td>
            <td>\(\beta_1\)</td>
            <td>2</td>
            <td>\(\beta_2\)</td>
            <td>-1</td>
            <td>\(\beta_3\)</td>
            <td>10</td>
          </tr>
          <tr style="text-align:center;">
          	<td style="text-align:right;">Explicand:</td>
            <!-- Height (in) -->
            <td>\(x^f_1\)</td>
            <td>70</td>
            <!-- Weight (lbs) -->
			      <td>\(x^f_2\)</td>
            <td>135</td>
            <!-- Gender 1-male, 0-female -->
            <td>\(x^f_3\)</td>
            <td>0</td>
          </tr>
        </table>
    </div>

      <hr style="margin-top:0px;margin-bottom:10px;">

      <div style="margin-bottom: -10px">
        <table style="border:none;margin-left:auto;margin-right:auto;">
          <col style="width:130px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <tr style="text-align:left;">
          	<td colspan="7" style="border:none;">b.) Zero baseline.</td>
          </tr>
          <tr style="text-align:center;">
          	<td style="text-align:right;">Baseline:</td>
            <td>\(x^b_1\)</td>
            <td>0</td>
            <td>\(x^b_2\)</td>
            <td>0</td>
            <td>\(x^b_3\)</td>
            <td>0</td>
          </tr>
          <tr style="text-align:center;">
          	<td style="text-align:right;">Attribution:</td>
            <td>\(\phi_1\)</td>
            <td>140</td>
            <td>\(\phi_2\)</td>
            <td>-135</td>
            <td>\(\phi_3\)</td>
            <td>0</td>
          </tr>
        </table>
      </div>


      <hr style="margin-top:0px;margin-bottom:10px;">

      <div style="margin-bottom: -10px">
        <table style="border:none;margin-left:auto;margin-right:auto;">
          <col style="width:130px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <col style="width:40px;"/>
          <col style="width:60px;"/>
          <tr style="text-align:left;">
          	<td colspan="7" style="border:none;">c.) Average baseline.</td>
          </tr>
          <tr style="text-align:center;">
          	<td style="text-align:right;">Baseline:</td>
            <td>\(x^b_1\)</td>
            <td>70</td>
            <td>\(x^b_2\)</td>
            <td>135</td>
            <td>\(x^b_3\)</td>
            <td>0.5</td>
          </tr>
          <tr style="text-align:center;">
          	<td style="text-align:right;">Attribution:</td>
            <td>\(\phi_1\)</td>
            <td>0</td>
            <td>\(\phi_2\)</td>
            <td>0</td>
            <td>\(\phi_3\)</td>
            <td>-5</td>
          </tr>
        </table>
      </div>

    <figcaption>
      <a href="#single_baselines_bad" class="figure-number">3</a>: Example illustrating the downsides of a single baseline for Shapley values.  Feature 1 corresponds to height (inches), feature 2 is weight (pounds), and feature 3 is gender (0 is male, 1 is female).  The first baseline is an all-zero baseline.  The second is an average feature value baseline.
    </figcaption>
    </figure>

  <!-- Proof -->
  <div>
    <p><a onclick="hideshow('proof_linearmodel_baseline')"><strong>+ Technical details</strong></a></p>

    <div id="proof_linearmodel_baseline" style="display:none">
      <p>
        For masking, the Shapley values for a linear model are easy to compute:
        $$
        \begin{aligned}
        \phi_i(f,x^f,x^b)&= \sum_{S\in C } W(|S|,|N|)(f(h^{S\cup i}) {-} f(h^{S}))\\
        &= \sum_{S\in C } W(|S|,|N|)(\beta h^{S\cup i} {-} \beta h^{S})\\
        &=\sum_{S\in C } W(|S|,|N|) \beta_i (x^f_i-x^b_i)\\ 
        &= \beta_i (x^f_i-x^b_i)\\ 
        \end{aligned}
        $$
        Note that \(\sum_{S\in C } W(|S|,|N|)=1\).
    </p>
  </div>


    <p>
      One downside of Baseline Shapley is that the choice of baseline is very influential to the resulting feature attributions.  In <a href="#single_baselines_bad" class="figure-number">3</a>, we can see that the choice of baseline heavily influences the resulting attribution value.
    </p>

    <p>
      <a href="#single_baselines_bad" class="figure-number">3b</a> is the zero baseline.  In this case, it appears that height and weight are quite important, however being male is not important at all.  This is a bit counter-intuitive, because relative to being female, being male reduces the prediction for this individual.  Put another way, we can consider a new model where \(x_3\) is 0 for female, rather than 1 for female.  Then, an equivalent model would be \(y=2x_1-x_2-10x_3+10\).  In this case, using the same zero baseline gives an attribution value of -10 instead of 0 for being male for the exact same model.  Since the meaning of zero is often arbitrary for different variables, selecting it as your baseline can result in misleading attributions.
    </p>

    <p>
      Alternatively, we could use a mean baseline as in <a href="#single_baselines_bad" class="figure-number">3c</a>.  Although the mean of a binary variable does not have a natural interpretation, the mean baseline is actually a reasonable choice of baseline for linear models when we use the interventional conditional expectation to define our coalitional game (more details in <a href="#shap_conditional_distribution">Section 1.5</a>).  For this baseline, we see that for an individual with average height and weight, the importance of their height and weight should be zero relative to an average individual.  Furthermore, in comparison to the zero baseline, the attribution for gender with a mean baseline will be consistent across different representations of gender.
    </p>

    <p>
      For linear models comparing to an average individual baseline is equivalent to comparing to the average population<d-footnote>For an interventional conditional expectation</d-footnote>.  However, if the data has binary features the average individual can be confusing, because they would be half female and half male.  Comparing to the average individual is even more unappealing for non-linear models where comparing to an average individual is not equivalent to comparing to the average population.  Rather than use a single background sample (or baseline) we can instead use many background samples and handling missingness with a conditional expectation over an entire population. In the next section we will describe two approaches to incorporate background distributions to our coalitional game \(v(S)\) for a better definition of missingness.
    </p>

    <h3 id="shap_conditional_distribution">1.5 Absence of a feature (conditioning)</h3>

    <p>
		Another natural approach to incorporate a background distribution to the coalitional game is with a conditional expectation.  Instead of simply replacing "missing" features with a fixed value, we condition on the set of features that are "present" as if we know them and use those to guess at the "missing" features.  If we define \(D\) to be the background (underlying) distribution our samples are drawn from, the value of the game is:
    	$$
		  v(S)=\mathbb{E}_D[f(x)|x_{S}]
    	$$
    </p>

    <p>
    	One caveat is that getting this conditional expectation for actual data is very difficult.  Furthermore, even if you do manage to do so, the resulting explanations can end up having undesirable characteristics (more on this later).  Because our goal is just to explain the model itself, an arguably more natural approach is to use causal inference's <i>interventional conditional expectation</i>:
    	$$
    	v(S)=\mathbb{E}_D[f(x)|\text{do}(x_{S})]
    	$$
    	The <i>do</i> notation is causal inference's <i>do</i>-operator <d-cite bibtex-key="pearl2009causality"></d-cite>.  In words, we break the dependence between the features in \(S\) and the remaining features, which is analogous to <i>intervening</i> on the remaining features.  The motivation behind this decision comes from <d-cite bibtex-key="janzing2019feature"></d-cite> which is also very close to Random Baseline Shapley in <d-cite bibtex-key="sundararajan2019many"></d-cite>.  Additionally, this is exactly the assumption made by <a href="https://shap.readthedocs.io/en/latest/#shap.KernelExplainer">Kernel Explainer</a> <d-cite bibtex-key="lundberg2017unified"></d-cite> and <a href="https://shap.readthedocs.io/en/latest/#shap.SamplingExplainer">Sampling Explainer</a> from the SHAP package.
    </p>

    <!-- Figure 3 -->
    <figure id="linear_shap_ex">
      <div align=center style="margin-bottom: 20px">

    		<table style="width:110px;display:inline;margin-right:25px;border:none;">
  	      <col style="width:50px;"/>
  	      <col style="width:65px;"/>
  	      <tr style="text-align:center;">
  	      	<td style="border:none;" colspan="2">Linear</td>
  	  	  </tr>
  	      <tr style="text-align:center;">
  	      	<td colspan="2">Model</td>
  	  	  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(\beta_1\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b1" value="1"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(\beta_2\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b2" value="2"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(\beta_3\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b3" value="3"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(\beta_4\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_b4" value="4"></td>
    		  </tr>
    		</table>

    		<table style="width:300px;display:inline;margin-right:25px;border:none;">
          <col style="width:50px;"/>
          <col style="width:65px;"/>
          <col style="width:65px;"/>
          <col style="width:65px;"/>
          <col style="width:65px;"/>
  	      <tr style="text-align:center;">
  	      	<td colspan="5">Covariance \(C\)</td>
  	      </tr>
  	      <tr style="text-align:center;">
    		    <td></td>
    		    <td>\(x_1\)</td>
    		    <td>\(x_2\)</td>
    		    <td>\(x_3\)</td>
    		    <td>\(x_4\)</td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_1\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor11" value="1"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor12" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor13" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor14" value="0"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_2\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor21" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor22" value="1"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor23" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor24" value="0"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_3\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor31" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor32" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor33" value="1"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor34" value="0"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_4\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor41" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor42" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor43" value="0"></td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_cor44" value="1"></td>
    		  </tr>
    		</table>

    		<table style="width:110px;display:inline;margin-right:25px;border:none;">
          <col style="width:50px;"/>
          <col style="width:65px;"/>
  	      <tr style="text-align:center;">
  	      	<td colspan="2" style="border:none;">Foreground</td>
  	  	  </tr>
  	      <tr style="text-align:center;">
  	      	<td colspan="2">Sample</td>
  	  	  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_1\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x1" value="1"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_2\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x2" value="1"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_3\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x3" value="1"></td>
    		  </tr>
    		  <tr style="text-align:center;">
    		    <td>\(x_4\)</td>
    		    <td style="font-size:12px;"><input class="w3-input w3-border w3-round" type="text" id="ex2_x4" value="1"></td>
    		  </tr>
    		</table>
      </div>

      <div align=center style="margin-bottom:20px">
  	  	<table style="width:300px;display:inline;margin-right:25px;border:none;">
          <col style="width:180px;"/>
          <col style="width:80px;"/>
          <col style="width:80px;"/>
          <col style="width:80px;"/>
          <col style="width:80px;"/>
  	      <tr style="text-align:center;">
  	      	<td></td>
  	      	<td>\(\phi_1\)</td>
  	      	<td>\(\phi_2\)</td>
  	      	<td>\(\phi_3\)</td>
  	      	<td>\(\phi_4\)</td>
  	  	  </tr>
    		  <tr style="text-align:center;">
    		    <td>Shapley Values (CE)</td>
    		    <td id="ex2_CE_phi1">1</td>
    		    <td id="ex2_CE_phi2">2</td>
    		    <td id="ex2_CE_phi3">3</td>
    		    <td id="ex2_CE_phi4">4</td>
    		  </tr>
    		  <tr style="text-align:center;">
    		  	<td>Shapley Values (ICE)</td>
    		    <td id="ex2_ICE_phi1">1</td>
    		    <td id="ex2_ICE_phi2">2</td>
    		    <td id="ex2_ICE_phi3">3</td>
    		    <td id="ex2_ICE_phi4">4</td>
    		  </tr>
  		  </table>
      </div>

      <div align=center style="margin-bottom: 10px">
    		<input type="button" value="Preset A" class="w3-button w3-teal" id="ex2_presetA" onclick="ex2_presetA()">
      	<input type="button" value="Preset B" class="w3-button w3-green" id="ex2_presetB" onclick="ex2_presetB()">
      	<input type="button" value="Preset C" class="w3-button w3-green" id="ex2_presetC" onclick="ex2_presetC()">
      	<input type="button" value="Preset D" class="w3-button w3-green" id="ex2_presetD" onclick="ex2_presetD()">
      </div>

	    <p id="ex2_preset_text" style="text-align:center;font-size:13px">Independent variables.</p>

      <figcaption>
        <a href="#linear_shap_ex" class="figure-number">4</a>: Comparing two versions of Shapley values: conditional expectation (CE) and interventional conditional expectation (ICE).  We make two simplifying assumptions:

        <ul>
          <li class="no-space">The function is linear (\(f=\beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4\))</li>
          <li class="no-space">The data-generating distribution is multivariate normal (\(D\sim \mathcal{N}_4(0,C)\))</li>
        </ul>
      </figcaption>
    </figure>


  <p>
    In general, computing the conditional expectation Shapley value is difficult; however, for a multivariate normal distribution the conditional expectation is easy to calculate.  In addition, for a linear function the conditional expectation of the function equals the function applied to the conditional expectation (\(E[f(x)|x_S]=f(E[x|x_S])\)<d-footnote>Note that this is not generally true.  Only for affine functions.</d-footnote>).  
  </p>

  <!-- Proof -->
  <div>
    <p><a onclick="hideshow('proof_linearmodel')"><strong>+ Technical details</strong></a></p>

    <div id="proof_linearmodel" style="display:none">
      <p>
        Computing Shapley values for a linear model is much easier than for other model classes <d-footnote>Note that we assume features have zero mean in the following calculations.</d-footnote>.  This is how we compute them for <a href="#linear_shap_ex" class="figure-number">4</a>.
      </p>

      <p>
        First, to compute Interventional Conditional Expectation (ICE) SHAP values for a linear model, we can start with:
        $$
        \begin{aligned}
        \phi_i(f,x)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(x)|do(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[f(x)|do(x_{S})])\\
        &=\sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[\beta x|do(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[\beta x|do(x_{S})])\\
        &=\sum_{S\in C } W(|S|,|N|) \beta (\mathbb{E}_{D}[x|do(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[x|do(x_{S})])\\
        &=\sum_{S\in C } W(|S|,|N|) \beta_i x^f_i\\ 
        &= \beta_i x^f_i\\ 
        \end{aligned}
          $$
          Note that \(\sum_{S\in C } W(|S|,|N|)=1\).
    </p>

      <p>
        Second, to compute Conditional Expectation (CE) Shapley values for a linear model, we assume the background distribution \(D\) is multivariate normal with zero mean and covariance \(C\), we can start with:
        $$
        \begin{aligned}
        \phi_i(f,x)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(x)|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[f(x)|x_{S}])\\
        &= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[\beta x|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[\beta x|x_{S}])\\
        &= \sum_{S\in C } W(|S|,|N|)\beta (\mathbb{E}_{D}[x|x_{S\cup \{i\}}] {-} \mathbb{E}_{D}[x|x_{S}])\\
        \end{aligned}
        $$
        Here, we know that \(\mathbb{E}_{D}[x|x_{S}]=C_{N\setminus S,S} C_{S,S}^{-1} x_{S}\).
      </p>
      <hr style="margin-top:0px;margin-bottom:20px;">
    </div>

  <p>
    In <a href="#linear_shap_ex" class="figure-number">4</a> we highlight tradeoffs between the conditional expectation and the interventional conditional expectation for a linear model.  Comparing <a href="#linear_shap_ex" class="figure-number">4A</a> to <a href="#linear_shap_ex" class="figure-number">4B</a>, we can see that the correlation between variables will cause the CE Shapley values to be split between correlated variables.  Although this may be desirable at times<d-footnote>For example, if we are interested in detecting whether a model is secretly using a confounding variable, we may want CE Shapley values.</d-footnote>, it can feel unnatural as in <a href="#linear_shap_ex" class="figure-number">4D</a>, where feature \(x_4\) is as important as feature \(x_3\) despite the fact the model explicitly does not use it.
  </p>

  <p>
    Although both CE Shapley values and ICE Shapley values are meaningful, we will focus on ICE Shapley values moving forward for two reasons: 1.) ICE Shapley values are tractable to compute as opposed to CE Shapley values that require modelling many conditional expectations and 2.) ICE Shapley values more explicitly describe the model's behavior whereas CE Shapley values conflate the model's behavior with the correlation in the data.
  </p>

	</div>

    <!-- Background distribution -->
    <h3 id="background_distribution">1.6 Incorporating a background distribution</h3>

	<p>
		To compute \(\phi_i(f,x^f)\) we evaluate the interventional conditional expectation.  However, this depends on a <i>background distribution</i> \(D\) that the foreground sample will be compared to.  
	</p>

	<p>
		One natural definition of the background distribution is a uniform distribution over a population sample (e.g., equal probability for every sample in a data set).  With this background distribution, we can re-write the Shapley value as an average of <i>Baseline Shapley values</i> (which are analogous to <a href="#masking_missing">masking missing features</a>) <d-cite bibtex-key="sundararajan2019many"></d-cite> <d-cite bibtex-key="chen2019explaining"></d-cite>:
		$$
		\phi_i(f,x^f)=\frac{1}{|D|}\sum_{x^b\in D}\phi_i(f,x^f,x^b)
		$$
    This follows because of the linear form of the Shapley equation and because the interventional conditional expectation has a very natural definition when the background distribution is a single sample \(x^b\) (\(D_{x^b}\)):
		$$
		\mathbb{E}_{D_{x^b}}[f(x^f)|\text{do}(x_{S})]=f(h^S)\text{, where } h^S_i = x^f_i\text{ if }i\in S\text{, }x^b_i\text{ otherwise}
		$$
    In other words, the interventional conditional expectation for a single background sample is the model prediction for a hybrid sample where the features in \(S\) are from the foreground sample and the remaining features are from background sample.  This is as if <i>we intervene on features in the foreground sample with features from the background sample</i> (as in <a href="#masking_missing">Section 1.4</a>).
	</p>  

	<!-- Background Distribution Proof -->
	<div>
		<p><a onclick="hideshow('proof_backgrounddist')"><strong>+ Technical details</strong></a></p>

		<div id="proof_backgrounddist" style="display:none">

		    <p>
			    Define \(C\) to be all combinations of the set \(N \setminus \{i\}\) and \(P\) to be all permutations of \(N \setminus \{i\}\).  Starting with the definition of Shapley values: 
				$$
				\begin{aligned}
				\phi_i(f,x^f)&= \sum_{S\in C } W(|S|,|N|)(\mathbb{E}_{D}[f(x^f)|\text{do}(x_{S\cup \{i\}})] {-} \mathbb{E}_{D}[f(x^f)|\text{do}(x_{S})])\\
				&=\frac{1}{|P|}\sum_{S\subseteq P} \mathbb{E}_D[f(x^f)|\text{do}(x_{S \cup \{i\}})] {-} \mathbb{E}_D[f(x^f)|\text{do}(x_{S})]\\
				&= \frac{1}{|P|}\sum_{S\subseteq P}\frac{1}{|D|}\sum_{x^b\in D} f(h^{S\cup \{i\}}) {-} f(h^{S})\\
				&= \frac{1}{|D|}\sum_{x^b\in D} \frac{1}{|P|}\sum_{S\subseteq P} f(h^{S\cup \{i\}}) {-} f(h^{S})\\
				&= \frac{1}{|D|}\sum_{x^b\in D} \underbrace{\sum_{S\subseteq C} W(|S|,|N|)f(h^{S\cup \{i\}}) {-} f(h^{S})}_{\text{Baseline Shapley value}}\\
				&=\frac{1}{|D|}\sum_{x^b\in D}\phi_i(f,x^f,x^b)
				\end{aligned}
				$$
			</p>
      <hr style="margin-top:0px;margin-bottom:20px;">
		</div>
	</div>

	<p>
		In summary, we show that the problem of obtaining \(\phi_i(f,x^f)\) <d-footnote>With an interventional conditional expectation for the coalitional game.</d-footnote> reduces to an average of simpler problems \(\phi_i(f,x^f,x^b)\) where our foreground sample \(x^f\) is compared to a distribution with only one background sample \(x^b\).  Obtaining \(\phi_i(f,x^f,x^b)\) will prove to be an easy problem to tackle for tree models.
	</p>

  </div>

  <hr>


  <!-- The Algorithm Section -->
  <div style="max-width:800px">
    <h2 id="algorithm">2. An algorithm to explain trees quickly and exactly</h2>
    
    <p>
    Now our goal is to tackle the simpler problem of obtaining Baseline Shapley values \(\phi_i(f,x^f,x^b)\) that are attributions for a single foreground sample and background sample.  The examples in this section are all for a specific foreground sample, background sample, and tree specified in <a href="#define_tree_samples" class="figure-number">5</a>.
	</p>

	<figure id="define_tree_samples">
		<p style="text-align:center;font-size:15px;">
			Tree Parameters <d-footnote>Green links indicate the foreground sample goes down a particular split, red indicates the background sample does, and blue indicates both samples do.</d-footnote> (Click nodes)<br>
		</p>

    <div style="max-width:800px;height:320px;text-align:center">
      <div style="width:350px;height:300px;display:inline-block;">

        <!-- The SVG tree itself -->
        <div align=center>
      	  <div id="graphic"></div> 
      	  <div class="tooltip" id="tooltip"></div>
        </div>

      </div>

      <div style="width:180px;height:300px;display:inline-block;vertical-align: top;">

        <!-- Select variable/threshold -->
        <div align=center style="margin-bottom: 20px">
          <p id="ex3_var_label" style="text-align:center;font-size: 15px">Node Variable:</p>
          <div align=center>
            <input type="button" value="x1" class="w3-button w3-teal" id="ex3_x1_select" onclick="ex3_select_feat1()" style="font-size: 15px">
            <input type="button" value="x2" class="w3-button w3-green" id="ex3_x2_select" onclick="ex3_select_feat2()" style="font-size: 15px">
            <input type="button" value="x3" class="w3-button w3-green" id="ex3_x3_select" onclick="ex3_select_feat3()" style="font-size: 15px">
          </div>
        </div>

        <div id="ex3_thres_div" align=center style="margin-bottom: 20px">
          <p style="font-size: 15px">Node Threshold:</p>
          <input type="range" min="-15" max="15" value="5" class="slider" id="ex3_thres" style="width: 130px;">
          <p style="font-size: 15px;width: 20px;" id="ex3_thres_out">5</p>
        </div>

        <div id="ex3_val_div" align=center style="margin-bottom: 20px;display: none;">
          <p style="font-size: 15px">Leaf Value:</p>
          <input type="range" min="-15" max="15" value="5" class="slider" id="ex3_val" style="width: 130px;">
          <p style="font-size: 15px;width: 20px;" id="ex3_val_out">5</p>
        </div>
      </div>
    
    </div>

    <!-- Foreground and background samples -->
    <div align=center style="margin-bottom: 20px;">
      <table style="width:500px;display:inline;border:none;">
        <col style="width:100px;"/>
        <col style="width:150px;"/>
        <col style="width:50px;"/>
        <col style="width:150px;"/>
        <col style="width:50px;"/>
        <tr>
          <td>Variable</td>
          <td colspan="2">Foreground Sample \(x^f\)</td>
          <td colspan="2">Background Sample \(x^b\)</td>
        </tr>
        <tr>
          <td>\(x_1\)</td>
          <td><input type="range" min="-15" max="15" value="0" class="slider" id="fx1"></td>
          <td style="text-align: left;" id="fx1_out"></td>
          <td><input type="range" min="-15" max="15" value="10" class="slider" id="bx1"></td>
          <td style="text-align: left;" id="bx1_out"></td>
        </tr>
        <tr>
          <td>\(x_2\)</td>
          <td><input type="range" min="-15" max="15" value="0" class="slider" id="fx2"></td>
          <td style="text-align: left;" id="fx2_out"></td>
          <td><input type="range" min="-15" max="15" value="10" class="slider" id="bx2"></td>
          <td style="text-align: left;" id="bx2_out"></td>
        </tr>
        <tr>
          <td>\(x_3\)</td>
          <td><input type="range" min="-15" max="15" value="10" class="slider" id="fx3"></td>
          <td style="text-align: left;" id="fx3_out"></td>
          <td><input type="range" min="-15" max="15" value="0" class="slider" id="bx3"></td>
          <td style="text-align: left;" id="bx3_out"></td>
        </tr>
      </table>
    </div>


    <div align=center style="margin-bottom: 10px">
      <input type="button" value="Reset" class="w3-button w3-green" onclick="ex3_reset()">
    </div>

    <figcaption>
      <a href="#define_tree_samples" class="figure-number">5</a>: Choose foreground sample \(x^f\), background sample \(x^b\), and tree parameters for the remainder of <a href="#algorithm">Section 2</a>.  This is the tree, foreground sample, and background sample that will be explained in the following examples.
    </figcaption>

	</figure>

    <!-- Brute force -->
    <h3 id="brute_force">2.1 Brute force</h3>

    <p>
    	Based on the proof in <a href="#background_distribution">Section 1.6</a>, the brute force approach would be to compute the following:

    	$$
    	\phi_i(f,x^f,x^b)=\sum_{S\subseteq N\setminus\{i\}} \underbrace{W(|S|,|N|)}_{W}(\underbrace{f(h^{S\cup \{i\}})}_{\text{\textcolor{green}{Pos} term}} {-} \underbrace{f(h^S)}_{\text{\textcolor{red}{Neg} term}})
    	$$

    	The algorithm is then fairly straightforward:
    </p>

  <figure id="brute_force_ex" style="margin-bottom: 0px">
    <div class="container" style="width:700px">

      <div class="first" style="width:350px;height:410px">
      	<p style="text-align:center;font-size:15px;margin-bottom:10px">Tree Parameters</p>
      	<div align=center id="ex4_divtree" style="margin-top:0px;margin-bottom:0px"></div>

	    <table style="border:none;text-align:center;margin-left:auto;margin-right:auto;">
        <col style="width:20px;"/>
        <col style="width:80px;"/>
        <col style="width:20px;"/>
        <col style="width:80px;"/>
        <col style="width:20px;"/>
        <col style="width:80px;"/>
	      <tr>
	        <td style="text-align:center;" colspan="6">Attribution Values</td>
	      </tr>
	      <tr>
	        <td id="ex4_phi1">\(\phi_1\)</td>
	        <td style="text-align:center;" id="ex4_phi1_val"></td>
	        <td id="ex4_phi2">\(\phi_2\)</td>
	        <td style="text-align:center;" id="ex4_phi2_val"></td>
	        <td id="ex4_phi3">\(\phi_3\)</td>
	        <td style="text-align:center;" id="ex4_phi3_val"></td>
	      </tr>
	    </table>
      	</div>
      </div>

      <div class="second" style="width:350px;height:410px">
        <table style="border:none;margin-bottom:-5px;margin-left:auto;margin-right:auto;">
          <col style="width:60px;"/>
          <col style="width:90px;"/>
          <col style="width:90px;"/>
          <col style="width:90px;"/>
          <tr>
            <td style="text-align:center;" colspan="4">Foreground & background sample</td>
          </tr>
          <tr>
            <th></th>
            <th>\(x_1\)</th>
            <th>\(x_2\)</th>
            <th>\(x_3\)</th>
          </tr>
          <tr>
            <td>\(x^f\)</td>
            <td id="ex4_fx1">0</td>
            <td id="ex4_fx2">0</td>
            <td id="ex4_fx3">10</td>
          </tr>
          <tr>
            <td>\(x^b\)</td>
            <td id="ex4_bx1">10</td>
            <td id="ex4_bx2">10</td>
            <td id="ex4_bx3">0</td>
          </tr>
          <tr id="ex4_hS">
            <td>\(h^S\)</td>
            <td id="ex4_hs1"></td>
            <td id="ex4_hs2"></td>
            <td id="ex4_hs3"></td>
          </tr>
          <tr id="ex4_hSi">
            <td>\(h^{S\cup i}\)</td>
            <td id="ex4_hsi1"></td>
            <td id="ex4_hsi2"></td>
            <td id="ex4_hsi3"></td>
          </tr>
        </table>

        <table style="border:none;margin-bottom:-5px;margin-left:auto;margin-right:auto;">
          <col style="width:50px;"/>
          <col style="width:67px;"/>
          <col style="width:67px;"/>
          <col style="width:67px;"/>
          <col style="width:67px;"/>
          <tr>
            <td style="text-align:center;" colspan="5">Algorithm State</td>
          </tr>
          <tr>
            <td>\(W\)</td>
            <td>\(S\)</td>
            <td id="ex4_fxS">\(f(h^S)\)</td>
            <td>\(S\cup{i}\)</td>
            <td id="ex4_fxSi">\(f(h^{S\cup{i}})\)</td>
          </tr>
          <tr id="ex4_s1_row">
            <td>1/3</td>
            <td id="s1"></td>
            <td id="s1_val"></td>
            <td id="s1i"></td>
            <td id="s1i_val"></td>
          </tr>
          <tr id="ex4_s2_row">
            <td>1/6</td>
            <td id="s2"></td>
            <td id="s2_val"></td>
            <td id="s2i"></td>
            <td id="s2i_val"></td>
          </tr>
          <tr id="ex4_s3_row">
            <td>1/6</td>
            <td id="s3"></td>
            <td id="s3_val"></td>
            <td id="s3i"></td>
            <td id="s3i_val"></td>
          </tr>
          <tr id="ex4_s4_row">
            <td>1/3</td>
            <td id="s4"></td>
            <td id="s4_val"></td>
            <td id="s4i"></td>
            <td id="s4i_val"></td>
          </tr>
        </table>
	  </div>

      <div class="clear"></div>

    <div align=center style="margin-bottom: 20px">
      <dt-code id="bf_1" block="" language="python">
        def ite_brute(array xf, array xb, tree T, array N):
      </dt-code>
      <dt-code id="bf_2" block="" language="python">
          phi = [0]*len(xf)
      </dt-code>
      <dt-code id="bf_3" block="" language="python">
          for each feature i in N:
      </dt-code>
      <dt-code id="bf_4" block="" language="python">
            for each set S in powerset(setminus(N,i)):
      </dt-code>
      <dt-code id="bf_5" block="" language="python">
              hs  = [xf[j] for j in N if j in S else xb[j]] # Hybrid samples
      </dt-code>
      <dt-code id="bf_6" block="" language="python">
              hsi = [xf[j] for j in N if j in union(S,i) else xb[j]]
      </dt-code>
      <dt-code id="bf_7" block="" language="python">
              fxs  = T.predict(hs) # Predictions
      </dt-code>
      <dt-code id="bf_8" block="" language="python">
              fxsi = T.predict(hsi)
      </dt-code>
      <dt-code id="bf_9" block="" language="python">
              W = (len(S)!*(len(N)-len(S)-1)!)/(len(N)!) # Weight
      </dt-code>
      <dt-code id="bf_10" block="" language="python">
              phi[i] += W*(fxsi-fxs) # Calculate phi contribution
      </dt-code>
    </div>

    <div align=center style="margin-bottom: 0px">
      <input type="button" class="w3-button w3-green" value="<<" onclick="ex4_reset()">
      <input type="button" class="w3-button w3-green" value=">" onclick="bruteForceStep()">
      <input type="button" class="w3-button w3-green" value=">>" onclick="bruteForceRunAll()">
    </div>
  </figure>

  <figure>
    <figcaption>
      <a href="#brute_force_ex" class="figure-number">6</a>: Brute force algorithm for the tree and samples specified in <a href="#define_tree_samples" class="figure-number">5</a>.
    </figcaption>
  </figure>

    <p>
    	If we assume the computational cost of computing the weight \(W\) is constant<d-footnote>Which it will be if we memoize \(k!\) for \(k=1,\cdots,d\).</d-footnote>, then the complexity of the brute force method is the number of terms in the summation multiplied by the cost of making a prediction (on the order of the depth of the tree).  This gives \(O((\text{tree depth})\times 2^{d})\).
    </p>

    <p>
    	Then, in order to compute \(\phi_i(f,x^f,x^b)\) for all features \(i\), we have to re-run the entire algorithm \(d\) times, giving us an overall complexity of
    	$$
    	O(d\times (\text{tree depth})\times 2^{d})
    	$$
	</p>


	<p>
	    An exponential computational complexity is bad; however, if we <i>constrain \(f(x)\) to be a tree-based model</i> (e.g., XGBoost, decision trees, random forests, etc.), then we can come up with a polynomial time algorithm to compute \(\phi_i(f,x^f,x^b)\) exactly.  Why is this the case?  Well, looking at <a href="#brute_force_ex" class="figure-number">6</a>, we can see that even for explaining a single feature, the brute force algorithm may consider a particular path multiple times.  However, to compute the Baseline Shapley value for a single feature, it turns out that we only need to consider each path once.  This insight leads us to the naive algorithm in <a href="#naive_implementation">Section 2.2</a>.
	</p>


    <!--                      -->
    <!-- Naive Implementation -->
    <!--                      -->

    <h3 id="naive_implementation">2.2 Naive Implementation</h3>

	<p>
		Before we get into the algorithm, we first describe a theorem that is the basis for this naive implementation.
	</p>    

  <hr style="margin-top:0px;margin-bottom:10px;">

	<p style="margin-bottom: 0px">
  	<strong>Theorem 1</strong>: To calculate \(\phi_i(f,x^f,x^b)\), we can calculate attributions for each path from the root to each leaf and then sum them:
    $$
    \phi_i(f,x^f,x^b)=\sum_P \phi_i^P(f,x^f,x^b)
    $$

  </p>

  <p>
    To obtain \(\phi_i^P(f,x^f,x^b)\) for a given path \(P\), we define \(N_P\) to be the unique features in the path and \(S_P\) to be the unique features in the path that came from \(x^f\).  Finally, define \(v\) to be the value of the path's leaf.  Then, the attribution of the path is:

  	$$
		\phi_i^P(f,x^f,x^b)=
    \begin{cases}
    	0 & \text{if}\ i\notin N_P \\
    	\underbrace{W(|S_P|-1,|N_P|)\times v}_{\text{\textcolor{green}{Pos} term}} & \text{if}\ i\in S_P \\
    	\underbrace{-W(|S_P|,|N_P|)\times v}_{\text{\textcolor{red}{Neg} term}} & \text{otherwise}
    \end{cases}
  	$$
	</p>


	<!-- Proof -->
	<p><a onclick="hideshow('naive_alg_proof')"><strong>+ Technical Details</strong></a></p>
	<div id="naive_alg_proof" style="display:none">
		<p>
			<i>Sketch of proof</i>: Treat each path \(P\) in the tree from the root to each leaf as a separate model \(f^P(x)\) that returns the value of the leaf if that path is traversed by \(x\) or zero otherwise.  This results in (\(\text{\# leaf nodes}\)) models that operate on disjoint parts of the input space, implying that our original model is equal to the summation of all of these path models:
      $$f(x)=\sum_P f^P(x)$$ 
      By the additivity of Shapley values, 
      $$\phi_i(f,x^f,x^b)=\sum_P\phi_i(f^P,x^f,x^b)$$  
      Then, we can simply calculate \(\phi_i\) for each path model.  Since the path model is zero everywhere except for the associated path, we arrive to the solution in Theorem 1.
		</p>
	</div>

  <hr style="margin-top:0px;margin-bottom:10px;">

	<p>
		Given Theorem 1, we just need an algorithm to obtain \(N_P\) and \(S_P\) for each path, which can be done by traversing the tree.  We will start by explaining the algorithm via an example:
	</p>

	<figure id="tree_example_cases" align=center>
		<img src="images/tree_example3.png" alt="Tree Example 3" style="width: 360px;margin-bottom: 20px;">
    <figcaption><a href="#tree_example_cases" class="figure-number">7</a>:  Green paths are associated with \(\textcolor{green}{x^f}\), red paths are \(\textcolor{red}{x^b}\), and blue paths are associated with both.</figcaption>
	</figure>

	<p>
		In the naive algorithm, we maintain lists \(N_P\) and \(S_P\) as we traverse the tree.  At each internal node (Cases 2-4) we update the lists and then pass them to the node's children.  At the leaf nodes (Case 1), we calculate the attribution for each path.  In <a href="#dynamic_ex" class="figure-number">3</a>, we see four possible cases:
		<ul>
			<li class="no-space">Case 1: \(n\) is a leaf</li>
			<ul class="no-space">
				<li class="no-space">Return the attribution from Theorem 1 based on \(N_P\) and \(S_P\)</li>
			</ul>

			<li class="no-space">Case 2: The feature has been encountered already (\(n_{feature}\in N_P\))</li>
			<ul class="no-space">
				<li class="no-space">Depending on if we split on \(x^f\) or \(x^b\), we compare either \(x^f_{n_{feature}}\) or \(x^b_{n_{feature}}\) to \(n_{threshold}\) and go down the appropriate child</li>
				<li class="no-space">Pass down \(N_P\) and \(S_P\) without modifications because we did not add a new feature</li>
			</ul>

			<li class="no-space">Case 3: Both \(x^f\) and \(x^b\) are on the same side of \(n\)'s split</li>
			<ul class="no-space">
				<li class="no-space">Pass down \(N_P\) and \(S_P\) without modifications because relative to \(x^f\) and \(x^b\) it's as if this node doesn't exist</li>
			</ul>

			<li class="no-space">Case 4: \(x^f\) and \(x^b\) go to different children</li>
			<ul class="no-space">
				<li class="no-space">Add \(n_{feature}\) to both \(N_P\) and \(S_P\) and pass both lists to the \(x^f\) child</li>
				<li class="no-space">Only add \(n_{feature}\) to \(N_P\) and pass both lists to the \(x^b\) child</li>
			</ul>
		</ul>
	</p>

  <figure id="naive_ex" class="l-middle" style="margin-bottom: -10px;">

  	<div class="container" style="width:1000px">
    	<div class="first" style="width:400px;height:620px">
        <p style="text-align:center;font-size:15px;margin-bottom:10px">Tree Parameters</p>
        <div id="ex5_divtree" style="margin-top:0px;margin-bottom:-5px;"></div>
            
  			<table style="border:none;margin-left:auto;margin-right:auto;">
          <col style="width:60px;"/>
          <col style="width:90px;"/>
          <col style="width:90px;"/>
          <col style="width:90px;"/>
          <tr>
            <td style="text-align:center;" colspan="4">Foreground & background sample</td>
          </tr>
    			<tr>
    				<td></td>
    				<td>\(x_1\)</td>
    				<td>\(x_2\)</td>
    				<td>\(x_3\)</td>
    			</tr>
    			<tr>
    				<td>\(x^f\)</td>
    				<td id="ex5_fx1">0</td>
    				<td id="ex5_fx2">0</td>
    				<td id="ex5_fx3">10</td>
    			</tr>
    			<tr>
    				<td>\(x^b\)</td>
    				<td id="ex5_bx1">10</td>
    				<td id="ex5_bx2">10</td>
    				<td id="ex5_bx3">0</td>
    			</tr>
    			<tr id="ex5_h">
    				<td>\(h\)</td>
    				<td id="ex5_h1"></td>
    				<td id="ex5_h2"></td>
    				<td id="ex5_h3"></td>
    			</tr>
  			</table>

        <table style="border:none;margin-left:auto;margin-right:auto;">
          <col style="width:40px;"/>
          <col style="width:120px;"/>
          <col style="width:40px;"/>
          <col style="width:120px;"/>
          <td style="text-align:center;" colspan="4">Algorithm State</td>
          <tr>
            <td>\(S_P\)</td>
            <td id="ex5_sp"></td>
            <td>\(N_P\)</td>
            <td id="ex5_np"></td>
          </tr>
        </table>

        <table style="border:none;margin-left:auto;margin-right:auto;">
          <col style="width:20px;"/>
          <col style="width:80px;"/>
          <col style="width:20px;"/>
          <col style="width:80px;"/>
          <col style="width:20px;"/>
          <col style="width:80px;"/>
          <tr>
            <td style="text-align:center;" colspan="6">Attribution Values</td>
          </tr>
          <tr>
            <td id="ex5_phi1">\(\phi_1\)</td>
            <td style="text-align:center;" id="ex5_phi1_val"></td>
            <td id="ex5_phi2">\(\phi_2\)</td>
            <td style="text-align:center;" id="ex5_phi2_val"></td>
            <td id="ex5_phi3">\(\phi_3\)</td>
            <td style="text-align:center;" id="ex5_phi3_val"></td>
          </tr>
        </table>
      </div>

	  <div class="second" style="width:600px;height:620px;margin-top:20px;">
        <dt-code id="naivecode_1" class="indent0" block="" language="python">
        def ite_naive(array xf, array xb, tree T):
        </dt-code>
        <dt-code id="naivecode_2" class="indent1" block="" language="python">
          phi = [0]*len(xf)
        </dt-code>
        <dt-code id="naivecode_3" class="indent1" block="" language="python">
          def recurse(node n, list np, list sp):
        </dt-code>
        <dt-code id="naivecode_4" class="indent2" block="" language="python">
            # Case 1: Leaf
        </dt-code>
        <dt-code id="naivecode_5" class="indent2" block="" language="python">
            if n.is_leaf: [Theorem 1]
        </dt-code>
        <dt-code id="naivecode_6" class="indent3" block="" language="python">
              for i in N:
        </dt-code>
        <dt-code id="naivecode_7" class="indent4" block="" language="python">
                if i in sp:
        </dt-code>
        <dt-code id="naivecode_8" class="indent5" block="" language="python">
                  phi[i] += W(len(sp)-1,len(np))*n.value
        </dt-code>
        <dt-code id="naivecode_9" class="indent4" block="" language="python">
                elif:
        </dt-code>
        <dt-code id="naivecode_10" class="indent5" block="" language="python">
                  phi[i] -= W(len(sp),len(np))*n.value
        </dt-code>
        <dt-code id="naivecode_11" class="indent2" block="" language="python">
            # Find children associated with xf and xb
        </dt-code>
        <dt-code id="naivecode_12" class="indent2" block="" language="python">
            xf_child = n.left if xf[n.feat] < n.thres else n.right
        </dt-code>
        <dt-code id="naivecode_13" class="indent2" block="" language="python">
            xb_child = n.left if xb[n.feat] < n.thres else n.right

        </dt-code>
        <dt-code id="naivecode_14" class="indent2" block="" language="python">
            # Case 2: Feature encountered before
        </dt-code>
        <dt-code id="naivecode_15" class="indent2" block="" language="python">
            if n.feat in np:
        </dt-code>
        <dt-code id="naivecode_16" class="indent3" block="" language="python">
              if n.feat in sp:
        </dt-code>
        <dt-code id="naivecode_17" class="indent4" block="" language="python">
                return(recurse(xf_child,np,sp))
        </dt-code>
        <dt-code id="naivecode_18" class="indent3" block="" language="python">
              else:
        </dt-code>
        <dt-code id="naivecode_19" class="indent4" block="" language="python">
                return(recurse(xb_child,np,sp))

        </dt-code>
        <dt-code id="naivecode_20" class="indent2" block="" language="python">
            # Case 3: xf and xb go the same way
        </dt-code>
        <dt-code id="naivecode_21" class="indent2" block="" language="python">
            if xf_child == xb_child:
        </dt-code>
        <dt-code id="naivecode_22" class="indent3" block="" language="python">
              return(recurse(xf_child,np,sp))

        </dt-code>
        <dt-code id="naivecode_23" class="indent2" block="" language="python">
            # Case 4: xf and xb don't go the same way
        </dt-code>
        <dt-code id="naivecode_24" class="indent2" block="" language="python">
            if not xf_child != xb_child:
        </dt-code>
        <dt-code id="naivecode_25" class="indent3" block="" language="python">
              f_phi = recurse(xf_child,np+[n.feat],sp+[n.feat])
        </dt-code>
        <dt-code id="naivecode_26" class="indent3" block="" language="python">
              b_phi = recurse(xb_child,np+[n.feat],sp)
        </dt-code>
        <dt-code id="naivecode_27" class="indent1" block="" language="python">
          recurse(n=T.root,sp=[],np=[])
        </dt-code>
      </div>

      <div class="clear"></div>
		</div>

    <div align=center>
    	<input type="button" class="w3-button w3-green" value="<<" onclick="ex5_reset()">
    	<input type="button" class="w3-button w3-green" value=">" onclick="naiveStep()">
    	<input type="button" class="w3-button w3-green" value=">>" onclick="naiveRunAll()">
    </div>

  </figure>

  <figure>

    <figcaption>
      <a href="#naive_ex" class="figure-number">8</a>: Naive algorithm for the tree and samples specified in <a href="#define_tree_samples" class="figure-number">5</a>.
    </figcaption>

	</figure>


  <p>
		Next we examine the computational complexity of computing \(\phi_i(f,x^f,x^b)\) for all features \(i\) using the naive algorithm.
	</p>

	<p>
		For each internal nodes, the complexity is based on Cases 2-4.  In the worst case, we need to check whether the current node's feature has been encountered previously by iterating through \(S_P\) and \(N_P\).  Since these lists are of length \((\text{tree depth})\) in the worst case, each node incurs a linear \(O(\text{tree depth})\) cost.
	</p>

	<p>
		For the leaf nodes, we compute the contributions for each feature (of which there are \(d\)).  Then, computing the contributions for each feature requires checking whether the feature is in \(S_P\).  This means that each leaf node incurs a cost of \(O((\text{tree depth})\times d)\) cost.
	</p>

	<p>
		Putting this together, we get an overall cost of:
		$$
		O((\text{\# internal nodes})\times (\text{tree depth})) + O((\text{\# leaf nodes})\times (\text{tree depth}) \times d)
		$$
	</p>

	<p>
		In the next section we present two observations that allows us to compute \(\phi_i(f,x^f,x^b)\) for all features \(i\) in just \(O(\text{\# nodes})\) time.
	</p>

    <!-- Dynamic Programming -->
    <h3 id="dynamic_programming_implementation">2.3 Dynamic Programming Implementation</h3>

    <p>
    	To improve the computational complexity of the straightforward naive algorithm, we can make two observations.
    </p>

    <p>
    	The first observation is that we can get rid of the multiplicative \((\text{tree depth})\) factor by focusing on what the lists \(S_P\) and \(N_P\) are used for.  The first use is to check if a feature has been previously encountered.  By replacing the lists with boolean arrays, we can check if a given feature has been encountered by a constant time access into the arrays.  This means the internal nodes now incur a constant cost.  The second use of \(S_P\) and \(N_P\) is to calculate \(|S|\) and \(|N|\) at the leaves.  By maintaining integers that keep track of these values, the leaves no longer have to iterate through lists.  This gets rid of the multiplicative \((\text{tree depth})\) factor for leaf nodes.  These optimizations lead to a new computational complexity of:
		$$
		O((\text{\# internal nodes}) + O((\text{\# leaf nodes}) \times d)
		$$
    </p>

    <p>
	    The second observation is that we can compute the attributions for all features simultaneously as we traverse the tree by passing \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) attributions to parent nodes<d-footnote>As a reminder, the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) attributions correspond to the following terms in Theorem 1:
      $$
      \phi_i^P(f,x^f,x^b)=
      \begin{cases}
        0 & \text{if}\ i\notin N_P \\
        \underbrace{W(|S_P|-1,|N_P|)\times v}_{\text{\textcolor{green}{Pos} term}} & \text{if}\ i\in S_P \\
        \underbrace{-W(|S_P|,|N_P|)\times v}_{\text{\textcolor{red}{Neg} term}} & \text{otherwise}
      \end{cases}
      $$
      </d-footnote>.  Before describing the algorithm in more detail, we first present a simple example that illustrates why we can pass up attributions.
	</p>

	<figure id="collapsibility_fig">
		<figure align=center style="margin-bottom: 10px">
			<img src="images/tree_example4.png" alt="Tree Example 3" style="width: 250px;">
		</figure>

		<table cellpadding="10" style="border:none;margin-left:auto;margin-right:auto;">
			<tr>
				<td style="text-align:left;">\(\phi_1(f,x^f,x^b)\)</td>
				<td style="text-align:left;">\(\textcolor{green}{\text{Pos}_{R\to L1}}+\textcolor{green}{\text{Pos}_{R\to L2}}+\textcolor{red}{\text{Neg}_{R\to L3}}+\textcolor{red}{\text{Neg}_{R\to L4}}\)</td>
			</tr>
			<tr>
				<td style="text-align:left;">\(\phi_2(f,x^f,x^b)\)</td>
				<td style="text-align:left;">\(\textcolor{red}{\text{Neg}_{R\to L1}}+\textcolor{green}{\text{Pos}_{R\to L2}}+\textcolor{green}{\text{Pos}_{R\to L3}}+\textcolor{red}{\text{Neg}_{R\to L4}}\)</td>
			</tr>
		</table>

    <figcaption><a href="#collapsibility_fig" class="figure-number">10</a> Example to illustrate collapsibility for features.  Green paths are associated with \(\textcolor{green}{x^f}\) and red paths are associated with \(\textcolor{red}{x^b}\).</figcaption>
	</figure>



	<p>
		In <a href="#collapsibility_fig" class="figure-number">10</a>, we can first observe that for each leaf, according to Theorem 1, there are only two possible values needed to compute the Baseline Shapley values (\(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\)).  Based on the attributions for \(x_1\) we see that these \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms can be grouped by the left and right subtrees below \(x_1\).  To generalize this example, we make the following observation:
	</p>

  <hr style="margin-top:0px;margin-bottom:10px;">

	<p>
		<strong>Observation:</strong> We only add to the attribution for Case 4 nodes.  For a specific Case 4 node \(n\), one child is associated with \(x^f\) and one child is associated with \(x^b\).  If \(\phi_i(f,x^f,x^b)\) is initialized to zeros for all features, then, for each Case 4 node:
		$$
		\phi_{n_{feature}}(f,x^f,x^b)\mathrel{{+}{=}}\sum_{L\in \text{leaves}(x^f\text{ child})}\textcolor{green}{\text{Pos}_{R \to L}} + \sum_{L\in \text{leaves}(x^b\text{ child})}\textcolor{red}{\text{Neg}_{R \to L}}
		$$
    In words, we only consider \(\textcolor{green}{\text{Pos}}\) terms from all paths under the \(x^f\) child and \(\textcolor{red}{\text{Neg}}\) terms from all paths under the \(x^b\) child.
	</p>

  <hr style="margin-top:0px;margin-bottom:10px;">

	<p>
		Therefore it is sufficient to add the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms at a given node and pass them up to the parent to calculate the attributions for a parent node's feature.  This aggregation of the \(\textcolor{green}{\text{Pos}}\) and \(\textcolor{red}{\text{Neg}}\) terms is the dynamic programming observation that allows each node to only need a constant number of operations.
	</p>

	<p>
		Then, the dynamic programming algorithm computes the attributions for all features simultaneously (which gets rid of the multiplicative \(d\) factor for the leaf nodes):
	</p>

    <figure id="dynamic_ex" class="l-middle" style="margin-bottom: -10px;">
      <div class="container" style="width:1000px">
        <div class="first" style="width:400px;height:620px">
        	<p style="text-align:center;font-size:15px;margin-bottom:10px">Tree Parameters</p>
        	<div id="ex6_divtree" style="margin-top:0px;margin-bottom:-5px;"></div>

          <table style="border:none;margin-left:auto;margin-right:auto;">
            <col style="width:60px;"/>
            <col style="width:90px;"/>
            <col style="width:90px;"/>
            <col style="width:90px;"/>
            <tr>
              <td style="text-align:center;" colspan="4">Foreground & background sample</td>
            </tr>
      			<tr>
      				<th></th>
      				<th>\(x_1\)</th>
      				<th>\(x_2\)</th>
      				<th>\(x_3\)</th>
      			</tr>
      			<tr>
      				<td>\(x^f\)</td>
      				<td id="ex6_fx1">0</td>
      				<td id="ex6_fx2">0</td>
      				<td id="ex6_fx3">10</td>
      			</tr>
      			<tr>
      				<td>\(x^b\)</td>
      				<td id="ex6_bx1">10</td>
      				<td id="ex6_bx2">10</td>
      				<td id="ex6_bx3">0</td>
      			</tr>
      			<tr id="ex6_h">
      				<td>\(h\)</td>
      				<td id="ex6_h1"></td>
      				<td id="ex6_h2"></td>
      				<td id="ex6_h3"></td>
      			</tr>
    			</table>

          <table style="border:none;margin-left:auto;margin-right:auto;">
            <col style="width:40px;"/>
            <col style="width:120px;"/>
            <col style="width:40px;"/>
            <col style="width:120px;"/>
            <td style="text-align:center;" colspan="4">Algorithm State</td>
            <tr>
              <td>\(S_C\)</td>
              <td id="ex6_sc"></td>
              <td>\(N_C\)</td>
              <td id="ex6_nc"></td>
            </tr>
          </table>

          <table style="border:none;margin-left:auto;margin-right:auto;">
            <col style="width:20px;"/>
            <col style="width:80px;"/>
            <col style="width:20px;"/>
            <col style="width:80px;"/>
            <col style="width:20px;"/>
            <col style="width:80px;"/>
            <tr>
              <td style="text-align:center;" colspan="6">Attribution Values</td>
            </tr>
            <tr>
              <td id="ex6_phi1">\(\phi_1\)</td>
              <td style="text-align:center;" id="ex6_phi1_val"></td>
              <td id="ex6_phi2">\(\phi_2\)</td>
              <td style="text-align:center;" id="ex6_phi2_val"></td>
              <td id="ex6_phi3">\(\phi_3\)</td>
              <td style="text-align:center;" id="ex6_phi3_val"></td>
            </tr>
          </table>
        </div>

        <div class="second" style="width:600px;height:620px;margin-top:20px">
            <dt-code id="dynamiccode_1" class="indent0" block="" language="python">
            def ite_dynamic(array xf, array xb, tree T):
            </dt-code>
            <dt-code id="dynamiccode_2" class="indent1" block="" language="python">
              phi = [0]*len(xf)
            </dt-code>
            <dt-code id="dynamiccode_3" class="indent1" block="" language="python">
              def recurse(node n, int nc, int sc, array fseen, array bseen):
            </dt-code>
            <dt-code id="dynamiccode_4" class="indent2" block="" language="python">
                # Case 1: Leaf
            </dt-code>
            <dt-code id="dynamiccode_5" class="indent2" block="" language="python">
                if n.is_leaf:
            </dt-code>
            <dt-code id="dynamiccode_6" class="indent3" block="" language="python">
                  if sc == 0: return((0,0))
            </dt-code>
            <dt-code id="dynamiccode_7" class="indent3" block="" language="python">
                  else: return((n.value*W(sc,nc-1),-n.value*W(sc,nc)))
            </dt-code>

            <dt-code id="dynamiccode_8" class="indent2" block="" language="python">
                # Find children associated with xf and xb
            </dt-code>
            <dt-code id="dynamiccode_9" class="indent2" block="" language="python">
                xf_child = n.left if xf[n.feat] < n.thres else n.right
            </dt-code>
            <dt-code id="dynamiccode_10" class="indent2" block="" language="python">
                xb_child = n.left if xb[n.feat] < n.thres else n.right
            </dt-code>
            <dt-code id="dynamiccode_11" class="indent2" block="" language="python">
                # Case 2: Feature encountered before
            </dt-code>
            <dt-code id="dynamiccode_12" class="indent2" block="" language="python">
                if fseen[n.feat] > 0:
            </dt-code>
            <dt-code id="dynamiccode_13" class="indent3" block="" language="python">
                  return(recurse(xf_child,nc,sc,fseen,bseen))
            </dt-code>
            <dt-code id="dynamiccode_14" class="indent2" block="" language="python">
                if bseen[n.feat] > 0:
            </dt-code>
            <dt-code id="dynamiccode_15" class="indent3" block="" language="python">
                  return(recurse(xb_child,nc,sc,fseen,bseen))
            </dt-code>

            <dt-code id="dynamiccode_16" class="indent2" block="" language="python">
                # Case 3: xf and xb go the same way
            </dt-code>
            <dt-code id="dynamiccode_17" class="indent2" block="" language="python">
                if xf_child == xb_child:
            </dt-code>
            <dt-code id="dynamiccode_18" class="indent3" block="" language="python">
                  return(recurse(xb_child,nc,sc,fseen,bseen))
            </dt-code>
            <dt-code id="dynamiccode_19" class="indent2" block="" language="python">
                # Case 4: xf and xb don't go the same way
            </dt-code>
            <dt-code id="dynamiccode_20" class="indent2" block="" language="python">
                if xf_child != xb_child:
            </dt-code>
            <dt-code id="dynamiccode_21" class="indent3" block="" language="python">
				fseen[n.feat] += 1
            </dt-code>
            <dt-code id="dynamiccode_22" class="indent3" block="" language="python">
                  posf,negf = recurse(xf_child,nc+1,sc+1,fseen,bseen)
            </dt-code>
            <dt-code id="dynamiccode_23" class="indent3" block="" language="python">
				fseen[n.feat] -= 1; bseen[n.feat] += 1
            </dt-code>
            <dt-code id="dynamiccode_24" class="indent3" block="" language="python">
                  posb,negb = recurse(xb_child,nc+1,sc  ,fseen,bseen)
            </dt-code>
            <dt-code id="dynamiccode_25" class="indent3" block="" language="python">
				bseen[n.feat] -= 1
            </dt-code>
            <dt-code id="dynamiccode_26" class="indent3" block="" language="python">
                  phi[n.feat] += posf+negb
            </dt-code>
            <dt-code id="dynamiccode_27" class="indent3" block="" language="python">
                  return((posf+posb,negf+negb))
            </dt-code>
            <dt-code id="dynamiccode_28" class="indent1" block="" language="python">
              recurse(n=T.root,0,0,[0]*len(xf),[0]*len(xf))
            </dt-code>
        </div>

  	    <div class="clear"></div>
  		</div>

    <div align=center>
    	<input type="button" class="w3-button w3-green" value="<<" onclick="ex6_reset()">
    	<input type="button" class="w3-button w3-green" value=">" onclick="dynamicStep()">
    	<input type="button" class="w3-button w3-green" value=">>" onclick="dynamicRunAll()">
    </div>

  </figure>

  <figure>

    <figcaption>
      <a href="#dynamic_ex" class="figure-number">10</a>: Dynamic programming algorithm for the tree and samples specified in <a href="#define_tree_samples" class="figure-number">5</a>.
    </figcaption>

  </figure>


    <p>
		In <a href="#dynamic_ex" class="figure-number">10</a> each node now only requires a constant amount of work.  The computational complexity to compute \(\phi_i(f,x^f,x^b)\) for all features \(i\) with this algorithm is just:
		$$
		O(\text{\# nodes})
		$$
	</p>

	<h3 id="final_considerations">2.4 Final considerations</h3>

    <p>
		<strong>Background distribution:</strong> Our original goal was to compute \(\phi_i(f,x^f)\).  In order to do so, we compute \(\phi_i(f,x^f,x^b)\) for many references \(x^b\), resulting in a run time of:
		$$
		O(|D|\times (\text{\# nodes}))
		$$
		where \(|D|\) is the number of samples in the background distribution.  In practice, using a fixed number of about 100 to 1000 references works well.
	</p>

    <p>
		<strong>Further optimization:</strong> Explaining the tree for a specific foreground and background sample requires knowing where all hybrid samples go in the tree.  Therefore we achieve the best possible complexity of \(\Omega(\text{\# nodes})\) for Baseline Shapley values.  However, it may be possible to compute the attributions for many background samples simultaneously in sub-linear time in order to reduce the \(O(|D|\times (\text{\# nodes}))\) cost.
	</p>

    <p>
		<strong>Ensembles of trees:</strong> Many tree based methods are ensembles (e.g., random forests, gradient boosting trees).  In order to compute that attributions for these types of models, we can simply leverage the additivity of Shapley values and explain each tree and sum the attributions for each tree.  This means that to explain a gradient boosting tree model, the computational complexity is:
		$$
		O((\text{\# trees}) \times |D|\times (\text{\# nodes}))
		$$		
	</p>

  <p>
    <strong>Empirical evaluation:</strong> The goal of this article is understanding how these algorithms work, and not empirically evaluating them. For evaluation we refer readers to <d-cite bibtex-key="lundberg2020local"></d-cite>.  In this article, we identify a way of assigning credit that comes equipped with a set of desirable properties (i.e., Shapley values) and show how to compute them exactly for trees with a tractable algorithm.  This means that the credit allocation we obtain comes built in with many of the properties that empirical evaluation (often in the form of ablation tests) aim to measure (e.g., consistency).
  </p>  

  	<hr>

    <h2 id="related_work">Related Work</h2>

    <h3>Methods in the SHAP package</h3>

    <p>
    	It should be noted that there are a number of alternative methods that aim to estimate interventional conditional expectation Shapley values.  A few of these methods include: <i>Sampling Explainer</i>, <i>Kernel Explainer</i>, and <i>Path Dependent Tree Explainer</i>.  If you are explaining tree-based models, it may not be clear which one you should use.  In this article we briefly overview a few of these the methods and compare them to Interventional Tree Explainer (ITE).
	</p>

    <p>
      First, there are two model agnostic explanation methods in the SHAP package.  The first is <i>Sampling Explainer</i> which is an implementation of Interactions-based Method for Explanation (IME) <d-cite bibtex-key="kononenko2010efficient"></d-cite>.  This approach is based on sampling from all possible sets in order to estimate ICE Shapley values.  The second is <i>Kernel Explainer</i> which is an extension of Local Interpretable Model-agnostic Explanations (LIME) <d-cite bibtex-key="ribeiro2016should"></d-cite> to estimate ICE Shapley values.  Both <i>Sampling Explainer</i> and <i>Kernel Explainer</i> are sampling based approaches that will converge to the same Shapley values ITE obtains.  However, ITE is much faster in practice because it leverages the structure of the tree.
    </p>

    <p>
      Second, in the SHAP package there is a method named <i>Path Dependent Tree Explainer (PDTE)</i> that is meant to obtain Shapley values for tree models specifically.  PDTE approximates the interventional conditional expectation based on how many training samples went down paths in the tree, whereas ITE computes it exactly.  The computational complexity of PDTE is \(O((\text{\# leaf nodes})\times (\text{tree depth})^2)\).  In practice, PDTE can be faster than ITE, although it may depend on the number of references or the tree depth.  The tradeoff is that the attribution values estimated by PDTE are biased away from interventional expectations by conditioning on parent nodes during the computation of the expected values.
	</p>

  <h3>Additional methods to explain trees</h3>

  <p>
    Two pre-existing methods to explain trees include <i>Gain (Gini Importance)</i> <d-cite bibtex-key="breiman_1984"></d-cite> and <i>Saabas</i> <d-cite bibtex-key="andosa_2019"></d-cite>.  Both methods consider a single ordering of the features (as opposed to all possible orderings) specified by the tree they are explaining.  Note that for an infinite ensemble of fully developed totally randomized trees <d-footnote>Where a fully developed totally randomized tree is a decision tree where each node \(n\) is partitioned using a variable \(x_i\) picked uniformly at random among those not yet used upstream of \(n\), each node \(n\) has one child for each possible value of \(x_i\), and the construction of these trees is complete only when all variables have been used.</d-footnote> and an infinitely large training sample, <i>Gain</i> is the mutual information between covariates and the outcome <d-cite bibtex-key="louppe2014understanding"></d-cite> and Saabas gives the Shapley values <d-cite bibtex-key="lundberg2020local"></d-cite>.  However, in practice trees are constructed greedily and both methods fail to satisfy the consistency axiom because they only consider a single ordering of the features.
  </p>

  <h3>Empirical Evaluation</h3>

  <p>
    In this article we do not empirically evaluate these methods, because evaluating interpretability methods can difficult due to the subjective nature of an explanation.  Instead, we identify a way of assigning credit that comes equipped with a set of desirable properties (i.e., Shapley values) and show how to compute them exactly for trees with a tractable algorithm.  This means that the credit allocation we obtain comes built in with many of the desirable properties that ablation tests aim to measure (e.g., consistency).  That being said, <d-cite bibtex-key="lundberg2020local"></d-cite> provides an in-depth empirical comparison of many of these methods using a variety of ablation tests.
  </p>

    <h2 id="references">Acknowledgements</h2>

    <p>This material is based upon work supported by the National Science Foundation Graduate Research Fellowship under Grant No. DGE-1762114.  Any opinion, findings, and conclusions or recommendations expressed in this material are those of the authors(s) and do not necessarily reflect the views of the National Science Foundation.</p>

	</div>

  </div>

</div>
</d-article>

<!-- Figure 1 - Kaggle methods d3 bar plot -->
<script src="js/kaggleMethods.js"></script>

<!-- Example 1 - Computing Shapley values -->
<script src="js/shapleyValues.js"></script>

<!-- Example 2 - Computing Shapley values CES vs RBS -->
<script src="js/linearModelCESvsRBS.js"></script>

<!-- Example 3 - Initial tree parameters -->
<script src="js/treeData0.js"></script>

<!-- Example 3 - Creating tree and samples -->
<script src="js/createTreeSamples.js"></script>

<!-- Example 4 - Brute force algorithm -->
<script src="js/brute_force_ex.js"></script>

<!-- Example 5 - Naive tree algorithm -->
<script src="js/naive_ex.js"></script>

<!-- Example 6 - DP tree algorithm -->
<script src="js/dp_ex.js"></script>

<script>
function hideshow(type) {
    var x = document.getElementById(type);
    if (x.style.display === 'none') {
        x.style.display = 'block';
    } else {
        x.style.display = 'none';
    }
}
</script>

<d-appendix>
  <d-footnote-list></d-footnote-list>
  <d-citation-list></d-citation-list>
</d-appendix>

<d-bibliography src="bibliography.bib"></d-bibliography>

<script src="local_template.v2.js"></script>

<script>
  window.onload = function() {
    // Set indentations for code
    for (var i=0; i < 10; i++) {
      var a = document.getElementById("bf_"+(i+1));
      var b = a.getElementsByTagName("pre")[0];
      b.style.marginTop = "0px";
      b.style.marginBottom = "0px";
      b.style.paddingTop = "0px";
      b.style.paddingBottom = "0px";
      b.style.fontSize = "14px";
      b.style.background = "#ffffff";
      if (i > 0) {
        b.style.textIndent = "18px";
      }
      if (i > 2) {
        b.style.textIndent = "36px";
      }
      if (i > 3) {
        b.style.textIndent = "54px";
      } 
    }

    // Set indentations for code
    for (var i=0; i < 27; i++) {
      var a = document.getElementById("naivecode_"+(i+1));
      var b = a.getElementsByTagName("pre")[0];
      b.style.marginTop = "0px";
      b.style.marginBottom = "0px";
      b.style.paddingTop = "0px";
      b.style.paddingBottom = "0px";
      b.style.fontSize = "14px";
      b.style.background = "#ffffff";
      if (a.classList[0] == "indent0") {
        b.style.textIndent = "0px";
      } else if (a.classList[0] == "indent1") {
        b.style.textIndent = "18px";
      } else if (a.classList[0] == "indent2") {
        b.style.textIndent = "36px";
      } else if (a.classList[0] == "indent3") {
        b.style.textIndent = "54px";
      } else if (a.classList[0] == "indent4") {
        b.style.textIndent = "72px";
      } else if (a.classList[0] == "indent5") {
        b.style.textIndent = "90px";
      }
    }

    // Set indentations for code
    for (var i=0; i < 28; i++) {
      var a = document.getElementById("dynamiccode_"+(i+1));
      var b = a.getElementsByTagName("pre")[0];
      b.style.marginTop = "0px";
      b.style.marginBottom = "0px";
      b.style.paddingTop = "0px";
      b.style.paddingBottom = "0px";
      b.style.fontSize = "14px";
      b.style.background = "#ffffff";
      if (a.classList[0] == "indent0") {
        b.style.textIndent = "0px";
      } else if (a.classList[0] == "indent1") {
        b.style.textIndent = "18px";
      } else if (a.classList[0] == "indent2") {
        b.style.textIndent = "36px";
      } else if (a.classList[0] == "indent3") {
        b.style.textIndent = "54px";
      } else if (a.classList[0] == "indent4") {
        b.style.textIndent = "72px";
      } else if (a.classList[0] == "indent5") {
        b.style.textIndent = "90px";
      }
    }

  };
</script>


</body>
</html>
